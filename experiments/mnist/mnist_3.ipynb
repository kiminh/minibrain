{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Experiments - Playing With Different Architectures\n",
    "\n",
    "Sometimes we need to come back to the basis, this is the place I choose for that.\n",
    "\n",
    "Here I'll experiment with different networks on the MNIST and MNIST variants datasets trying to find relations in which I can reduce the number of parameters in comparison with a Fully Connected (FC) network.\n",
    "\n",
    "Later on, I might try with other datasets that are small enough for my GTX1080.\n",
    "\n",
    "Yes, I know, the issue is already solved for Images with Convolutional Networks but what I want to see is not that. Instead I want to understand ways in which fully connected networks can be replaced by other types of connections to minimize the number of parameters in it. This is an exploratory work to get a deeper understanding on Neural Networks (NNs) that will at least give me some fun time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparseNet\n",
    "\n",
    "MMMMmmmmmm ... something is not working right here .... should fix it ...\n",
    "where have I made the mistake ... ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network modules  to try\n",
    "from network_modules import *\n",
    "from net_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_mnist():\n",
    "    return transforms.Compose([\n",
    "#         transforms.Grayscale(),\n",
    "#         transforms.Resize((w, h)),  # this should be used ONLY if the image is bigger than this size\n",
    "        transforms.ToTensor()\n",
    "#         transforms.Normalize(0.5, 0.25)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, mname, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "\n",
    "    model.to(device)\n",
    "    num_epochs = 100\n",
    "    batch_size = 128\n",
    "#     learning_rate = 0.0001\n",
    "    learning_rate = 0.001\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "#     criterion = nn.MSELoss()\n",
    "    criterion = F.nll_loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "    transformation = transform_mnist()\n",
    "    train_loader, test_loader = get_loaders(batch_size, transformation)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (img, labels) in enumerate(train_loader):\n",
    "#             print(\"shape: \", img.shape, labels.shape)\n",
    "            labels = labels.to(device)\n",
    "            img = img.to(device).view((-1,784))\n",
    "            \n",
    "#             print(\"shape2: \", img.shape)\n",
    "            # ===================forward=====================\n",
    "            #         print(\"encoding batch of  images\")\n",
    "            output = model(img)\n",
    "#             print(\"output shape: \", output.shape, labels.shape, labels[:10])\n",
    "            #         print(\"computing loss\")\n",
    "            loss = criterion(output, labels)\n",
    "            # ===================backward====================\n",
    "            #         print(\"Backward \")\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # ===================log========================\n",
    "        if epoch % 20 == 0:\n",
    "            print('epoch [{}/{}], loss:{:.6f}'.format(epoch+1, num_epochs, loss.data[0]))\n",
    "#         if epoch % 10 == 0:\n",
    "#             pic = to_img(output.cpu().data)\n",
    "#             in_pic = to_img(img.cpu().data)\n",
    "#             save_image(pic, './results/2x2-out_image_{}.png'.format(epoch))\n",
    "#             save_image(in_pic, './results/2x2-in_image_{}.png'.format(epoch))\n",
    "#         if loss.data[0] < 0.015: #arbitrary number because I saw that it works well enough\n",
    "#             print(\"loss < 0.015, breaking\")\n",
    "#             break\n",
    "#     model.save_model(mname, \"model\")\n",
    "\n",
    "    print('########################################################')\n",
    "    print('Final performance of model {} epoch [{}/{}], loss:{:.8f}'.format(mname, epoch+1, num_epochs, loss.data[0]))\n",
    "    print('--------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = [\n",
    "    \"relu\",\n",
    "    \"relu6\",\n",
    "    \"sigmoid\",\n",
    "    \"elu\",\n",
    "    \"leaky_relu\",\n",
    "    \"logsigmoid\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcnets_layers = [\n",
    "        [784,500,10],\n",
    "        [784,1000,10],\n",
    "        [784,1500,10],\n",
    "        [784,500,500,10],\n",
    "        [784,1000,500,10],\n",
    "        [784,1000,1000,10],\n",
    "        [784,500,500,500,10],\n",
    "        [784,1000,500,500,10],\n",
    "        [784,1000,1000,500,10],\n",
    "        [784,1000,1000,1000,10],\n",
    "]\n",
    "\n",
    "sparsities = [0.9, 0.8, 0.7, 0.6]  # , 0.5, 0.4, 0.3, 0.2, 0.1]  # [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = []\n",
    "for l in fcnets_layers:\n",
    "    for s in sparsities:\n",
    "#         for a in activations:\n",
    "        for a in [\"relu\"]:\n",
    "            mname = str(l)+\"_\"+str(s)+\"_\"+a\n",
    "            models.append(SparseNet(l, sparsity=s, activation=a, name=mname) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:-22719.091797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [21/100], loss:-6152859.500000\n",
      "epoch [41/100], loss:-20490514.000000\n",
      "epoch [61/100], loss:-47534016.000000\n",
      "epoch [81/100], loss:-77134024.000000\n",
      "########################################################\n",
      "Final performance of model [784, 500, 10]_0.9_relu epoch [100/100], loss:-115477160.00000000\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel_launcher.py:52: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:-19076.304688\n",
      "epoch [21/100], loss:-5708181.500000\n",
      "epoch [41/100], loss:-19475594.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-504:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torchvision/datasets/mnist.py\", line 77, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torchvision/transforms/functional.py\", line 78, in to_tensor\n",
      "    img = img.view(pic.size[1], pic.size[0], nchannel)\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-90bff572eccb>\", line 4, in <module>\n",
      "    train(model, mname)\n",
      "  File \"<ipython-input-6-555887a5db65>\", line 21, in train\n",
      "    for i, (img, labels) in enumerate(train_loader):\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 330, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 309, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/usr/lib/python3.5/queue.py\", line 164, in get\n",
      "    self.not_empty.wait()\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 293, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1414, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 167, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 709, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 23779) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "for i in range(len(fcnets_layers)):\n",
    "    model = models[i]\n",
    "    mname = model.name\n",
    "    train(model, mname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:-3690.978271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [21/100], loss:-933181.437500\n",
      "epoch [41/100], loss:-3140060.250000\n",
      "epoch [61/100], loss:-6421920.500000\n",
      "epoch [81/100], loss:-11181103.000000\n",
      "########################################################\n",
      "Final performance of model [784, 500, 10]_0.1_relu epoch [100/100], loss:-16312471.00000000\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel_launcher.py:52: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:-5665.460938\n",
      "epoch [21/100], loss:-1565372.000000\n",
      "epoch [41/100], loss:-5051212.000000\n",
      "epoch [61/100], loss:-10459762.000000\n",
      "epoch [81/100], loss:-18005732.000000\n",
      "########################################################\n",
      "Final performance of model [784, 500, 10]_0.2_relu epoch [100/100], loss:-28013096.00000000\n",
      "--------------------------------------------------------\n",
      "epoch [1/100], loss:-7268.011719\n",
      "epoch [21/100], loss:-2069410.125000\n",
      "epoch [41/100], loss:-6789892.500000\n",
      "epoch [61/100], loss:-14524044.000000\n",
      "epoch [81/100], loss:-24793238.000000\n",
      "########################################################\n",
      "Final performance of model [784, 500, 10]_0.3_relu epoch [100/100], loss:-36976052.00000000\n",
      "--------------------------------------------------------\n",
      "epoch [1/100], loss:-10079.895508\n",
      "epoch [21/100], loss:-3124085.750000\n",
      "epoch [41/100], loss:-10146665.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-354:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torchvision/datasets/mnist.py\", line 77, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torchvision/transforms/functional.py\", line 70, in to_tensor\n",
      "    img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-90bff572eccb>\", line 4, in <module>\n",
      "    train(model, mname)\n",
      "  File \"<ipython-input-6-555887a5db65>\", line 21, in train\n",
      "    for i, (img, labels) in enumerate(train_loader):\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 336, in __next__\n",
      "    return self._process_next_batch(batch)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 355, in _process_next_batch\n",
      "    self._put_indices()\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 345, in _put_indices\n",
      "    indices = next(self.sample_iter, None)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torch/utils/data/sampler.py\", line 139, in __iter__\n",
      "    batch.append(idx)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 715, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 684, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 669, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 22680) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "for i in range(len(fcnets_layers)):\n",
    "    model = models[i]\n",
    "    mname = model.name\n",
    "    train(model, mname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
