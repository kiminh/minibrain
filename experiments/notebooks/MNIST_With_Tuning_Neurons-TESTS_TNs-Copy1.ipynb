{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with Tuning Neurons\n",
    "\n",
    "This notebook is dedicated to study the effectof the tunning neurons in the MNIST task, the comparison should be done with other kind of ANNs already know in the industry.\n",
    "\n",
    "**The main points to compare are**:\n",
    " - Performance (errors, accuracy, other metrics)\n",
    " - Learning Speed (in cycles)\n",
    " - Compare results of BOTH types of networks at initialization moment with a final Linear decoder\n",
    " - Operation complexity (number of OPS for example for each to get to a meaningful representation)\n",
    " - Compare a  random set of Tuning Neuron Ensembles (TNEs) with a final linear decoder\n",
    " - Create several ideas on attention mechanisms for the TNEs to generate different Deep TNEs Networks (DTNENs) and compare results\n",
    "\n",
    "*NOTE*: The implementation of TNEs in TensorFlow might be needed for this task, as it might take a lot of time in the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#issue with TensorFlow, reference here: https://github.com/tensorflow/tensorflow/issues/6698\n",
    "#config needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "# sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions and neuron creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_tuning_neuron_2d(shape, min_y=0.5,\n",
    "#                                max_y=1.5, min_weight=0.0, max_weight=0.8,\n",
    "#                                min_x=-1.0, max_x=1.0, saturation=None,\n",
    "#                               ):\n",
    "#     height, width, input_channels, output_channels = shape #NHWC\n",
    "#     n_neurons = n_synapses = width * height\n",
    "#     # the first point is for y=0\n",
    "#     nshape = [height, width] #, output_channels]\n",
    "#     y1 = tf.zeros((n_neurons, ))\n",
    "#     x1 = tf.random_uniform((n_neurons, ), -1, 1)\n",
    "#     # the second point is for x = +-1\n",
    "#     y2 = tf.random_uniform((n_neurons, ),min_y, max_y)\n",
    "#     vec = np.random.choice([-1,1], (n_neurons, ))\n",
    "#     x2 = tf.convert_to_tensor(vec, tf.float32) #will define a's sign\n",
    "#     #a = tf.Variable( tf.divide(tf.subtract(y1,y2), tf.subtract(x1,x2)))\n",
    "#     a = tf.divide(tf.subtract(y1,y2), tf.subtract(x1,x2))\n",
    "#     A = a\n",
    "#     #A = tf.stack([a for i in range(output_channels)])#, axis=1)\n",
    "#     b = tf.subtract(y1, (a - x1))\n",
    "#     B = b\n",
    "#     #b = tf.Variable(tf.subtract(y1, (a - x1)))\n",
    "#     #B = tf.stack([b for i in range(output_channels)])#, axis=1)\n",
    "#     W = tf.Variable(tf.random_uniform([n_synapses,n_neurons]))\n",
    "#     if(saturation is None):\n",
    "#         saturation = [random.uniform(0.8, 1.0),1.0]\n",
    "#     sat = tf.random_uniform((n_neurons, ), *saturation)\n",
    "#     SAT = sat\n",
    "#     return (A, B, SAT, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tuning_neuron_2d(shape, min_y=0.5,\n",
    "                               max_y=1.5, min_weight=0.0, max_weight=0.8,\n",
    "                               min_x=-1.0, max_x=1.0, saturation=None,\n",
    "                              ):\n",
    "    height, width, input_channels, output_channels = shape #NHWC\n",
    "    n_neurons = n_synapses = width * height\n",
    "    # the first point is for y=0\n",
    "    y1 = tf.zeros((n_neurons, ))\n",
    "    #x1 = tf.random_uniform((n_neurons, ), -1, 1)\n",
    "    x1 = tf.zeros((n_neurons, )) #try with the equivalent of a relu\n",
    "    #tf.random_uniform((n_neurons, ), -1, 1)\n",
    "    # the second point is for x = +-1\n",
    "    #y2 = tf.random_uniform((n_neurons, ), min_y, max_y)\n",
    "    #vec = np.random.choice([-1,1], (n_neurons, ))\n",
    "    #x2 = tf.convert_to_tensor(vec, tf.float32) #will define a's sign\n",
    "    #try with the equivalent of a relu\n",
    "    y2 = tf.ones((n_neurons, ))\n",
    "    x2 = tf.ones((n_neurons, ))\n",
    "    #a = tf.Variable( tf.divide(tf.subtract(y1,y2), tf.subtract(x1,x2)))\n",
    "    #a = tf.divide(tf.subtract(y1,y2), tf.subtract(x1,x2))\n",
    "    a = tf.ones((n_neurons,))\n",
    "    #a = tf.ones((height, width))\n",
    "    #a = tf.ones((n_neurons, output_channels))\n",
    "    A = a\n",
    "    #A = tf.stack([a for i in range(output_channels)], axis=2)\n",
    "    #b = tf.subtract(y1, (a - x1))\n",
    "    b = tf.zeros((n_neurons, ))\n",
    "    #b = tf.zeros((n_neurons, output_channels, ))\n",
    "    #b = tf.Variable(tf.subtract(y1, (a - x1)))\n",
    "    #B = tf.stack([b for i in range(output_channels)])#, axis=1)\n",
    "    B = b\n",
    "    #W = tf.Variable(tf.random_uniform([n_synapses,n_neurons]))\n",
    "    W = tf.random_uniform([n_synapses,n_neurons])\n",
    "    #W = tf.random_uniform([n_synapses,n_neurons, output_channels])\n",
    "    #W = tf.random_uniform((n_synapses * n_neurons * output_channels, ))\n",
    "                   \n",
    "    if(saturation is None):\n",
    "        saturation = [random.uniform(0.8, 1.0),1.0]\n",
    "    sat = tf.random_uniform((n_neurons, ), *saturation)\n",
    "    SAT = sat\n",
    "    #SAT = tf.stack([sat for i in range(output_channels)])#, axis=1)\n",
    "    #outputs placeholder\n",
    "    return (A,B,SAT,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tuning_neuron(shape, A,B,SAT,W,x):\n",
    "    height, width, input_channels, output_channels = shape #NHWC\n",
    "    #regression logit model\n",
    "    # I will first play with reshaping as I don't understand TF yet too much\n",
    "    # it seems that reshaping is the ONLY available solution for tensorflow\n",
    "    #xresh = tf.transpose(tf.reshape(x, [batch_size, height*width, output_channels]))\n",
    "    #print(A.shape, B.shape, W.shape, SAT.shape, x.shape)\n",
    "    xresh = tf.transpose(tf.reshape(x, [-1, height*width, output_channels ]),perm=[0,2,1])\n",
    "    #xresh = tf.reshape(x, [-1, height * width, output_channels ])\n",
    "    #Wr = tf.reshape(W, [-1, height*width, height*width])\n",
    "    #try with another resizing and see what gives!!\n",
    "    xresh2 = tf.reshape(x, [-1, height*width])\n",
    "    xcurrent = tf.matmul(xresh2, W)\n",
    "    #xcurrent = tf.matmul(xresh, W)\n",
    "    #yb = tf.maximum(tf.minimum(tf.multiply(xcurrent, A) + B, sat), 0 )\n",
    "    #print(A.shape, B.shape, W.shape, SAT.shape, x.shape, xcurrent.shape, xresh.shape)\n",
    "    #yb = tf.maximum(tf.minimum(tf.multiply(xcurrent, A) + B, SAT), 0 )\n",
    "    #yb = tf.maximum(tf.multiply(xcurrent, A) + B, 0 )\n",
    "    #yb = tf.transpose(tf.reshape(xcurrent, [-1, output_channels, height, width]), perm=[0,1,3,2])\n",
    "    yb = tf.maximum(tf.matmul(xcurrent, tf.reshape(A,(height*width,-1))), 0 )\n",
    "    #y = tf.maximum(tf.multiply(yb, A), 0 )\n",
    "    #yb = tf.maximum( x, 0)\n",
    "    y = tf.transpose(tf.reshape(yb, [-1, output_channels, height, width]), perm=[0,2,3,1])\n",
    "    #try with a relu!\n",
    "    #y = tf.maximum( tf.multiply(x, A), 0)\n",
    "    #y = tf.maximum( x, 0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "ty_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch [width, height, input channels, output channels]\n",
    "tW_conv1 = weight_variable([5, 5, 1, 32])\n",
    "tb_conv1 = bias_variable([32]) #number of output bias\n",
    "#4d tensor [ N# batch inputs, width, height, n#channels]\n",
    "tx_image = tf.reshape(tx, [-1, 28, 28, 1])\n",
    "\n",
    "thconv1 = conv2d(tx_image, tW_conv1) + tb_conv1\n",
    "#thconv1 = tf.Print(thconv1, [thconv1.shape])\n",
    "shape1 = [28, 28, 1, 32 ]\n",
    "A1,B1,SAT1,W1 = create_tuning_neuron_2d(shape1, saturation=[0.8,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ones_2:0' shape=(784,) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_conv1 = evaluate_tuning_neuron(shape1, A1,B1,SAT1,W1, thconv1)\n",
    "# th_conv1 = tf.Print(th_conv1, [th_conv1.shape])\n",
    "th_pool1 = max_pool_2x2(th_conv1)\n",
    "\n",
    "# th_conv1 = tf.nn.relu(conv2d(tx_image, tW_conv1) + tb_conv1)\n",
    "# th_pool1 = max_pool_2x2(th_conv1)\n",
    "# th_pool1 = tf.Print(th_pool1, [th_pool1.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose_1:0' shape=(?, 28, 28, 32) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool:0' shape=(?, 14, 14, 32) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_pool1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tW_conv2 = weight_variable([5, 5, 32, 64])\n",
    "tb_conv2 = bias_variable([64])\n",
    "\n",
    "# thconv2 = conv2d(th_pool1, tW_conv2) + tb_conv2\n",
    "# (a, b, sat, W, x, th_conv2, y_ )= create_tuning_neuron_2d([14, 14, 1, 64], thconv2,\n",
    "#                                                    saturation=[0.8,10])\n",
    "# th_pool2 = max_pool_2x2(th_conv2)\n",
    "\n",
    "# shape2 = [14, 14, 1, 64 ]\n",
    "# A2,B2,SAT2,W2 = create_tuning_neuron_2d(shape2, saturation=[0.8,10])\n",
    "# th_conv2 = evaluate_tuning_neuron(shape2, A2,B2,SAT2,W2, thconv2)\n",
    "# th_conv2 = tf.Print(th_conv1, [th_conv1.shape])\n",
    "# th_pool2 = max_pool_2x2(th_conv2)\n",
    "\n",
    "th_conv2 = tf.nn.relu(conv2d(th_pool1, tW_conv2) + tb_conv2)\n",
    "th_pool2 = max_pool_2x2(th_conv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_1:0' shape=(?, 7, 7, 64) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_pool2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Densely connected layer\n",
    "tW_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "tb_fc1 = bias_variable([1024])\n",
    "\n",
    "th_pool2_flat = tf.reshape(th_pool2, [-1, 7*7*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_5:0' shape=(?, 3136) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_pool2_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is HERE that I have to replace by my Tuning Neurons\n",
    "\n",
    "# thconv1 = conv2d(tx_image, tW_conv1) + tb_conv1\n",
    "# (a, b, sat, W, x, th_conv1, y_ )= create_tuning_neuron_2d([28, 28, 1, 32 ], \n",
    "#                                                           thconv1, saturation=[0.8,10])\n",
    "# th_pool1 = max_pool_2x2(th_conv1)\n",
    "\n",
    "th_fc1 = tf.nn.relu(tf.matmul(th_pool2_flat, tW_fc1) + tb_fc1)\n",
    "\n",
    "#Dropout\n",
    "\n",
    "tkeep_prob = tf.placeholder(tf.float32)\n",
    "th_fc1_drop = tf.nn.dropout(th_fc1, tkeep_prob)\n",
    "\n",
    "#Readout Layer\n",
    "\n",
    "tW_fc2 = weight_variable([1024, 10])\n",
    "tb_fc2 = bias_variable([10])\n",
    "\n",
    "ty_conv = tf.matmul(th_fc1_drop, tW_fc2) + tb_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=ty_, logits=ty_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(ty_conv, 1), tf.argmax(ty_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=ty_, logits=ty_conv))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# for _ in range(1000):\n",
    "#   batch = mnist.train.next_batch(batch_size)\n",
    "#   train_step.run(feed_dict={tx: batch[0], ty_: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 1600 values, but the requested shape requires a multiple of 25088\n\t [[Node: Reshape_4 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Maximum, Reshape_4/shape)]]\n\nCaused by op 'Reshape_4', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-492fec871f5e>\", line 1, in <module>\n    th_conv1 = evaluate_tuning_neuron(shape1, A1,B1,SAT1,W1, thconv1)\n  File \"<ipython-input-8-bd771c4d9244>\", line 23, in evaluate_tuning_neuron\n    y = tf.transpose(tf.reshape(yb, [-1, output_channels, height, width]), perm=[0,2,3,1])\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2619, in reshape\n    name=name)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 1600 values, but the requested shape requires a multiple of 25088\n\t [[Node: Reshape_4 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Maximum, Reshape_4/shape)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 1600 values, but the requested shape requires a multiple of 25088\n\t [[Node: Reshape_4 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Maximum, Reshape_4/shape)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1742\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m     \"\"\"\n\u001b[0;32m-> 1744\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4118\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4119\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4120\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 1600 values, but the requested shape requires a multiple of 25088\n\t [[Node: Reshape_4 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Maximum, Reshape_4/shape)]]\n\nCaused by op 'Reshape_4', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-492fec871f5e>\", line 1, in <module>\n    th_conv1 = evaluate_tuning_neuron(shape1, A1,B1,SAT1,W1, thconv1)\n  File \"<ipython-input-8-bd771c4d9244>\", line 23, in evaluate_tuning_neuron\n    y = tf.transpose(tf.reshape(yb, [-1, output_channels, height, width]), perm=[0,2,3,1])\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2619, in reshape\n    name=name)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/leo/DeepLearning/venv3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 1600 values, but the requested shape requires a multiple of 25088\n\t [[Node: Reshape_4 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Maximum, Reshape_4/shape)]]\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(2000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i>0 and i % 100 == 0:\n",
    "      train_accuracy = accuracy.eval(feed_dict={\n",
    "          tx: batch[0], ty_: batch[1], tkeep_prob: 1.0})\n",
    "      print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "      if(train_accuracy > 0.999):\n",
    "        break\n",
    "    train_step.run(feed_dict={tx: batch[0], ty_: batch[1], tkeep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results seem completely random, as if it was creating a NEW encoding each time ???\n",
    "\n",
    "I really don't understand it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d109304490f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m print('test accuracy %g' % accuracy.eval(feed_dict={\n\u001b[0;32m----> 3\u001b[0;31m x: mnist.test.images, y_: mnist.test.labels, tkeep_prob: 1.0}))\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "x: mnist.test.images, y_: mnist.test.labels, tkeep_prob: 1.0}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still with issues about the dimensions:\n",
    "\n",
    "    InvalidArgumentError: In[0].dim(0) and In[1].dim(0) must be the same: [10000,32,784] vs [1,784,784]\n",
    "         [[Node: MatMul_3 = BatchMatMul[T=DT_FLOAT, adj_x=false, adj_y=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](transpose, Reshape_9)]]\n",
    "         [[Node: Mean_3/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_239_Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
    "\n",
    "    During handling of the above exception, another exception occurred:\n",
    "    \n",
    "After this I must check on HOW to do the correct things for the trainings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = sess.run(tf.trainable_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in zip([v.name for v in tf.trainable_variables()], vals):\n",
    "    print (\"var: \"+k+\" = \"+str(v.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
