{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Tests for Part Of Speech tagging\n",
    "\n",
    "This notebook is dedicated to start working with the PoS dataset already pre-processed and the column networks that I'm creating.\n",
    "\n",
    "The network will be constructed from small parts, each will be trained on top of the previous one, adding a new column and decoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Loading faiss with AVX2 support.\n",
      "Loading faiss.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from langmodels.models import *\n",
    "import langmodels.utf8codec as utf8codec\n",
    "from langmodels.utils.tools import *\n",
    "from langmodels.utils.helpers import *\n",
    "from langmodels.utils.preprocess_conllu import *\n",
    "from langmodels.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/leo/projects/minibrain/predictors/sequence/text/utf8-codes/utf8_codebook_overfit_matrix_2seg_dim64.npy'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcodebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utf8codes = np.load(fcodebook)\n",
    "utf8codes = utf8codes.reshape(1987, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GatedConv1DPoS(utf8codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained from saved Conv1D model\n",
    "model.network.old_load_model(\"./trained_models/conv1dcol/\",\"conv1dcol_nll-loss_epoch-79_001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Timestamp 2019-11-29 16:14:19.379404 Epoch: 1 Average loss: 0.01313078\n",
      "====> Timestamp 2019-11-29 16:16:10.513596 Epoch: 2 Average loss: 0.00784747\n",
      "====> Timestamp 2019-11-29 16:18:01.780184 Epoch: 3 Average loss: 0.00737822\n",
      "====> Timestamp 2019-11-29 16:19:53.327939 Epoch: 4 Average loss: 0.00681860\n",
      "====> Timestamp 2019-11-29 16:21:44.910042 Epoch: 5 Average loss: 0.00653033\n",
      "====> Timestamp 2019-11-29 16:23:36.287940 Epoch: 6 Average loss: 0.00623974\n",
      "====> Timestamp 2019-11-29 16:25:27.709583 Epoch: 7 Average loss: 0.00601973\n",
      "====> Timestamp 2019-11-29 16:27:19.147079 Epoch: 8 Average loss: 0.00554546\n",
      "====> Timestamp 2019-11-29 16:29:09.132243 Epoch: 9 Average loss: 0.00530290\n",
      "====> Timestamp 2019-11-29 16:31:01.551584 Epoch: 10 Average loss: 0.00532029\n",
      "====> Timestamp 2019-11-29 16:32:55.329889 Epoch: 11 Average loss: 0.00521510\n",
      "====> Timestamp 2019-11-29 16:34:49.958010 Epoch: 12 Average loss: 0.00502656\n",
      "====> Timestamp 2019-11-29 16:36:44.820244 Epoch: 13 Average loss: 0.00486095\n",
      "====> Timestamp 2019-11-29 16:38:45.730967 Epoch: 14 Average loss: 0.00478796\n",
      "====> Timestamp 2019-11-29 16:40:46.174842 Epoch: 15 Average loss: 0.00480084\n",
      "====> Timestamp 2019-11-29 16:42:49.440767 Epoch: 16 Average loss: 0.00468916\n",
      "====> Timestamp 2019-11-29 16:44:53.018543 Epoch: 17 Average loss: 0.00464971\n",
      "====> Timestamp 2019-11-29 16:46:57.341347 Epoch: 18 Average loss: 0.00463995\n",
      "====> Timestamp 2019-11-29 16:49:01.601886 Epoch: 19 Average loss: 0.00454721\n",
      "====> Timestamp 2019-11-29 16:51:05.208722 Epoch: 20 Average loss: 0.00450722\n",
      "====> Timestamp 2019-11-29 16:53:08.858344 Epoch: 21 Average loss: 0.00447133\n",
      "====> Timestamp 2019-11-29 16:55:12.289461 Epoch: 22 Average loss: 0.00444278\n",
      "====> Timestamp 2019-11-29 16:57:16.569099 Epoch: 23 Average loss: 0.00436767\n",
      "====> Timestamp 2019-11-29 16:59:20.230881 Epoch: 24 Average loss: 0.00439947\n",
      "====> Timestamp 2019-11-29 17:01:23.451417 Epoch: 25 Average loss: 0.00429408\n",
      "====> Timestamp 2019-11-29 17:03:26.619034 Epoch: 26 Average loss: 0.00427034\n",
      "====> Timestamp 2019-11-29 17:05:29.655144 Epoch: 27 Average loss: 0.00416195\n",
      "====> Timestamp 2019-11-29 17:07:32.953006 Epoch: 28 Average loss: 0.00414419\n",
      "====> Timestamp 2019-11-29 17:09:36.203661 Epoch: 29 Average loss: 0.00412225\n",
      "====> Timestamp 2019-11-29 17:11:39.816451 Epoch: 30 Average loss: 0.00408560\n",
      "====> Timestamp 2019-11-29 17:13:43.834654 Epoch: 31 Average loss: 0.00420661\n",
      "====> Timestamp 2019-11-29 17:15:47.306453 Epoch: 32 Average loss: 0.00413180\n",
      "====> Timestamp 2019-11-29 17:17:51.991442 Epoch: 33 Average loss: 0.00416178\n",
      "====> Timestamp 2019-11-29 17:19:56.302805 Epoch: 34 Average loss: 0.00414349\n",
      "====> Timestamp 2019-11-29 17:21:59.861755 Epoch: 35 Average loss: 0.00399642\n",
      "====> Timestamp 2019-11-29 17:24:03.398213 Epoch: 36 Average loss: 0.00394921\n",
      "====> Timestamp 2019-11-29 17:26:06.442414 Epoch: 37 Average loss: 0.00404875\n",
      "====> Timestamp 2019-11-29 17:28:08.668843 Epoch: 38 Average loss: 0.00389179\n",
      "====> Timestamp 2019-11-29 17:30:09.374627 Epoch: 39 Average loss: 0.00393752\n",
      "====> Timestamp 2019-11-29 17:32:08.514505 Epoch: 40 Average loss: 0.00405794\n",
      "====> Timestamp 2019-11-29 17:34:07.465419 Epoch: 41 Average loss: 0.00397271\n",
      "====> Timestamp 2019-11-29 17:36:08.036297 Epoch: 42 Average loss: 0.00394212\n",
      "====> Timestamp 2019-11-29 17:38:07.228637 Epoch: 43 Average loss: 0.00408144\n",
      "====> Timestamp 2019-11-29 17:40:07.444354 Epoch: 44 Average loss: 0.00393038\n",
      "====> Timestamp 2019-11-29 17:42:06.159148 Epoch: 45 Average loss: 0.00378420\n",
      "====> Timestamp 2019-11-29 17:44:05.336763 Epoch: 46 Average loss: 0.00380641\n",
      "====> Timestamp 2019-11-29 17:46:04.634598 Epoch: 47 Average loss: 0.00377743\n",
      "====> Timestamp 2019-11-29 17:48:04.319104 Epoch: 48 Average loss: 0.00380100\n",
      "====> Timestamp 2019-11-29 17:50:04.231873 Epoch: 49 Average loss: 0.00385157\n",
      "====> Timestamp 2019-11-29 17:52:04.101629 Epoch: 50 Average loss: 0.00384689\n",
      "====> Timestamp 2019-11-29 17:54:05.446429 Epoch: 51 Average loss: 0.00390029\n",
      "====> Timestamp 2019-11-29 17:56:08.580940 Epoch: 52 Average loss: 0.00398549\n",
      "====> Timestamp 2019-11-29 17:58:08.314928 Epoch: 53 Average loss: 0.00394213\n",
      "====> Timestamp 2019-11-29 18:00:07.886884 Epoch: 54 Average loss: 0.00407076\n",
      "====> Timestamp 2019-11-29 18:02:07.182727 Epoch: 55 Average loss: 0.00403257\n",
      "====> Timestamp 2019-11-29 18:04:02.108188 Epoch: 56 Average loss: 0.00396269\n",
      "====> Timestamp 2019-11-29 18:05:55.800496 Epoch: 57 Average loss: 0.00397728\n",
      "====> Timestamp 2019-11-29 18:07:53.065305 Epoch: 58 Average loss: 0.00396002\n",
      "====> Timestamp 2019-11-29 18:09:49.563529 Epoch: 59 Average loss: 0.00381392\n",
      "====> Timestamp 2019-11-29 18:11:44.605660 Epoch: 60 Average loss: 0.00386852\n",
      "====> Timestamp 2019-11-29 18:13:39.317923 Epoch: 61 Average loss: 0.00389522\n",
      "====> Timestamp 2019-11-29 18:15:32.284445 Epoch: 62 Average loss: 0.00391524\n",
      "====> Timestamp 2019-11-29 18:17:25.203962 Epoch: 63 Average loss: 0.00389671\n",
      "====> Timestamp 2019-11-29 18:19:18.128487 Epoch: 64 Average loss: 0.00390530\n",
      "====> Timestamp 2019-11-29 18:21:12.593129 Epoch: 65 Average loss: 0.00399719\n",
      "====> Timestamp 2019-11-29 18:23:06.660676 Epoch: 66 Average loss: 0.00389038\n",
      "====> Timestamp 2019-11-29 18:25:00.018603 Epoch: 67 Average loss: 0.00389344\n",
      "====> Timestamp 2019-11-29 18:26:54.881882 Epoch: 68 Average loss: 0.00408376\n",
      "====> Timestamp 2019-11-29 18:28:48.679303 Epoch: 69 Average loss: 0.00408623\n",
      "====> Timestamp 2019-11-29 18:30:44.327502 Epoch: 70 Average loss: 0.00397204\n",
      "====> Timestamp 2019-11-29 18:32:38.716022 Epoch: 71 Average loss: 0.00407150\n",
      "====> Timestamp 2019-11-29 18:34:33.328927 Epoch: 72 Average loss: 0.00450079\n",
      "====> Timestamp 2019-11-29 18:36:30.682487 Epoch: 73 Average loss: 0.00423831\n",
      "====> Timestamp 2019-11-29 18:38:24.698447 Epoch: 74 Average loss: 0.00415385\n",
      "====> Timestamp 2019-11-29 18:40:16.473667 Epoch: 75 Average loss: 0.00399821\n",
      "====> Timestamp 2019-11-29 18:42:09.480456 Epoch: 76 Average loss: 0.00409125\n",
      "====> Timestamp 2019-11-29 18:44:03.329465 Epoch: 77 Average loss: 0.00410107\n",
      "====> Timestamp 2019-11-29 18:45:43.950431 Epoch: 78 Average loss: 0.00369665\n",
      "CPU times: user 1h 35min 11s, sys: 56min 16s, total: 2h 31min 28s\n",
      "Wall time: 2h 33min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = \"./trained_models/GatedConv1DCol\"\n",
    "base_name = \"GatedConv1DPoS_nll-loss\"\n",
    "train_test(model, path, base_name, max_data=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42101760"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75497472"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42101760"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54525952"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
