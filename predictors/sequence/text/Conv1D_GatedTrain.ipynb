{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Tests for Part Of Speech tagging\n",
    "\n",
    "This notebook is dedicated to start working with the PoS dataset already pre-processed and the column networks that I'm creating.\n",
    "\n",
    "The network will be constructed from small parts, each will be trained on top of the previous one, adding a new column and decoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Loading faiss with AVX2 support.\n",
      "Loading faiss.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from langmodels.models import *\n",
    "import langmodels.utf8codec as utf8codec\n",
    "from langmodels.utils.tools import *\n",
    "from langmodels.utils.preprocess_conllu import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the embeddings first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the codebook and all the dictionaries mapping the data\n",
    "# utf8codes, txt2code, code2txt, txt2num, num2txt = utf8codec._load_codebook()\n",
    "utf8codes = np.load(\"./utf8-codes/utf8_codebook_overfit_matrix_2seg_dim64.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utf8codes = utf8codes.reshape(1987,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Conv1DPoS(utf8codes)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1949540"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the original network 11266152 parameters, I have cut the number of features and dimensions to make it smaller\n",
    "\n",
    "for nlayers = 5 of dim 5 is 6912424 and 6846888 trainable\n",
    "\n",
    "for the following Conv1DPartOfSpeech the number of parameters is: 2161960 where 2096424 are trainable\n",
    "\n",
    "    nchannels_in=[64, 128, 256, 512, 256],\n",
    "    nchannels_out=[128, 256, 512, 256, 96],\n",
    "    kernels=[3, 3, 3, 3, 3],\n",
    "    nlayers=[6, 6, 4, 4, 3],\n",
    "    groups=[1, 4, 8, 4, 1],\n",
    "    \n",
    "And LinearUposDeprelDecoder params are:\n",
    "\n",
    "    lin_in_dim=96, \n",
    "    lin_hidd_dim=768,\n",
    "    upos_dim=18, \n",
    "    deprel_dim=278,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1884004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets are the one that are heavy, so I'll just load them and check what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = \"/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/traindev_np_batches_779000x3x1024_uint16.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.load(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779000, 3, 1024)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint16')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta_train_txt = data_train[:,0,:]\n",
    "dta_train_upos = data_train[:,1,:]\n",
    "dta_train_deprel = data_train[:,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.from_numpy(dta_train_txt[:50].astype(\"int64\")).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txtcode, positions, latent, dec = net(x)\n",
    "# last_latent = latent[-1]\n",
    "# upos, deprel = dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txtcode.shape, positions.shape, last_latent.shape, upos.shape, #  deprel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = torch.cat([upos,deprel], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upos and deprel data are given by indices, this keeps memory as low as possible, but they need to be encoded\n",
    "upos_eye = torch.eye(len(UPOS))\n",
    "deprel_eye = torch.eye(len(DEPREL))\n",
    "with torch.no_grad():\n",
    "    upos_emb = nn.Embedding(*upos_eye.shape)\n",
    "    upos_emb.weight.data.copy_(upos_eye)\n",
    "    upos_emb = upos_emb.to(device)\n",
    "\n",
    "    deprel_emb = nn.Embedding(*deprel_eye.shape)\n",
    "    deprel_emb.weight.data.copy_(deprel_eye)\n",
    "    deprel_emb.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "def chunks(data, n, dim=0):\n",
    "    \"\"\"Yield successive n-sized chunks from data by the dimension dim\"\"\"\n",
    "    for i in range(0, data.shape[dim], n):\n",
    "        yield data[i:i + n,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(upos, deprel, target_upos, target_deprel):\n",
    "\n",
    "    # TODO check a more sofisticated loss function, for the moment only the sum to see if it runs\n",
    "    # the issue is that upos is easier than deprel (18 vs 278 classes)\n",
    "#     upos_loss = F.mse_loss(upos, target_upos)\n",
    "#     deprel_loss = F.mse_loss(deprel, target_deprel)\n",
    "    # issue with the size of target and tensors for cross_entropy ... I don't understand\n",
    "#     upos_loss = F.cross_entropy(upos, target_upos)\n",
    "#     deprel_loss = F.cross_entropy(deprel, target_deprel)\n",
    "#     print(upos.shape, target_upos.shape, deprel.shape, target_deprel.shape)\n",
    "    upos_loss = F.nll_loss(upos, target_upos)\n",
    "    deprel_loss = F.nll_loss(deprel, target_deprel)\n",
    "#     upos_loss = F.kl_div(upos, target_upos)\n",
    "#     deprel_loss = F.kl_div(deprel, target_deprel)\n",
    "    loss = upos_loss + deprel_loss\n",
    "#     loss = F.kl_div(torch.cat([upos, deprel], dim=-1).contiguous(), torch.cat([target_upos, target_deprel], dim=-1).contiguous())\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indata = torch.from_numpy(data_train[-2:,0,:].astype(\"int64\")).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# testing tensorboard add_graph to see if the network graph is drawn correctly ;)\n",
    "# indata = torch.from_numpy(data_train[-2:,0,:].astype(\"int64\")).to(device)\n",
    "# writer.add_graph(net, indata)\n",
    "# Kernel dies when I do this ... so ... :O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_function, batches, epoch, ndatapoints, device, log_interval=100):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "#     batch_loss = []\n",
    "    batch_idx = 1\n",
    "    for b_data in batches:\n",
    "        torch.cuda.empty_cache()  # make sure the cache is emptied to begin the nexxt batch\n",
    "        b_train = torch.from_numpy(b_data[:,0,:].astype(\"int64\")).squeeze().to(device).long()\n",
    "        b_upos = torch.from_numpy(b_data[:,1,:].astype(\"int64\")).squeeze().to(device).long()\n",
    "#         b_deprel = torch.from_numpy(b_data[:,2,:].astype(\"int64\")).squeeze().to(device).long()\n",
    "#         tensor_data = torch.from_numpy(bdata).to(device).long()  #.double()  #.float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        txtcode, positions, latent, dec = model(b_train)\n",
    "        last_latent = latent[-1]\n",
    "        upos, deprel = dec\n",
    "#         print(emb.shape,emb.dtype, res.shape, res.dtype)\n",
    "#         print(upos.shape, b_upos.shape)\n",
    "#         loss = loss_function(upos, deprel, upos_emb(b_upos), deprel_emb(b_deprel))\n",
    "#         loss = loss_function(upos, deprel, b_upos, b_deprel)\n",
    "        # Untill I make it work, work only with the UPOS PoS as it will be faster MUCH faster\n",
    "#         loss = F.kl_div(upos, upos_emb(b_upos), reduction=\"batchmean\")\n",
    "        loss = F.nll_loss(upos.view([-1,18]),b_upos.view([-1]))\n",
    "#         loss = F.cross_entropy(upos.view([-1,18]),b_upos.view([-1]))\n",
    "#         loss = F.cross_entropy(upos,b_upos)\n",
    "#         loss = F.mse_loss(upos, upos_emb(b_upos))\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.data.item()  # [0]\n",
    "        writer.add_scalar(\"Loss/train\", loss.data.item(), global_step=epoch*batch_idx)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Timestamp {} Train Epoch: {} [{}/{} ]\\tLoss: {:.6f}'.format(\n",
    "                datetime.now(),\n",
    "                epoch, batch_idx , (ndatapoints//len(b_data)),\n",
    "                loss.data.item() / b_data.shape[0]))\n",
    "#             batch_loss.append(loss)\n",
    "        batch_idx += 1\n",
    "        del(b_train)\n",
    "        del(b_upos)\n",
    "#         del(b_deprel)\n",
    "        torch.cuda.empty_cache()\n",
    "    writer.add_scalar(\"EpochLoss/train\", train_loss / batch_idx, epoch)\n",
    "    print('====> Timestamp {} Epoch: {} Average loss: {:.8f}'.format(datetime.now(), epoch, train_loss / ndatapoints))\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load testing data ALL the training data\n",
    "base_dir = \"/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4\"\n",
    "# get all file paths for testing\n",
    "all_fnames = get_all_files_recurse(base_dir)\n",
    "fnames = [f for f in all_fnames if \"test-charse\" in f and f.endswith(\".npy\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all test files \n",
    "test_data = []\n",
    "for f in fnames:\n",
    "    data = np.load(f)\n",
    "    lang_name = path_leaf(f).split(\"-ud\")[0]\n",
    "    test_data.append((lang_name, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loss_function, test_data, epoch, device, max_data=100):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for lang, d in test_data:\n",
    "        torch.cuda.empty_cache()  # make sure the cache is emptied to begin the nexxt batch\n",
    "        b_test = torch.from_numpy(d[:max_data,0,:].astype(\"int64\")).squeeze().to(device).long()\n",
    "        b_upos = torch.from_numpy(d[:max_data,1,:].astype(\"int64\")).squeeze().to(device).long()\n",
    "#         b_deprel = torch.from_numpy(d[:,2,:].astype(\"int64\")).squeeze().to(device).long()\n",
    "        _, _, _, dec = model(b_test)\n",
    "#         last_latent = latent[-1]\n",
    "        upos, _ = dec\n",
    "        loss = loss_function(upos.view([-1,18]),b_upos.view([-1]))\n",
    "#         loss =  loss_function(res, tensor_data).data.item()  # [0]\n",
    "        test_loss += loss.data.item()\n",
    "        writer.add_scalar(\"LangLoss/test/\"+lang, loss.data.item(), global_step=epoch)\n",
    "        del(b_test)\n",
    "        del(b_upos)\n",
    "        torch.cuda.empty_cache()\n",
    "    test_loss /= len(test_data)  # although this is not faire as different languages give different results\n",
    "    writer.add_scalar(\"EpochLangLoss/test/\", test_loss, global_step=epoch)\n",
    "    print('epoch: {}====> Test set loss: {:.8f}'.format(epoch, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload model from saved state:\n",
    "# net.network.load_model(\"./trained_models/conv1dcol\", \"conv1dcol_kl-div+1000batches-mse-loss_epoch-3_001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-6, weight_decay=0, amsgrad=False )\n",
    "# optimizer = torch.optim.AdamW(model.parameters())\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((779000, 3, 1024), 15580)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_train.shape[0]//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 10000\n",
    "batch_size = 50\n",
    "# data = data_train[-1000*batch_size:,:,:]  # just for the trials, use the last 1000 batches only\n",
    "data = data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(779000, 3, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = chunks(data, epoch_size, dim=0)\n",
    "# batches = chunks(data, batch_size, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# epoch_count = 0\n",
    "# test(model, loss_function, test_data, epoch_count, device, max_data=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp 2019-11-27 19:52:25.851542 Train Epoch: 1 [10/200 ]\tLoss: 0.000960\n",
      "Timestamp 2019-11-27 19:52:28.203686 Train Epoch: 1 [20/200 ]\tLoss: 0.001140\n",
      "Timestamp 2019-11-27 19:52:30.547525 Train Epoch: 1 [30/200 ]\tLoss: 0.001090\n",
      "Timestamp 2019-11-27 19:52:32.921625 Train Epoch: 1 [40/200 ]\tLoss: 0.001542\n",
      "Timestamp 2019-11-27 19:52:35.273168 Train Epoch: 1 [50/200 ]\tLoss: 0.001165\n",
      "Timestamp 2019-11-27 19:52:37.623825 Train Epoch: 1 [60/200 ]\tLoss: 0.001330\n",
      "Timestamp 2019-11-27 19:52:39.991177 Train Epoch: 1 [70/200 ]\tLoss: 0.001307\n",
      "Timestamp 2019-11-27 19:52:42.331851 Train Epoch: 1 [80/200 ]\tLoss: 0.001120\n",
      "Timestamp 2019-11-27 19:52:44.666896 Train Epoch: 1 [90/200 ]\tLoss: 0.001170\n",
      "Timestamp 2019-11-27 19:52:47.013404 Train Epoch: 1 [100/200 ]\tLoss: 0.001357\n",
      "Timestamp 2019-11-27 19:52:49.385902 Train Epoch: 1 [110/200 ]\tLoss: 0.001010\n",
      "Timestamp 2019-11-27 19:52:51.718984 Train Epoch: 1 [120/200 ]\tLoss: 0.000937\n",
      "Timestamp 2019-11-27 19:52:54.079247 Train Epoch: 1 [130/200 ]\tLoss: 0.001263\n",
      "Timestamp 2019-11-27 19:52:56.448857 Train Epoch: 1 [140/200 ]\tLoss: 0.001201\n",
      "Timestamp 2019-11-27 19:52:58.884581 Train Epoch: 1 [150/200 ]\tLoss: 0.001304\n",
      "Timestamp 2019-11-27 19:53:01.267496 Train Epoch: 1 [160/200 ]\tLoss: 0.001653\n",
      "Timestamp 2019-11-27 19:53:03.776084 Train Epoch: 1 [170/200 ]\tLoss: 0.001288\n",
      "Timestamp 2019-11-27 19:53:06.152787 Train Epoch: 1 [180/200 ]\tLoss: 0.001050\n",
      "Timestamp 2019-11-27 19:53:08.478890 Train Epoch: 1 [190/200 ]\tLoss: 0.001466\n",
      "Timestamp 2019-11-27 19:53:10.861343 Train Epoch: 1 [200/200 ]\tLoss: 0.001347\n",
      "====> Timestamp 2019-11-27 19:53:10.903071 Epoch: 1 Average loss: 0.00125348\n",
      "epoch: 1====> Test set loss: 0.13905613\n",
      "Timestamp 2019-11-27 19:53:24.747214 Train Epoch: 2 [10/200 ]\tLoss: 0.000972\n",
      "Timestamp 2019-11-27 19:53:27.197281 Train Epoch: 2 [20/200 ]\tLoss: 0.001134\n",
      "Timestamp 2019-11-27 19:53:29.676031 Train Epoch: 2 [30/200 ]\tLoss: 0.001097\n",
      "Timestamp 2019-11-27 19:53:32.152306 Train Epoch: 2 [40/200 ]\tLoss: 0.001466\n",
      "Timestamp 2019-11-27 19:53:34.645786 Train Epoch: 2 [50/200 ]\tLoss: 0.001194\n",
      "Timestamp 2019-11-27 19:53:37.119778 Train Epoch: 2 [60/200 ]\tLoss: 0.001326\n",
      "Timestamp 2019-11-27 19:53:39.611473 Train Epoch: 2 [70/200 ]\tLoss: 0.001287\n",
      "Timestamp 2019-11-27 19:53:42.091800 Train Epoch: 2 [80/200 ]\tLoss: 0.001159\n",
      "Timestamp 2019-11-27 19:53:44.562636 Train Epoch: 2 [90/200 ]\tLoss: 0.001110\n",
      "Timestamp 2019-11-27 19:53:46.959460 Train Epoch: 2 [100/200 ]\tLoss: 0.001315\n",
      "Timestamp 2019-11-27 19:53:49.364927 Train Epoch: 2 [110/200 ]\tLoss: 0.000995\n",
      "Timestamp 2019-11-27 19:53:51.765121 Train Epoch: 2 [120/200 ]\tLoss: 0.000914\n",
      "Timestamp 2019-11-27 19:53:54.123337 Train Epoch: 2 [130/200 ]\tLoss: 0.001203\n",
      "Timestamp 2019-11-27 19:53:56.525480 Train Epoch: 2 [140/200 ]\tLoss: 0.001205\n",
      "Timestamp 2019-11-27 19:53:58.956482 Train Epoch: 2 [150/200 ]\tLoss: 0.001265\n",
      "Timestamp 2019-11-27 19:54:01.449886 Train Epoch: 2 [160/200 ]\tLoss: 0.001626\n",
      "Timestamp 2019-11-27 19:54:03.917860 Train Epoch: 2 [170/200 ]\tLoss: 0.001302\n",
      "Timestamp 2019-11-27 19:54:06.386148 Train Epoch: 2 [180/200 ]\tLoss: 0.001070\n",
      "Timestamp 2019-11-27 19:54:08.886580 Train Epoch: 2 [190/200 ]\tLoss: 0.001478\n",
      "Timestamp 2019-11-27 19:54:11.376510 Train Epoch: 2 [200/200 ]\tLoss: 0.001294\n",
      "====> Timestamp 2019-11-27 19:54:11.419335 Epoch: 2 Average loss: 0.00124046\n",
      "epoch: 2====> Test set loss: 0.13796692\n",
      "Timestamp 2019-11-27 19:54:25.406344 Train Epoch: 3 [10/200 ]\tLoss: 0.000943\n",
      "Timestamp 2019-11-27 19:54:27.795456 Train Epoch: 3 [20/200 ]\tLoss: 0.001088\n",
      "Timestamp 2019-11-27 19:54:30.225888 Train Epoch: 3 [30/200 ]\tLoss: 0.001072\n",
      "Timestamp 2019-11-27 19:54:32.666322 Train Epoch: 3 [40/200 ]\tLoss: 0.001473\n",
      "Timestamp 2019-11-27 19:54:35.050014 Train Epoch: 3 [50/200 ]\tLoss: 0.001125\n",
      "Timestamp 2019-11-27 19:54:37.525400 Train Epoch: 3 [60/200 ]\tLoss: 0.001282\n",
      "Timestamp 2019-11-27 19:54:39.893466 Train Epoch: 3 [70/200 ]\tLoss: 0.001277\n",
      "Timestamp 2019-11-27 19:54:42.276084 Train Epoch: 3 [80/200 ]\tLoss: 0.001138\n",
      "Timestamp 2019-11-27 19:54:44.619310 Train Epoch: 3 [90/200 ]\tLoss: 0.001096\n",
      "Timestamp 2019-11-27 19:54:47.068936 Train Epoch: 3 [100/200 ]\tLoss: 0.001286\n",
      "Timestamp 2019-11-27 19:54:49.549955 Train Epoch: 3 [110/200 ]\tLoss: 0.001014\n",
      "Timestamp 2019-11-27 19:54:52.036634 Train Epoch: 3 [120/200 ]\tLoss: 0.000877\n",
      "Timestamp 2019-11-27 19:54:54.466844 Train Epoch: 3 [130/200 ]\tLoss: 0.001219\n",
      "Timestamp 2019-11-27 19:54:56.887183 Train Epoch: 3 [140/200 ]\tLoss: 0.001183\n",
      "Timestamp 2019-11-27 19:54:59.359989 Train Epoch: 3 [150/200 ]\tLoss: 0.001252\n",
      "Timestamp 2019-11-27 19:55:01.814206 Train Epoch: 3 [160/200 ]\tLoss: 0.001601\n",
      "Timestamp 2019-11-27 19:55:04.281784 Train Epoch: 3 [170/200 ]\tLoss: 0.001264\n",
      "Timestamp 2019-11-27 19:55:06.673355 Train Epoch: 3 [180/200 ]\tLoss: 0.001032\n",
      "Timestamp 2019-11-27 19:55:09.077808 Train Epoch: 3 [190/200 ]\tLoss: 0.001417\n",
      "Timestamp 2019-11-27 19:55:11.510851 Train Epoch: 3 [200/200 ]\tLoss: 0.001362\n",
      "====> Timestamp 2019-11-27 19:55:11.552439 Epoch: 3 Average loss: 0.00123332\n",
      "epoch: 3====> Test set loss: 0.13923354\n",
      "Timestamp 2019-11-27 19:55:25.662518 Train Epoch: 4 [10/200 ]\tLoss: 0.000918\n",
      "Timestamp 2019-11-27 19:55:28.127872 Train Epoch: 4 [20/200 ]\tLoss: 0.001135\n",
      "Timestamp 2019-11-27 19:55:30.600830 Train Epoch: 4 [30/200 ]\tLoss: 0.001101\n",
      "Timestamp 2019-11-27 19:55:33.091305 Train Epoch: 4 [40/200 ]\tLoss: 0.001482\n",
      "Timestamp 2019-11-27 19:55:35.591940 Train Epoch: 4 [50/200 ]\tLoss: 0.001123\n",
      "Timestamp 2019-11-27 19:55:38.084230 Train Epoch: 4 [60/200 ]\tLoss: 0.001244\n",
      "Timestamp 2019-11-27 19:55:40.507034 Train Epoch: 4 [70/200 ]\tLoss: 0.001292\n",
      "Timestamp 2019-11-27 19:55:42.885951 Train Epoch: 4 [80/200 ]\tLoss: 0.001127\n",
      "Timestamp 2019-11-27 19:55:45.344934 Train Epoch: 4 [90/200 ]\tLoss: 0.001070\n",
      "Timestamp 2019-11-27 19:55:47.814168 Train Epoch: 4 [100/200 ]\tLoss: 0.001304\n",
      "Timestamp 2019-11-27 19:55:50.174923 Train Epoch: 4 [110/200 ]\tLoss: 0.001014\n",
      "Timestamp 2019-11-27 19:55:52.523441 Train Epoch: 4 [120/200 ]\tLoss: 0.000895\n",
      "Timestamp 2019-11-27 19:55:54.962513 Train Epoch: 4 [130/200 ]\tLoss: 0.001187\n",
      "Timestamp 2019-11-27 19:55:57.332281 Train Epoch: 4 [140/200 ]\tLoss: 0.001154\n",
      "Timestamp 2019-11-27 19:55:59.724111 Train Epoch: 4 [150/200 ]\tLoss: 0.001283\n",
      "Timestamp 2019-11-27 19:56:02.195124 Train Epoch: 4 [160/200 ]\tLoss: 0.001587\n",
      "Timestamp 2019-11-27 19:56:04.600150 Train Epoch: 4 [170/200 ]\tLoss: 0.001287\n",
      "Timestamp 2019-11-27 19:56:06.990081 Train Epoch: 4 [180/200 ]\tLoss: 0.001005\n",
      "Timestamp 2019-11-27 19:56:09.456177 Train Epoch: 4 [190/200 ]\tLoss: 0.001458\n",
      "Timestamp 2019-11-27 19:56:11.815914 Train Epoch: 4 [200/200 ]\tLoss: 0.001345\n",
      "====> Timestamp 2019-11-27 19:56:11.859794 Epoch: 4 Average loss: 0.00122189\n",
      "epoch: 4====> Test set loss: 0.13932411\n",
      "Timestamp 2019-11-27 19:56:25.763418 Train Epoch: 5 [10/200 ]\tLoss: 0.000923\n",
      "Timestamp 2019-11-27 19:56:28.228642 Train Epoch: 5 [20/200 ]\tLoss: 0.001083\n",
      "Timestamp 2019-11-27 19:56:30.710989 Train Epoch: 5 [30/200 ]\tLoss: 0.001070\n",
      "Timestamp 2019-11-27 19:56:33.130289 Train Epoch: 5 [40/200 ]\tLoss: 0.001448\n",
      "Timestamp 2019-11-27 19:56:35.517730 Train Epoch: 5 [50/200 ]\tLoss: 0.001136\n",
      "Timestamp 2019-11-27 19:56:37.963043 Train Epoch: 5 [60/200 ]\tLoss: 0.001292\n",
      "Timestamp 2019-11-27 19:56:40.392473 Train Epoch: 5 [70/200 ]\tLoss: 0.001263\n",
      "Timestamp 2019-11-27 19:56:42.856293 Train Epoch: 5 [80/200 ]\tLoss: 0.001141\n",
      "Timestamp 2019-11-27 19:56:45.260955 Train Epoch: 5 [90/200 ]\tLoss: 0.001063\n",
      "Timestamp 2019-11-27 19:56:47.766707 Train Epoch: 5 [100/200 ]\tLoss: 0.001305\n",
      "Timestamp 2019-11-27 19:56:50.144264 Train Epoch: 5 [110/200 ]\tLoss: 0.000977\n",
      "Timestamp 2019-11-27 19:56:52.506491 Train Epoch: 5 [120/200 ]\tLoss: 0.000918\n",
      "Timestamp 2019-11-27 19:56:54.867020 Train Epoch: 5 [130/200 ]\tLoss: 0.001222\n",
      "Timestamp 2019-11-27 19:56:57.235593 Train Epoch: 5 [140/200 ]\tLoss: 0.001161\n",
      "Timestamp 2019-11-27 19:56:59.602085 Train Epoch: 5 [150/200 ]\tLoss: 0.001239\n",
      "Timestamp 2019-11-27 19:57:02.035447 Train Epoch: 5 [160/200 ]\tLoss: 0.001608\n",
      "Timestamp 2019-11-27 19:57:04.502522 Train Epoch: 5 [170/200 ]\tLoss: 0.001264\n",
      "Timestamp 2019-11-27 19:57:06.916917 Train Epoch: 5 [180/200 ]\tLoss: 0.001012\n",
      "Timestamp 2019-11-27 19:57:09.400162 Train Epoch: 5 [190/200 ]\tLoss: 0.001412\n",
      "Timestamp 2019-11-27 19:57:11.793862 Train Epoch: 5 [200/200 ]\tLoss: 0.001341\n",
      "====> Timestamp 2019-11-27 19:57:11.837502 Epoch: 5 Average loss: 0.00121437\n",
      "epoch: 5====> Test set loss: 0.13828734\n",
      "Timestamp 2019-11-27 19:57:25.355435 Train Epoch: 6 [10/200 ]\tLoss: 0.000940\n",
      "Timestamp 2019-11-27 19:57:27.731214 Train Epoch: 6 [20/200 ]\tLoss: 0.001064\n",
      "Timestamp 2019-11-27 19:57:30.116791 Train Epoch: 6 [30/200 ]\tLoss: 0.001078\n",
      "Timestamp 2019-11-27 19:57:32.463677 Train Epoch: 6 [40/200 ]\tLoss: 0.001458\n",
      "Timestamp 2019-11-27 19:57:34.818336 Train Epoch: 6 [50/200 ]\tLoss: 0.001130\n",
      "Timestamp 2019-11-27 19:57:37.173645 Train Epoch: 6 [60/200 ]\tLoss: 0.001273\n",
      "Timestamp 2019-11-27 19:57:39.666390 Train Epoch: 6 [70/200 ]\tLoss: 0.001245\n",
      "Timestamp 2019-11-27 19:57:42.047727 Train Epoch: 6 [80/200 ]\tLoss: 0.001082\n",
      "Timestamp 2019-11-27 19:57:44.467981 Train Epoch: 6 [90/200 ]\tLoss: 0.001026\n",
      "Timestamp 2019-11-27 19:57:46.909382 Train Epoch: 6 [100/200 ]\tLoss: 0.001251\n",
      "Timestamp 2019-11-27 19:57:49.285394 Train Epoch: 6 [110/200 ]\tLoss: 0.000950\n",
      "Timestamp 2019-11-27 19:57:51.643385 Train Epoch: 6 [120/200 ]\tLoss: 0.000884\n",
      "Timestamp 2019-11-27 19:57:53.993956 Train Epoch: 6 [130/200 ]\tLoss: 0.001162\n",
      "Timestamp 2019-11-27 19:57:56.354276 Train Epoch: 6 [140/200 ]\tLoss: 0.001141\n",
      "Timestamp 2019-11-27 19:57:58.755293 Train Epoch: 6 [150/200 ]\tLoss: 0.001217\n",
      "Timestamp 2019-11-27 19:58:01.136062 Train Epoch: 6 [160/200 ]\tLoss: 0.001625\n",
      "Timestamp 2019-11-27 19:58:03.493212 Train Epoch: 6 [170/200 ]\tLoss: 0.001220\n",
      "Timestamp 2019-11-27 19:58:05.839643 Train Epoch: 6 [180/200 ]\tLoss: 0.001007\n",
      "Timestamp 2019-11-27 19:58:08.288770 Train Epoch: 6 [190/200 ]\tLoss: 0.001379\n",
      "Timestamp 2019-11-27 19:58:10.742037 Train Epoch: 6 [200/200 ]\tLoss: 0.001336\n",
      "====> Timestamp 2019-11-27 19:58:10.789571 Epoch: 6 Average loss: 0.00120424\n",
      "epoch: 6====> Test set loss: 0.13962985\n",
      "Timestamp 2019-11-27 19:58:24.333561 Train Epoch: 7 [10/200 ]\tLoss: 0.000930\n",
      "Timestamp 2019-11-27 19:58:26.677619 Train Epoch: 7 [20/200 ]\tLoss: 0.001046\n",
      "Timestamp 2019-11-27 19:58:29.025565 Train Epoch: 7 [30/200 ]\tLoss: 0.001116\n",
      "Timestamp 2019-11-27 19:58:31.370431 Train Epoch: 7 [40/200 ]\tLoss: 0.001453\n",
      "Timestamp 2019-11-27 19:58:33.714925 Train Epoch: 7 [50/200 ]\tLoss: 0.001160\n",
      "Timestamp 2019-11-27 19:58:36.059595 Train Epoch: 7 [60/200 ]\tLoss: 0.001278\n",
      "Timestamp 2019-11-27 19:58:38.407880 Train Epoch: 7 [70/200 ]\tLoss: 0.001252\n",
      "Timestamp 2019-11-27 19:58:40.774146 Train Epoch: 7 [80/200 ]\tLoss: 0.001081\n",
      "Timestamp 2019-11-27 19:58:43.116642 Train Epoch: 7 [90/200 ]\tLoss: 0.001040\n",
      "Timestamp 2019-11-27 19:58:45.456507 Train Epoch: 7 [100/200 ]\tLoss: 0.001270\n",
      "Timestamp 2019-11-27 19:58:47.817046 Train Epoch: 7 [110/200 ]\tLoss: 0.000957\n",
      "Timestamp 2019-11-27 19:58:50.158025 Train Epoch: 7 [120/200 ]\tLoss: 0.000861\n",
      "Timestamp 2019-11-27 19:58:52.501979 Train Epoch: 7 [130/200 ]\tLoss: 0.001214\n",
      "Timestamp 2019-11-27 19:58:54.850724 Train Epoch: 7 [140/200 ]\tLoss: 0.001125\n",
      "Timestamp 2019-11-27 19:58:57.190430 Train Epoch: 7 [150/200 ]\tLoss: 0.001239\n",
      "Timestamp 2019-11-27 19:58:59.541752 Train Epoch: 7 [160/200 ]\tLoss: 0.001576\n",
      "Timestamp 2019-11-27 19:59:01.887491 Train Epoch: 7 [170/200 ]\tLoss: 0.001220\n",
      "Timestamp 2019-11-27 19:59:04.238166 Train Epoch: 7 [180/200 ]\tLoss: 0.000989\n",
      "Timestamp 2019-11-27 19:59:06.570200 Train Epoch: 7 [190/200 ]\tLoss: 0.001383\n",
      "Timestamp 2019-11-27 19:59:08.907244 Train Epoch: 7 [200/200 ]\tLoss: 0.001348\n",
      "====> Timestamp 2019-11-27 19:59:08.951722 Epoch: 7 Average loss: 0.00119308\n",
      "epoch: 7====> Test set loss: 0.13999924\n",
      "Timestamp 2019-11-27 19:59:22.428663 Train Epoch: 8 [10/200 ]\tLoss: 0.000956\n",
      "Timestamp 2019-11-27 19:59:24.771627 Train Epoch: 8 [20/200 ]\tLoss: 0.001092\n",
      "Timestamp 2019-11-27 19:59:27.110699 Train Epoch: 8 [30/200 ]\tLoss: 0.001027\n",
      "Timestamp 2019-11-27 19:59:29.450890 Train Epoch: 8 [40/200 ]\tLoss: 0.001403\n",
      "Timestamp 2019-11-27 19:59:31.786699 Train Epoch: 8 [50/200 ]\tLoss: 0.001105\n",
      "Timestamp 2019-11-27 19:59:34.134053 Train Epoch: 8 [60/200 ]\tLoss: 0.001276\n",
      "Timestamp 2019-11-27 19:59:36.468313 Train Epoch: 8 [70/200 ]\tLoss: 0.001261\n",
      "Timestamp 2019-11-27 19:59:38.805424 Train Epoch: 8 [80/200 ]\tLoss: 0.001080\n",
      "Timestamp 2019-11-27 19:59:41.145251 Train Epoch: 8 [90/200 ]\tLoss: 0.001111\n",
      "Timestamp 2019-11-27 19:59:43.481984 Train Epoch: 8 [100/200 ]\tLoss: 0.001276\n",
      "Timestamp 2019-11-27 19:59:45.809636 Train Epoch: 8 [110/200 ]\tLoss: 0.000986\n",
      "Timestamp 2019-11-27 19:59:48.145516 Train Epoch: 8 [120/200 ]\tLoss: 0.000846\n",
      "Timestamp 2019-11-27 19:59:50.474307 Train Epoch: 8 [130/200 ]\tLoss: 0.001202\n",
      "Timestamp 2019-11-27 19:59:52.804191 Train Epoch: 8 [140/200 ]\tLoss: 0.001125\n",
      "Timestamp 2019-11-27 19:59:55.140210 Train Epoch: 8 [150/200 ]\tLoss: 0.001184\n",
      "Timestamp 2019-11-27 19:59:57.467843 Train Epoch: 8 [160/200 ]\tLoss: 0.001586\n",
      "Timestamp 2019-11-27 19:59:59.802113 Train Epoch: 8 [170/200 ]\tLoss: 0.001255\n",
      "Timestamp 2019-11-27 20:00:02.132268 Train Epoch: 8 [180/200 ]\tLoss: 0.000948\n",
      "Timestamp 2019-11-27 20:00:04.461814 Train Epoch: 8 [190/200 ]\tLoss: 0.001400\n",
      "Timestamp 2019-11-27 20:00:06.788327 Train Epoch: 8 [200/200 ]\tLoss: 0.001331\n",
      "====> Timestamp 2019-11-27 20:00:06.831940 Epoch: 8 Average loss: 0.00118419\n",
      "epoch: 8====> Test set loss: 0.13970696\n",
      "Timestamp 2019-11-27 20:00:20.254223 Train Epoch: 9 [10/200 ]\tLoss: 0.000944\n",
      "Timestamp 2019-11-27 20:00:22.592682 Train Epoch: 9 [20/200 ]\tLoss: 0.001079\n",
      "Timestamp 2019-11-27 20:00:24.933247 Train Epoch: 9 [30/200 ]\tLoss: 0.001066\n",
      "Timestamp 2019-11-27 20:00:27.275131 Train Epoch: 9 [40/200 ]\tLoss: 0.001456\n",
      "Timestamp 2019-11-27 20:00:29.629358 Train Epoch: 9 [50/200 ]\tLoss: 0.001087\n",
      "Timestamp 2019-11-27 20:00:31.970689 Train Epoch: 9 [60/200 ]\tLoss: 0.001239\n",
      "Timestamp 2019-11-27 20:00:34.309338 Train Epoch: 9 [70/200 ]\tLoss: 0.001211\n",
      "Timestamp 2019-11-27 20:00:36.650354 Train Epoch: 9 [80/200 ]\tLoss: 0.001057\n",
      "Timestamp 2019-11-27 20:00:38.995721 Train Epoch: 9 [90/200 ]\tLoss: 0.001019\n",
      "Timestamp 2019-11-27 20:00:41.340236 Train Epoch: 9 [100/200 ]\tLoss: 0.001253\n",
      "Timestamp 2019-11-27 20:00:43.673941 Train Epoch: 9 [110/200 ]\tLoss: 0.000963\n",
      "Timestamp 2019-11-27 20:00:46.021045 Train Epoch: 9 [120/200 ]\tLoss: 0.000876\n",
      "Timestamp 2019-11-27 20:00:48.363415 Train Epoch: 9 [130/200 ]\tLoss: 0.001178\n",
      "Timestamp 2019-11-27 20:00:50.703000 Train Epoch: 9 [140/200 ]\tLoss: 0.001107\n",
      "Timestamp 2019-11-27 20:00:53.057105 Train Epoch: 9 [150/200 ]\tLoss: 0.001220\n",
      "Timestamp 2019-11-27 20:00:55.385319 Train Epoch: 9 [160/200 ]\tLoss: 0.001596\n",
      "Timestamp 2019-11-27 20:00:57.715196 Train Epoch: 9 [170/200 ]\tLoss: 0.001228\n",
      "Timestamp 2019-11-27 20:01:00.058039 Train Epoch: 9 [180/200 ]\tLoss: 0.000960\n",
      "Timestamp 2019-11-27 20:01:02.385027 Train Epoch: 9 [190/200 ]\tLoss: 0.001373\n",
      "Timestamp 2019-11-27 20:01:04.719461 Train Epoch: 9 [200/200 ]\tLoss: 0.001280\n",
      "====> Timestamp 2019-11-27 20:01:04.763139 Epoch: 9 Average loss: 0.00117533\n",
      "epoch: 9====> Test set loss: 0.13947130\n",
      "Timestamp 2019-11-27 20:01:18.175542 Train Epoch: 10 [10/200 ]\tLoss: 0.000900\n",
      "Timestamp 2019-11-27 20:01:20.519890 Train Epoch: 10 [20/200 ]\tLoss: 0.001076\n",
      "Timestamp 2019-11-27 20:01:22.860688 Train Epoch: 10 [30/200 ]\tLoss: 0.001019\n",
      "Timestamp 2019-11-27 20:01:25.207357 Train Epoch: 10 [40/200 ]\tLoss: 0.001433\n",
      "Timestamp 2019-11-27 20:01:27.541890 Train Epoch: 10 [50/200 ]\tLoss: 0.001096\n",
      "Timestamp 2019-11-27 20:01:29.867001 Train Epoch: 10 [60/200 ]\tLoss: 0.001211\n",
      "Timestamp 2019-11-27 20:01:32.201054 Train Epoch: 10 [70/200 ]\tLoss: 0.001228\n",
      "Timestamp 2019-11-27 20:01:34.531462 Train Epoch: 10 [80/200 ]\tLoss: 0.001076\n",
      "Timestamp 2019-11-27 20:01:36.855994 Train Epoch: 10 [90/200 ]\tLoss: 0.001083\n",
      "Timestamp 2019-11-27 20:01:39.197319 Train Epoch: 10 [100/200 ]\tLoss: 0.001273\n",
      "Timestamp 2019-11-27 20:01:41.524697 Train Epoch: 10 [110/200 ]\tLoss: 0.000951\n",
      "Timestamp 2019-11-27 20:01:43.864198 Train Epoch: 10 [120/200 ]\tLoss: 0.000882\n",
      "Timestamp 2019-11-27 20:01:46.190450 Train Epoch: 10 [130/200 ]\tLoss: 0.001178\n",
      "Timestamp 2019-11-27 20:01:48.527498 Train Epoch: 10 [140/200 ]\tLoss: 0.001136\n",
      "Timestamp 2019-11-27 20:01:50.853088 Train Epoch: 10 [150/200 ]\tLoss: 0.001190\n",
      "Timestamp 2019-11-27 20:01:53.186767 Train Epoch: 10 [160/200 ]\tLoss: 0.001548\n",
      "Timestamp 2019-11-27 20:01:55.511126 Train Epoch: 10 [170/200 ]\tLoss: 0.001207\n",
      "Timestamp 2019-11-27 20:01:57.849153 Train Epoch: 10 [180/200 ]\tLoss: 0.000992\n",
      "Timestamp 2019-11-27 20:02:00.184241 Train Epoch: 10 [190/200 ]\tLoss: 0.001359\n",
      "Timestamp 2019-11-27 20:02:02.514631 Train Epoch: 10 [200/200 ]\tLoss: 0.001306\n",
      "====> Timestamp 2019-11-27 20:02:02.557478 Epoch: 10 Average loss: 0.00116934\n",
      "epoch: 10====> Test set loss: 0.14026557\n",
      "Timestamp 2019-11-27 20:02:15.872533 Train Epoch: 11 [10/200 ]\tLoss: 0.000917\n",
      "Timestamp 2019-11-27 20:02:18.214220 Train Epoch: 11 [20/200 ]\tLoss: 0.001055\n",
      "Timestamp 2019-11-27 20:02:20.544816 Train Epoch: 11 [30/200 ]\tLoss: 0.001001\n",
      "Timestamp 2019-11-27 20:02:22.884174 Train Epoch: 11 [40/200 ]\tLoss: 0.001419\n",
      "Timestamp 2019-11-27 20:02:25.224311 Train Epoch: 11 [50/200 ]\tLoss: 0.001100\n",
      "Timestamp 2019-11-27 20:02:27.557894 Train Epoch: 11 [60/200 ]\tLoss: 0.001233\n",
      "Timestamp 2019-11-27 20:02:29.890359 Train Epoch: 11 [70/200 ]\tLoss: 0.001216\n",
      "Timestamp 2019-11-27 20:02:32.218044 Train Epoch: 11 [80/200 ]\tLoss: 0.001047\n",
      "Timestamp 2019-11-27 20:02:34.551124 Train Epoch: 11 [90/200 ]\tLoss: 0.000993\n",
      "Timestamp 2019-11-27 20:02:36.892773 Train Epoch: 11 [100/200 ]\tLoss: 0.001213\n",
      "Timestamp 2019-11-27 20:02:39.232202 Train Epoch: 11 [110/200 ]\tLoss: 0.000958\n",
      "Timestamp 2019-11-27 20:02:41.566248 Train Epoch: 11 [120/200 ]\tLoss: 0.000896\n",
      "Timestamp 2019-11-27 20:02:43.898008 Train Epoch: 11 [130/200 ]\tLoss: 0.001129\n",
      "Timestamp 2019-11-27 20:02:46.220016 Train Epoch: 11 [140/200 ]\tLoss: 0.001126\n",
      "Timestamp 2019-11-27 20:02:48.549466 Train Epoch: 11 [150/200 ]\tLoss: 0.001166\n",
      "Timestamp 2019-11-27 20:02:50.872207 Train Epoch: 11 [160/200 ]\tLoss: 0.001596\n",
      "Timestamp 2019-11-27 20:02:53.196538 Train Epoch: 11 [170/200 ]\tLoss: 0.001181\n",
      "Timestamp 2019-11-27 20:02:55.526260 Train Epoch: 11 [180/200 ]\tLoss: 0.000939\n",
      "Timestamp 2019-11-27 20:02:57.863850 Train Epoch: 11 [190/200 ]\tLoss: 0.001367\n",
      "Timestamp 2019-11-27 20:03:00.199520 Train Epoch: 11 [200/200 ]\tLoss: 0.001248\n",
      "====> Timestamp 2019-11-27 20:03:00.240005 Epoch: 11 Average loss: 0.00116126\n",
      "epoch: 11====> Test set loss: 0.14019584\n",
      "Timestamp 2019-11-27 20:03:13.510682 Train Epoch: 12 [10/200 ]\tLoss: 0.000879\n",
      "Timestamp 2019-11-27 20:03:15.846682 Train Epoch: 12 [20/200 ]\tLoss: 0.001031\n",
      "Timestamp 2019-11-27 20:03:18.182556 Train Epoch: 12 [30/200 ]\tLoss: 0.001013\n",
      "Timestamp 2019-11-27 20:03:20.519057 Train Epoch: 12 [40/200 ]\tLoss: 0.001369\n",
      "Timestamp 2019-11-27 20:03:22.858130 Train Epoch: 12 [50/200 ]\tLoss: 0.001075\n",
      "Timestamp 2019-11-27 20:03:25.191816 Train Epoch: 12 [60/200 ]\tLoss: 0.001137\n",
      "Timestamp 2019-11-27 20:03:27.527848 Train Epoch: 12 [70/200 ]\tLoss: 0.001181\n",
      "Timestamp 2019-11-27 20:03:29.863855 Train Epoch: 12 [80/200 ]\tLoss: 0.001070\n",
      "Timestamp 2019-11-27 20:03:32.195838 Train Epoch: 12 [90/200 ]\tLoss: 0.001013\n",
      "Timestamp 2019-11-27 20:03:34.532681 Train Epoch: 12 [100/200 ]\tLoss: 0.001237\n",
      "Timestamp 2019-11-27 20:03:36.865212 Train Epoch: 12 [110/200 ]\tLoss: 0.000944\n",
      "Timestamp 2019-11-27 20:03:39.245205 Train Epoch: 12 [120/200 ]\tLoss: 0.000875\n",
      "Timestamp 2019-11-27 20:03:41.583953 Train Epoch: 12 [130/200 ]\tLoss: 0.001197\n",
      "Timestamp 2019-11-27 20:03:43.924558 Train Epoch: 12 [140/200 ]\tLoss: 0.001113\n",
      "Timestamp 2019-11-27 20:03:46.254742 Train Epoch: 12 [150/200 ]\tLoss: 0.001141\n",
      "Timestamp 2019-11-27 20:03:48.589676 Train Epoch: 12 [160/200 ]\tLoss: 0.001558\n",
      "Timestamp 2019-11-27 20:03:50.920243 Train Epoch: 12 [170/200 ]\tLoss: 0.001187\n",
      "Timestamp 2019-11-27 20:03:53.253118 Train Epoch: 12 [180/200 ]\tLoss: 0.000958\n",
      "Timestamp 2019-11-27 20:03:55.581959 Train Epoch: 12 [190/200 ]\tLoss: 0.001311\n",
      "Timestamp 2019-11-27 20:03:57.926594 Train Epoch: 12 [200/200 ]\tLoss: 0.001283\n",
      "====> Timestamp 2019-11-27 20:03:57.969410 Epoch: 12 Average loss: 0.00115300\n",
      "epoch: 12====> Test set loss: 0.14058677\n",
      "Timestamp 2019-11-27 20:04:11.416391 Train Epoch: 13 [10/200 ]\tLoss: 0.000876\n",
      "Timestamp 2019-11-27 20:04:13.761153 Train Epoch: 13 [20/200 ]\tLoss: 0.000992\n",
      "Timestamp 2019-11-27 20:04:16.097689 Train Epoch: 13 [30/200 ]\tLoss: 0.001003\n",
      "Timestamp 2019-11-27 20:04:18.440054 Train Epoch: 13 [40/200 ]\tLoss: 0.001361\n",
      "Timestamp 2019-11-27 20:04:20.789290 Train Epoch: 13 [50/200 ]\tLoss: 0.001062\n",
      "Timestamp 2019-11-27 20:04:23.137960 Train Epoch: 13 [60/200 ]\tLoss: 0.001199\n",
      "Timestamp 2019-11-27 20:04:25.483112 Train Epoch: 13 [70/200 ]\tLoss: 0.001178\n",
      "Timestamp 2019-11-27 20:04:27.818074 Train Epoch: 13 [80/200 ]\tLoss: 0.001052\n",
      "Timestamp 2019-11-27 20:04:30.166441 Train Epoch: 13 [90/200 ]\tLoss: 0.001039\n",
      "Timestamp 2019-11-27 20:04:32.503909 Train Epoch: 13 [100/200 ]\tLoss: 0.001220\n",
      "Timestamp 2019-11-27 20:04:34.834629 Train Epoch: 13 [110/200 ]\tLoss: 0.000929\n",
      "Timestamp 2019-11-27 20:04:37.170235 Train Epoch: 13 [120/200 ]\tLoss: 0.000834\n",
      "Timestamp 2019-11-27 20:04:39.511047 Train Epoch: 13 [130/200 ]\tLoss: 0.001148\n",
      "Timestamp 2019-11-27 20:04:41.845588 Train Epoch: 13 [140/200 ]\tLoss: 0.001110\n",
      "Timestamp 2019-11-27 20:04:44.175356 Train Epoch: 13 [150/200 ]\tLoss: 0.001165\n",
      "Timestamp 2019-11-27 20:04:46.509599 Train Epoch: 13 [160/200 ]\tLoss: 0.001516\n",
      "Timestamp 2019-11-27 20:04:48.840613 Train Epoch: 13 [170/200 ]\tLoss: 0.001203\n",
      "Timestamp 2019-11-27 20:04:51.168594 Train Epoch: 13 [180/200 ]\tLoss: 0.000948\n",
      "Timestamp 2019-11-27 20:04:53.506691 Train Epoch: 13 [190/200 ]\tLoss: 0.001324\n",
      "Timestamp 2019-11-27 20:04:55.844582 Train Epoch: 13 [200/200 ]\tLoss: 0.001287\n",
      "====> Timestamp 2019-11-27 20:04:55.891484 Epoch: 13 Average loss: 0.00114320\n",
      "epoch: 13====> Test set loss: 0.14054329\n",
      "Timestamp 2019-11-27 20:05:09.388970 Train Epoch: 14 [10/200 ]\tLoss: 0.000878\n",
      "Timestamp 2019-11-27 20:05:11.747213 Train Epoch: 14 [20/200 ]\tLoss: 0.001030\n",
      "Timestamp 2019-11-27 20:05:14.087182 Train Epoch: 14 [30/200 ]\tLoss: 0.000979\n",
      "Timestamp 2019-11-27 20:05:16.425611 Train Epoch: 14 [40/200 ]\tLoss: 0.001373\n",
      "Timestamp 2019-11-27 20:05:18.768234 Train Epoch: 14 [50/200 ]\tLoss: 0.001029\n",
      "Timestamp 2019-11-27 20:05:21.107338 Train Epoch: 14 [60/200 ]\tLoss: 0.001163\n",
      "Timestamp 2019-11-27 20:05:23.448077 Train Epoch: 14 [70/200 ]\tLoss: 0.001182\n",
      "Timestamp 2019-11-27 20:05:25.787634 Train Epoch: 14 [80/200 ]\tLoss: 0.001088\n",
      "Timestamp 2019-11-27 20:05:28.120085 Train Epoch: 14 [90/200 ]\tLoss: 0.001007\n",
      "Timestamp 2019-11-27 20:05:30.466975 Train Epoch: 14 [100/200 ]\tLoss: 0.001216\n",
      "Timestamp 2019-11-27 20:05:32.796657 Train Epoch: 14 [110/200 ]\tLoss: 0.000923\n",
      "Timestamp 2019-11-27 20:05:35.127748 Train Epoch: 14 [120/200 ]\tLoss: 0.000825\n",
      "Timestamp 2019-11-27 20:05:37.468121 Train Epoch: 14 [130/200 ]\tLoss: 0.001179\n",
      "Timestamp 2019-11-27 20:05:39.820043 Train Epoch: 14 [140/200 ]\tLoss: 0.001084\n",
      "Timestamp 2019-11-27 20:05:42.152180 Train Epoch: 14 [150/200 ]\tLoss: 0.001176\n",
      "Timestamp 2019-11-27 20:05:44.495094 Train Epoch: 14 [160/200 ]\tLoss: 0.001484\n",
      "Timestamp 2019-11-27 20:05:46.825936 Train Epoch: 14 [170/200 ]\tLoss: 0.001145\n",
      "Timestamp 2019-11-27 20:05:49.156046 Train Epoch: 14 [180/200 ]\tLoss: 0.000943\n",
      "Timestamp 2019-11-27 20:05:51.489098 Train Epoch: 14 [190/200 ]\tLoss: 0.001320\n",
      "Timestamp 2019-11-27 20:05:53.828380 Train Epoch: 14 [200/200 ]\tLoss: 0.001236\n",
      "====> Timestamp 2019-11-27 20:05:53.874073 Epoch: 14 Average loss: 0.00113287\n",
      "epoch: 14====> Test set loss: 0.14039421\n",
      "Timestamp 2019-11-27 20:06:07.301966 Train Epoch: 15 [10/200 ]\tLoss: 0.000863\n",
      "Timestamp 2019-11-27 20:06:09.664995 Train Epoch: 15 [20/200 ]\tLoss: 0.000964\n",
      "Timestamp 2019-11-27 20:06:12.001820 Train Epoch: 15 [30/200 ]\tLoss: 0.000974\n",
      "Timestamp 2019-11-27 20:06:14.336640 Train Epoch: 15 [40/200 ]\tLoss: 0.001339\n",
      "Timestamp 2019-11-27 20:06:16.672112 Train Epoch: 15 [50/200 ]\tLoss: 0.001031\n",
      "Timestamp 2019-11-27 20:06:19.015256 Train Epoch: 15 [60/200 ]\tLoss: 0.001222\n",
      "Timestamp 2019-11-27 20:06:21.357084 Train Epoch: 15 [70/200 ]\tLoss: 0.001175\n",
      "Timestamp 2019-11-27 20:06:23.700699 Train Epoch: 15 [80/200 ]\tLoss: 0.001058\n",
      "Timestamp 2019-11-27 20:06:26.040847 Train Epoch: 15 [90/200 ]\tLoss: 0.000985\n",
      "Timestamp 2019-11-27 20:06:28.386667 Train Epoch: 15 [100/200 ]\tLoss: 0.001205\n",
      "Timestamp 2019-11-27 20:06:30.718684 Train Epoch: 15 [110/200 ]\tLoss: 0.000901\n",
      "Timestamp 2019-11-27 20:06:33.057923 Train Epoch: 15 [120/200 ]\tLoss: 0.000774\n",
      "Timestamp 2019-11-27 20:06:35.398268 Train Epoch: 15 [130/200 ]\tLoss: 0.001136\n",
      "Timestamp 2019-11-27 20:06:37.734061 Train Epoch: 15 [140/200 ]\tLoss: 0.001078\n",
      "Timestamp 2019-11-27 20:06:40.081530 Train Epoch: 15 [150/200 ]\tLoss: 0.001134\n",
      "Timestamp 2019-11-27 20:06:42.433492 Train Epoch: 15 [160/200 ]\tLoss: 0.001518\n",
      "Timestamp 2019-11-27 20:06:44.783514 Train Epoch: 15 [170/200 ]\tLoss: 0.001147\n",
      "Timestamp 2019-11-27 20:06:47.127494 Train Epoch: 15 [180/200 ]\tLoss: 0.000923\n",
      "Timestamp 2019-11-27 20:06:49.466321 Train Epoch: 15 [190/200 ]\tLoss: 0.001300\n",
      "Timestamp 2019-11-27 20:06:51.809718 Train Epoch: 15 [200/200 ]\tLoss: 0.001199\n",
      "====> Timestamp 2019-11-27 20:06:51.853589 Epoch: 15 Average loss: 0.00112411\n",
      "epoch: 15====> Test set loss: 0.14056092\n",
      "Timestamp 2019-11-27 20:07:05.360890 Train Epoch: 16 [10/200 ]\tLoss: 0.000876\n",
      "Timestamp 2019-11-27 20:07:07.689864 Train Epoch: 16 [20/200 ]\tLoss: 0.000962\n",
      "Timestamp 2019-11-27 20:07:10.028943 Train Epoch: 16 [30/200 ]\tLoss: 0.001011\n",
      "Timestamp 2019-11-27 20:07:12.355021 Train Epoch: 16 [40/200 ]\tLoss: 0.001351\n",
      "Timestamp 2019-11-27 20:07:14.680327 Train Epoch: 16 [50/200 ]\tLoss: 0.001091\n",
      "Timestamp 2019-11-27 20:07:17.017501 Train Epoch: 16 [60/200 ]\tLoss: 0.001155\n",
      "Timestamp 2019-11-27 20:07:19.348218 Train Epoch: 16 [70/200 ]\tLoss: 0.001154\n",
      "Timestamp 2019-11-27 20:07:21.672880 Train Epoch: 16 [80/200 ]\tLoss: 0.001038\n",
      "Timestamp 2019-11-27 20:07:23.997185 Train Epoch: 16 [90/200 ]\tLoss: 0.000969\n",
      "Timestamp 2019-11-27 20:07:26.324693 Train Epoch: 16 [100/200 ]\tLoss: 0.001144\n",
      "Timestamp 2019-11-27 20:07:28.660905 Train Epoch: 16 [110/200 ]\tLoss: 0.000915\n",
      "Timestamp 2019-11-27 20:07:30.989873 Train Epoch: 16 [120/200 ]\tLoss: 0.000757\n",
      "Timestamp 2019-11-27 20:07:33.314001 Train Epoch: 16 [130/200 ]\tLoss: 0.001096\n",
      "Timestamp 2019-11-27 20:07:35.637876 Train Epoch: 16 [140/200 ]\tLoss: 0.001107\n",
      "Timestamp 2019-11-27 20:07:37.981472 Train Epoch: 16 [150/200 ]\tLoss: 0.001163\n",
      "Timestamp 2019-11-27 20:07:40.345362 Train Epoch: 16 [160/200 ]\tLoss: 0.001547\n",
      "Timestamp 2019-11-27 20:07:42.682567 Train Epoch: 16 [170/200 ]\tLoss: 0.001154\n",
      "Timestamp 2019-11-27 20:07:45.018798 Train Epoch: 16 [180/200 ]\tLoss: 0.000922\n",
      "Timestamp 2019-11-27 20:07:47.351224 Train Epoch: 16 [190/200 ]\tLoss: 0.001331\n",
      "Timestamp 2019-11-27 20:07:49.689287 Train Epoch: 16 [200/200 ]\tLoss: 0.001176\n",
      "====> Timestamp 2019-11-27 20:07:49.731898 Epoch: 16 Average loss: 0.00111592\n",
      "epoch: 16====> Test set loss: 0.14147700\n",
      "Timestamp 2019-11-27 20:08:03.209710 Train Epoch: 17 [10/200 ]\tLoss: 0.000910\n",
      "Timestamp 2019-11-27 20:08:05.544232 Train Epoch: 17 [20/200 ]\tLoss: 0.000960\n",
      "Timestamp 2019-11-27 20:08:07.881077 Train Epoch: 17 [30/200 ]\tLoss: 0.000945\n",
      "Timestamp 2019-11-27 20:08:10.235282 Train Epoch: 17 [40/200 ]\tLoss: 0.001340\n",
      "Timestamp 2019-11-27 20:08:12.569941 Train Epoch: 17 [50/200 ]\tLoss: 0.001052\n",
      "Timestamp 2019-11-27 20:08:14.912525 Train Epoch: 17 [60/200 ]\tLoss: 0.001143\n",
      "Timestamp 2019-11-27 20:08:17.263800 Train Epoch: 17 [70/200 ]\tLoss: 0.001127\n",
      "Timestamp 2019-11-27 20:08:19.610429 Train Epoch: 17 [80/200 ]\tLoss: 0.001049\n",
      "Timestamp 2019-11-27 20:08:21.955387 Train Epoch: 17 [90/200 ]\tLoss: 0.000977\n",
      "Timestamp 2019-11-27 20:08:24.293010 Train Epoch: 17 [100/200 ]\tLoss: 0.001165\n",
      "Timestamp 2019-11-27 20:08:26.618764 Train Epoch: 17 [110/200 ]\tLoss: 0.000943\n",
      "Timestamp 2019-11-27 20:08:28.947381 Train Epoch: 17 [120/200 ]\tLoss: 0.000756\n",
      "Timestamp 2019-11-27 20:08:31.283168 Train Epoch: 17 [130/200 ]\tLoss: 0.001136\n",
      "Timestamp 2019-11-27 20:08:33.624057 Train Epoch: 17 [140/200 ]\tLoss: 0.001096\n",
      "Timestamp 2019-11-27 20:08:35.954810 Train Epoch: 17 [150/200 ]\tLoss: 0.001134\n",
      "Timestamp 2019-11-27 20:08:38.281811 Train Epoch: 17 [160/200 ]\tLoss: 0.001499\n",
      "Timestamp 2019-11-27 20:08:40.621213 Train Epoch: 17 [170/200 ]\tLoss: 0.001147\n",
      "Timestamp 2019-11-27 20:08:42.948720 Train Epoch: 17 [180/200 ]\tLoss: 0.000908\n",
      "Timestamp 2019-11-27 20:08:45.288902 Train Epoch: 17 [190/200 ]\tLoss: 0.001299\n",
      "Timestamp 2019-11-27 20:08:47.618287 Train Epoch: 17 [200/200 ]\tLoss: 0.001224\n",
      "====> Timestamp 2019-11-27 20:08:47.661446 Epoch: 17 Average loss: 0.00111060\n",
      "epoch: 17====> Test set loss: 0.14092142\n",
      "Timestamp 2019-11-27 20:09:01.032512 Train Epoch: 18 [10/200 ]\tLoss: 0.000881\n",
      "Timestamp 2019-11-27 20:09:03.382338 Train Epoch: 18 [20/200 ]\tLoss: 0.000965\n",
      "Timestamp 2019-11-27 20:09:05.728162 Train Epoch: 18 [30/200 ]\tLoss: 0.000996\n",
      "Timestamp 2019-11-27 20:09:08.080308 Train Epoch: 18 [40/200 ]\tLoss: 0.001355\n",
      "Timestamp 2019-11-27 20:09:10.440468 Train Epoch: 18 [50/200 ]\tLoss: 0.001042\n",
      "Timestamp 2019-11-27 20:09:12.785821 Train Epoch: 18 [60/200 ]\tLoss: 0.001141\n",
      "Timestamp 2019-11-27 20:09:15.135550 Train Epoch: 18 [70/200 ]\tLoss: 0.001134\n",
      "Timestamp 2019-11-27 20:09:17.477979 Train Epoch: 18 [80/200 ]\tLoss: 0.001035\n",
      "Timestamp 2019-11-27 20:09:19.817465 Train Epoch: 18 [90/200 ]\tLoss: 0.000972\n",
      "Timestamp 2019-11-27 20:09:22.163841 Train Epoch: 18 [100/200 ]\tLoss: 0.001127\n",
      "Timestamp 2019-11-27 20:09:24.513519 Train Epoch: 18 [110/200 ]\tLoss: 0.000909\n",
      "Timestamp 2019-11-27 20:09:26.863287 Train Epoch: 18 [120/200 ]\tLoss: 0.000773\n",
      "Timestamp 2019-11-27 20:09:29.207525 Train Epoch: 18 [130/200 ]\tLoss: 0.001133\n",
      "Timestamp 2019-11-27 20:09:31.550933 Train Epoch: 18 [140/200 ]\tLoss: 0.001044\n",
      "Timestamp 2019-11-27 20:09:33.892691 Train Epoch: 18 [150/200 ]\tLoss: 0.001085\n",
      "Timestamp 2019-11-27 20:09:36.244192 Train Epoch: 18 [160/200 ]\tLoss: 0.001522\n",
      "Timestamp 2019-11-27 20:09:38.578906 Train Epoch: 18 [170/200 ]\tLoss: 0.001156\n",
      "Timestamp 2019-11-27 20:09:40.933246 Train Epoch: 18 [180/200 ]\tLoss: 0.000896\n",
      "Timestamp 2019-11-27 20:09:43.283245 Train Epoch: 18 [190/200 ]\tLoss: 0.001315\n",
      "Timestamp 2019-11-27 20:09:45.624232 Train Epoch: 18 [200/200 ]\tLoss: 0.001162\n",
      "====> Timestamp 2019-11-27 20:09:45.667924 Epoch: 18 Average loss: 0.00109995\n",
      "epoch: 18====> Test set loss: 0.14096283\n",
      "Timestamp 2019-11-27 20:09:58.885827 Train Epoch: 19 [10/200 ]\tLoss: 0.000856\n",
      "Timestamp 2019-11-27 20:10:01.231753 Train Epoch: 19 [20/200 ]\tLoss: 0.000970\n",
      "Timestamp 2019-11-27 20:10:03.573996 Train Epoch: 19 [30/200 ]\tLoss: 0.000971\n",
      "Timestamp 2019-11-27 20:10:05.922256 Train Epoch: 19 [40/200 ]\tLoss: 0.001329\n",
      "Timestamp 2019-11-27 20:10:08.256065 Train Epoch: 19 [50/200 ]\tLoss: 0.001027\n",
      "Timestamp 2019-11-27 20:10:10.612676 Train Epoch: 19 [60/200 ]\tLoss: 0.001115\n",
      "Timestamp 2019-11-27 20:10:12.953020 Train Epoch: 19 [70/200 ]\tLoss: 0.001176\n",
      "Timestamp 2019-11-27 20:10:15.292211 Train Epoch: 19 [80/200 ]\tLoss: 0.001017\n",
      "Timestamp 2019-11-27 20:10:17.646538 Train Epoch: 19 [90/200 ]\tLoss: 0.000959\n",
      "Timestamp 2019-11-27 20:10:19.986498 Train Epoch: 19 [100/200 ]\tLoss: 0.001160\n",
      "Timestamp 2019-11-27 20:10:22.323507 Train Epoch: 19 [110/200 ]\tLoss: 0.000906\n",
      "Timestamp 2019-11-27 20:10:24.669531 Train Epoch: 19 [120/200 ]\tLoss: 0.000759\n",
      "Timestamp 2019-11-27 20:10:27.004258 Train Epoch: 19 [130/200 ]\tLoss: 0.001107\n",
      "Timestamp 2019-11-27 20:10:29.346540 Train Epoch: 19 [140/200 ]\tLoss: 0.001095\n",
      "Timestamp 2019-11-27 20:10:31.697015 Train Epoch: 19 [150/200 ]\tLoss: 0.001128\n",
      "Timestamp 2019-11-27 20:10:34.051090 Train Epoch: 19 [160/200 ]\tLoss: 0.001506\n",
      "Timestamp 2019-11-27 20:10:36.398530 Train Epoch: 19 [170/200 ]\tLoss: 0.001130\n",
      "Timestamp 2019-11-27 20:10:38.742459 Train Epoch: 19 [180/200 ]\tLoss: 0.000918\n",
      "Timestamp 2019-11-27 20:10:41.092797 Train Epoch: 19 [190/200 ]\tLoss: 0.001284\n",
      "Timestamp 2019-11-27 20:10:43.436067 Train Epoch: 19 [200/200 ]\tLoss: 0.001237\n",
      "====> Timestamp 2019-11-27 20:10:43.482078 Epoch: 19 Average loss: 0.00109840\n",
      "epoch: 19====> Test set loss: 0.14121317\n",
      "Timestamp 2019-11-27 20:10:56.900312 Train Epoch: 20 [10/200 ]\tLoss: 0.000810\n",
      "Timestamp 2019-11-27 20:10:59.241577 Train Epoch: 20 [20/200 ]\tLoss: 0.000986\n",
      "Timestamp 2019-11-27 20:11:01.567499 Train Epoch: 20 [30/200 ]\tLoss: 0.000951\n",
      "Timestamp 2019-11-27 20:11:03.902130 Train Epoch: 20 [40/200 ]\tLoss: 0.001293\n",
      "Timestamp 2019-11-27 20:11:06.234412 Train Epoch: 20 [50/200 ]\tLoss: 0.001058\n",
      "Timestamp 2019-11-27 20:11:08.577982 Train Epoch: 20 [60/200 ]\tLoss: 0.001105\n",
      "Timestamp 2019-11-27 20:11:10.915846 Train Epoch: 20 [70/200 ]\tLoss: 0.001127\n",
      "Timestamp 2019-11-27 20:11:13.244945 Train Epoch: 20 [80/200 ]\tLoss: 0.001029\n",
      "Timestamp 2019-11-27 20:11:15.635062 Train Epoch: 20 [90/200 ]\tLoss: 0.000903\n",
      "Timestamp 2019-11-27 20:11:18.022050 Train Epoch: 20 [100/200 ]\tLoss: 0.001156\n",
      "Timestamp 2019-11-27 20:11:20.436763 Train Epoch: 20 [110/200 ]\tLoss: 0.000883\n",
      "Timestamp 2019-11-27 20:11:22.840900 Train Epoch: 20 [120/200 ]\tLoss: 0.000716\n",
      "Timestamp 2019-11-27 20:11:25.270196 Train Epoch: 20 [130/200 ]\tLoss: 0.001122\n",
      "Timestamp 2019-11-27 20:11:27.618395 Train Epoch: 20 [140/200 ]\tLoss: 0.001055\n",
      "Timestamp 2019-11-27 20:11:29.995817 Train Epoch: 20 [150/200 ]\tLoss: 0.001106\n",
      "Timestamp 2019-11-27 20:11:32.392926 Train Epoch: 20 [160/200 ]\tLoss: 0.001520\n",
      "Timestamp 2019-11-27 20:11:34.790309 Train Epoch: 20 [170/200 ]\tLoss: 0.001141\n",
      "Timestamp 2019-11-27 20:11:37.199860 Train Epoch: 20 [180/200 ]\tLoss: 0.000906\n",
      "Timestamp 2019-11-27 20:11:39.595719 Train Epoch: 20 [190/200 ]\tLoss: 0.001335\n",
      "Timestamp 2019-11-27 20:11:41.947463 Train Epoch: 20 [200/200 ]\tLoss: 0.001134\n",
      "====> Timestamp 2019-11-27 20:11:41.992290 Epoch: 20 Average loss: 0.00108532\n",
      "epoch: 20====> Test set loss: 0.14016284\n",
      "Timestamp 2019-11-27 20:11:55.850468 Train Epoch: 21 [10/200 ]\tLoss: 0.000820\n",
      "Timestamp 2019-11-27 20:11:58.231502 Train Epoch: 21 [20/200 ]\tLoss: 0.000956\n",
      "Timestamp 2019-11-27 20:12:00.647320 Train Epoch: 21 [30/200 ]\tLoss: 0.000902\n",
      "Timestamp 2019-11-27 20:12:03.059284 Train Epoch: 21 [40/200 ]\tLoss: 0.001313\n",
      "Timestamp 2019-11-27 20:12:05.501438 Train Epoch: 21 [50/200 ]\tLoss: 0.001046\n",
      "Timestamp 2019-11-27 20:12:07.910828 Train Epoch: 21 [60/200 ]\tLoss: 0.001110\n",
      "Timestamp 2019-11-27 20:12:10.313763 Train Epoch: 21 [70/200 ]\tLoss: 0.001130\n",
      "Timestamp 2019-11-27 20:12:12.736050 Train Epoch: 21 [80/200 ]\tLoss: 0.001001\n",
      "Timestamp 2019-11-27 20:12:15.176400 Train Epoch: 21 [90/200 ]\tLoss: 0.000922\n",
      "Timestamp 2019-11-27 20:12:17.634970 Train Epoch: 21 [100/200 ]\tLoss: 0.001129\n",
      "Timestamp 2019-11-27 20:12:20.063244 Train Epoch: 21 [110/200 ]\tLoss: 0.000847\n",
      "Timestamp 2019-11-27 20:12:22.426831 Train Epoch: 21 [120/200 ]\tLoss: 0.000765\n",
      "Timestamp 2019-11-27 20:12:24.829630 Train Epoch: 21 [130/200 ]\tLoss: 0.001131\n",
      "Timestamp 2019-11-27 20:12:27.227261 Train Epoch: 21 [140/200 ]\tLoss: 0.001005\n",
      "Timestamp 2019-11-27 20:12:29.572984 Train Epoch: 21 [150/200 ]\tLoss: 0.001086\n",
      "Timestamp 2019-11-27 20:12:31.913945 Train Epoch: 21 [160/200 ]\tLoss: 0.001481\n",
      "Timestamp 2019-11-27 20:12:34.270667 Train Epoch: 21 [170/200 ]\tLoss: 0.001153\n",
      "Timestamp 2019-11-27 20:12:36.616169 Train Epoch: 21 [180/200 ]\tLoss: 0.000873\n",
      "Timestamp 2019-11-27 20:12:38.967329 Train Epoch: 21 [190/200 ]\tLoss: 0.001294\n",
      "Timestamp 2019-11-27 20:12:41.323064 Train Epoch: 21 [200/200 ]\tLoss: 0.001151\n",
      "====> Timestamp 2019-11-27 20:12:41.367945 Epoch: 21 Average loss: 0.00107858\n",
      "epoch: 21====> Test set loss: 0.14328682\n",
      "Timestamp 2019-11-27 20:12:54.792641 Train Epoch: 22 [10/200 ]\tLoss: 0.000852\n",
      "Timestamp 2019-11-27 20:12:57.143821 Train Epoch: 22 [20/200 ]\tLoss: 0.000929\n",
      "Timestamp 2019-11-27 20:12:59.496000 Train Epoch: 22 [30/200 ]\tLoss: 0.000980\n",
      "Timestamp 2019-11-27 20:13:01.833436 Train Epoch: 22 [40/200 ]\tLoss: 0.001238\n",
      "Timestamp 2019-11-27 20:13:04.170458 Train Epoch: 22 [50/200 ]\tLoss: 0.000993\n",
      "Timestamp 2019-11-27 20:13:06.506578 Train Epoch: 22 [60/200 ]\tLoss: 0.001143\n",
      "Timestamp 2019-11-27 20:13:08.843836 Train Epoch: 22 [70/200 ]\tLoss: 0.001057\n",
      "Timestamp 2019-11-27 20:13:11.193541 Train Epoch: 22 [80/200 ]\tLoss: 0.000999\n",
      "Timestamp 2019-11-27 20:13:13.539285 Train Epoch: 22 [90/200 ]\tLoss: 0.000911\n",
      "Timestamp 2019-11-27 20:13:15.873678 Train Epoch: 22 [100/200 ]\tLoss: 0.001165\n",
      "Timestamp 2019-11-27 20:13:18.212295 Train Epoch: 22 [110/200 ]\tLoss: 0.000853\n",
      "Timestamp 2019-11-27 20:13:20.549683 Train Epoch: 22 [120/200 ]\tLoss: 0.000750\n",
      "Timestamp 2019-11-27 20:13:22.882294 Train Epoch: 22 [130/200 ]\tLoss: 0.001065\n",
      "Timestamp 2019-11-27 20:13:25.228653 Train Epoch: 22 [140/200 ]\tLoss: 0.001019\n",
      "Timestamp 2019-11-27 20:13:27.578604 Train Epoch: 22 [150/200 ]\tLoss: 0.001077\n",
      "Timestamp 2019-11-27 20:13:29.920886 Train Epoch: 22 [160/200 ]\tLoss: 0.001538\n",
      "Timestamp 2019-11-27 20:13:32.268174 Train Epoch: 22 [170/200 ]\tLoss: 0.001149\n",
      "Timestamp 2019-11-27 20:13:34.610904 Train Epoch: 22 [180/200 ]\tLoss: 0.000907\n",
      "Timestamp 2019-11-27 20:13:36.948924 Train Epoch: 22 [190/200 ]\tLoss: 0.001299\n",
      "Timestamp 2019-11-27 20:13:39.309918 Train Epoch: 22 [200/200 ]\tLoss: 0.001201\n",
      "====> Timestamp 2019-11-27 20:13:39.356566 Epoch: 22 Average loss: 0.00107427\n",
      "epoch: 22====> Test set loss: 0.14172040\n",
      "Timestamp 2019-11-27 20:13:52.668008 Train Epoch: 23 [10/200 ]\tLoss: 0.000790\n",
      "Timestamp 2019-11-27 20:13:55.019440 Train Epoch: 23 [20/200 ]\tLoss: 0.000919\n",
      "Timestamp 2019-11-27 20:13:57.364427 Train Epoch: 23 [30/200 ]\tLoss: 0.000919\n",
      "Timestamp 2019-11-27 20:13:59.716267 Train Epoch: 23 [40/200 ]\tLoss: 0.001288\n",
      "Timestamp 2019-11-27 20:14:02.060247 Train Epoch: 23 [50/200 ]\tLoss: 0.000967\n",
      "Timestamp 2019-11-27 20:14:04.411992 Train Epoch: 23 [60/200 ]\tLoss: 0.001101\n",
      "Timestamp 2019-11-27 20:14:06.748870 Train Epoch: 23 [70/200 ]\tLoss: 0.001088\n",
      "Timestamp 2019-11-27 20:14:09.110541 Train Epoch: 23 [80/200 ]\tLoss: 0.001013\n",
      "Timestamp 2019-11-27 20:14:11.455687 Train Epoch: 23 [90/200 ]\tLoss: 0.000904\n",
      "Timestamp 2019-11-27 20:14:13.796862 Train Epoch: 23 [100/200 ]\tLoss: 0.001169\n",
      "Timestamp 2019-11-27 20:14:16.134613 Train Epoch: 23 [110/200 ]\tLoss: 0.000893\n",
      "Timestamp 2019-11-27 20:14:18.490443 Train Epoch: 23 [120/200 ]\tLoss: 0.000748\n",
      "Timestamp 2019-11-27 20:14:20.845422 Train Epoch: 23 [130/200 ]\tLoss: 0.001105\n",
      "Timestamp 2019-11-27 20:14:23.191202 Train Epoch: 23 [140/200 ]\tLoss: 0.001067\n",
      "Timestamp 2019-11-27 20:14:25.539163 Train Epoch: 23 [150/200 ]\tLoss: 0.001083\n",
      "Timestamp 2019-11-27 20:14:27.882843 Train Epoch: 23 [160/200 ]\tLoss: 0.001455\n",
      "Timestamp 2019-11-27 20:14:30.250921 Train Epoch: 23 [170/200 ]\tLoss: 0.001139\n",
      "Timestamp 2019-11-27 20:14:32.600222 Train Epoch: 23 [180/200 ]\tLoss: 0.000865\n",
      "Timestamp 2019-11-27 20:14:34.945768 Train Epoch: 23 [190/200 ]\tLoss: 0.001299\n",
      "Timestamp 2019-11-27 20:14:37.290920 Train Epoch: 23 [200/200 ]\tLoss: 0.001108\n",
      "====> Timestamp 2019-11-27 20:14:37.333433 Epoch: 23 Average loss: 0.00106607\n",
      "epoch: 23====> Test set loss: 0.14191750\n",
      "Timestamp 2019-11-27 20:14:50.665646 Train Epoch: 24 [10/200 ]\tLoss: 0.000808\n",
      "Timestamp 2019-11-27 20:14:53.019470 Train Epoch: 24 [20/200 ]\tLoss: 0.000928\n",
      "Timestamp 2019-11-27 20:14:55.359955 Train Epoch: 24 [30/200 ]\tLoss: 0.000920\n",
      "Timestamp 2019-11-27 20:14:57.689914 Train Epoch: 24 [40/200 ]\tLoss: 0.001273\n",
      "Timestamp 2019-11-27 20:15:00.025242 Train Epoch: 24 [50/200 ]\tLoss: 0.001007\n",
      "Timestamp 2019-11-27 20:15:02.360812 Train Epoch: 24 [60/200 ]\tLoss: 0.001097\n",
      "Timestamp 2019-11-27 20:15:04.705423 Train Epoch: 24 [70/200 ]\tLoss: 0.001098\n",
      "Timestamp 2019-11-27 20:15:07.043930 Train Epoch: 24 [80/200 ]\tLoss: 0.000949\n",
      "Timestamp 2019-11-27 20:15:09.386259 Train Epoch: 24 [90/200 ]\tLoss: 0.000949\n",
      "Timestamp 2019-11-27 20:15:11.717643 Train Epoch: 24 [100/200 ]\tLoss: 0.001141\n",
      "Timestamp 2019-11-27 20:15:14.052245 Train Epoch: 24 [110/200 ]\tLoss: 0.000868\n",
      "Timestamp 2019-11-27 20:15:16.382590 Train Epoch: 24 [120/200 ]\tLoss: 0.000737\n",
      "Timestamp 2019-11-27 20:15:18.716907 Train Epoch: 24 [130/200 ]\tLoss: 0.001039\n",
      "Timestamp 2019-11-27 20:15:21.053229 Train Epoch: 24 [140/200 ]\tLoss: 0.001032\n",
      "Timestamp 2019-11-27 20:15:23.384702 Train Epoch: 24 [150/200 ]\tLoss: 0.001071\n",
      "Timestamp 2019-11-27 20:15:25.717294 Train Epoch: 24 [160/200 ]\tLoss: 0.001456\n",
      "Timestamp 2019-11-27 20:15:28.044264 Train Epoch: 24 [170/200 ]\tLoss: 0.001101\n",
      "Timestamp 2019-11-27 20:15:30.376000 Train Epoch: 24 [180/200 ]\tLoss: 0.000912\n",
      "Timestamp 2019-11-27 20:15:32.710073 Train Epoch: 24 [190/200 ]\tLoss: 0.001291\n",
      "Timestamp 2019-11-27 20:15:35.039450 Train Epoch: 24 [200/200 ]\tLoss: 0.001162\n",
      "====> Timestamp 2019-11-27 20:15:35.082486 Epoch: 24 Average loss: 0.00106015\n",
      "epoch: 24====> Test set loss: 0.14209147\n",
      "Timestamp 2019-11-27 20:15:48.490973 Train Epoch: 25 [10/200 ]\tLoss: 0.000796\n",
      "Timestamp 2019-11-27 20:15:50.833489 Train Epoch: 25 [20/200 ]\tLoss: 0.000904\n",
      "Timestamp 2019-11-27 20:15:53.176310 Train Epoch: 25 [30/200 ]\tLoss: 0.000890\n",
      "Timestamp 2019-11-27 20:15:55.528145 Train Epoch: 25 [40/200 ]\tLoss: 0.001264\n",
      "Timestamp 2019-11-27 20:15:57.871468 Train Epoch: 25 [50/200 ]\tLoss: 0.001003\n",
      "Timestamp 2019-11-27 20:16:00.211170 Train Epoch: 25 [60/200 ]\tLoss: 0.001104\n",
      "Timestamp 2019-11-27 20:16:02.547394 Train Epoch: 25 [70/200 ]\tLoss: 0.001058\n",
      "Timestamp 2019-11-27 20:16:04.891488 Train Epoch: 25 [80/200 ]\tLoss: 0.000989\n",
      "Timestamp 2019-11-27 20:16:07.223397 Train Epoch: 25 [90/200 ]\tLoss: 0.000909\n",
      "Timestamp 2019-11-27 20:16:09.575094 Train Epoch: 25 [100/200 ]\tLoss: 0.001114\n",
      "Timestamp 2019-11-27 20:16:11.925390 Train Epoch: 25 [110/200 ]\tLoss: 0.000873\n",
      "Timestamp 2019-11-27 20:16:14.271921 Train Epoch: 25 [120/200 ]\tLoss: 0.000714\n",
      "Timestamp 2019-11-27 20:16:16.609554 Train Epoch: 25 [130/200 ]\tLoss: 0.001046\n",
      "Timestamp 2019-11-27 20:16:18.954718 Train Epoch: 25 [140/200 ]\tLoss: 0.001063\n",
      "Timestamp 2019-11-27 20:16:21.299224 Train Epoch: 25 [150/200 ]\tLoss: 0.001036\n",
      "Timestamp 2019-11-27 20:16:23.633786 Train Epoch: 25 [160/200 ]\tLoss: 0.001487\n",
      "Timestamp 2019-11-27 20:16:25.975044 Train Epoch: 25 [170/200 ]\tLoss: 0.001124\n",
      "Timestamp 2019-11-27 20:16:28.323235 Train Epoch: 25 [180/200 ]\tLoss: 0.000879\n",
      "Timestamp 2019-11-27 20:16:30.651616 Train Epoch: 25 [190/200 ]\tLoss: 0.001231\n",
      "Timestamp 2019-11-27 20:16:32.997682 Train Epoch: 25 [200/200 ]\tLoss: 0.001158\n",
      "====> Timestamp 2019-11-27 20:16:33.041253 Epoch: 25 Average loss: 0.00105423\n",
      "epoch: 25====> Test set loss: 0.14348168\n",
      "Timestamp 2019-11-27 20:16:46.357504 Train Epoch: 26 [10/200 ]\tLoss: 0.000789\n",
      "Timestamp 2019-11-27 20:16:48.706727 Train Epoch: 26 [20/200 ]\tLoss: 0.000896\n",
      "Timestamp 2019-11-27 20:16:51.049293 Train Epoch: 26 [30/200 ]\tLoss: 0.000927\n",
      "Timestamp 2019-11-27 20:16:53.395726 Train Epoch: 26 [40/200 ]\tLoss: 0.001260\n",
      "Timestamp 2019-11-27 20:16:55.742895 Train Epoch: 26 [50/200 ]\tLoss: 0.000994\n",
      "Timestamp 2019-11-27 20:16:58.093650 Train Epoch: 26 [60/200 ]\tLoss: 0.001054\n",
      "Timestamp 2019-11-27 20:17:00.439534 Train Epoch: 26 [70/200 ]\tLoss: 0.001114\n",
      "Timestamp 2019-11-27 20:17:02.780511 Train Epoch: 26 [80/200 ]\tLoss: 0.000942\n",
      "Timestamp 2019-11-27 20:17:05.135440 Train Epoch: 26 [90/200 ]\tLoss: 0.000871\n",
      "Timestamp 2019-11-27 20:17:07.481217 Train Epoch: 26 [100/200 ]\tLoss: 0.001130\n",
      "Timestamp 2019-11-27 20:17:09.849372 Train Epoch: 26 [110/200 ]\tLoss: 0.000879\n",
      "Timestamp 2019-11-27 20:17:12.201747 Train Epoch: 26 [120/200 ]\tLoss: 0.000728\n",
      "Timestamp 2019-11-27 20:17:14.543929 Train Epoch: 26 [130/200 ]\tLoss: 0.001070\n",
      "Timestamp 2019-11-27 20:17:16.883187 Train Epoch: 26 [140/200 ]\tLoss: 0.001005\n",
      "Timestamp 2019-11-27 20:17:19.232202 Train Epoch: 26 [150/200 ]\tLoss: 0.001050\n",
      "Timestamp 2019-11-27 20:17:21.578818 Train Epoch: 26 [160/200 ]\tLoss: 0.001423\n",
      "Timestamp 2019-11-27 20:17:23.918347 Train Epoch: 26 [170/200 ]\tLoss: 0.001068\n",
      "Timestamp 2019-11-27 20:17:26.268041 Train Epoch: 26 [180/200 ]\tLoss: 0.000835\n",
      "Timestamp 2019-11-27 20:17:28.607724 Train Epoch: 26 [190/200 ]\tLoss: 0.001225\n",
      "Timestamp 2019-11-27 20:17:30.934479 Train Epoch: 26 [200/200 ]\tLoss: 0.001054\n",
      "====> Timestamp 2019-11-27 20:17:30.977315 Epoch: 26 Average loss: 0.00104263\n",
      "epoch: 26====> Test set loss: 0.14271314\n",
      "Timestamp 2019-11-27 20:17:44.395227 Train Epoch: 27 [10/200 ]\tLoss: 0.000779\n",
      "Timestamp 2019-11-27 20:17:46.738920 Train Epoch: 27 [20/200 ]\tLoss: 0.000899\n",
      "Timestamp 2019-11-27 20:17:49.081680 Train Epoch: 27 [30/200 ]\tLoss: 0.000912\n",
      "Timestamp 2019-11-27 20:17:51.421579 Train Epoch: 27 [40/200 ]\tLoss: 0.001286\n",
      "Timestamp 2019-11-27 20:17:53.760670 Train Epoch: 27 [50/200 ]\tLoss: 0.000974\n",
      "Timestamp 2019-11-27 20:17:56.105158 Train Epoch: 27 [60/200 ]\tLoss: 0.001095\n",
      "Timestamp 2019-11-27 20:17:58.443672 Train Epoch: 27 [70/200 ]\tLoss: 0.001122\n",
      "Timestamp 2019-11-27 20:18:00.784700 Train Epoch: 27 [80/200 ]\tLoss: 0.000990\n",
      "Timestamp 2019-11-27 20:18:03.128771 Train Epoch: 27 [90/200 ]\tLoss: 0.000923\n",
      "Timestamp 2019-11-27 20:18:05.466985 Train Epoch: 27 [100/200 ]\tLoss: 0.001111\n",
      "Timestamp 2019-11-27 20:18:07.812819 Train Epoch: 27 [110/200 ]\tLoss: 0.000850\n",
      "Timestamp 2019-11-27 20:18:10.172445 Train Epoch: 27 [120/200 ]\tLoss: 0.000742\n",
      "Timestamp 2019-11-27 20:18:12.518362 Train Epoch: 27 [130/200 ]\tLoss: 0.001075\n",
      "Timestamp 2019-11-27 20:18:14.855431 Train Epoch: 27 [140/200 ]\tLoss: 0.001027\n",
      "Timestamp 2019-11-27 20:18:17.202663 Train Epoch: 27 [150/200 ]\tLoss: 0.001049\n",
      "Timestamp 2019-11-27 20:18:19.545164 Train Epoch: 27 [160/200 ]\tLoss: 0.001417\n",
      "Timestamp 2019-11-27 20:18:21.890908 Train Epoch: 27 [170/200 ]\tLoss: 0.001127\n",
      "Timestamp 2019-11-27 20:18:24.222291 Train Epoch: 27 [180/200 ]\tLoss: 0.000858\n",
      "Timestamp 2019-11-27 20:18:26.557792 Train Epoch: 27 [190/200 ]\tLoss: 0.001247\n",
      "Timestamp 2019-11-27 20:18:28.886458 Train Epoch: 27 [200/200 ]\tLoss: 0.001085\n",
      "====> Timestamp 2019-11-27 20:18:28.933538 Epoch: 27 Average loss: 0.00103956\n",
      "epoch: 27====> Test set loss: 0.14200896\n",
      "Timestamp 2019-11-27 20:18:42.366626 Train Epoch: 28 [10/200 ]\tLoss: 0.000760\n",
      "Timestamp 2019-11-27 20:18:44.712889 Train Epoch: 28 [20/200 ]\tLoss: 0.000910\n",
      "Timestamp 2019-11-27 20:18:47.052406 Train Epoch: 28 [30/200 ]\tLoss: 0.000942\n",
      "Timestamp 2019-11-27 20:18:49.384719 Train Epoch: 28 [40/200 ]\tLoss: 0.001227\n",
      "Timestamp 2019-11-27 20:18:51.726481 Train Epoch: 28 [50/200 ]\tLoss: 0.000958\n",
      "Timestamp 2019-11-27 20:18:54.062300 Train Epoch: 28 [60/200 ]\tLoss: 0.001031\n",
      "Timestamp 2019-11-27 20:18:56.406190 Train Epoch: 28 [70/200 ]\tLoss: 0.001054\n",
      "Timestamp 2019-11-27 20:18:58.743210 Train Epoch: 28 [80/200 ]\tLoss: 0.000967\n",
      "Timestamp 2019-11-27 20:19:01.077297 Train Epoch: 28 [90/200 ]\tLoss: 0.000850\n",
      "Timestamp 2019-11-27 20:19:03.418436 Train Epoch: 28 [100/200 ]\tLoss: 0.001060\n",
      "Timestamp 2019-11-27 20:19:05.754945 Train Epoch: 28 [110/200 ]\tLoss: 0.000795\n",
      "Timestamp 2019-11-27 20:19:08.085284 Train Epoch: 28 [120/200 ]\tLoss: 0.000687\n",
      "Timestamp 2019-11-27 20:19:10.440154 Train Epoch: 28 [130/200 ]\tLoss: 0.001066\n",
      "Timestamp 2019-11-27 20:19:12.780880 Train Epoch: 28 [140/200 ]\tLoss: 0.000982\n",
      "Timestamp 2019-11-27 20:19:15.110687 Train Epoch: 28 [150/200 ]\tLoss: 0.000976\n",
      "Timestamp 2019-11-27 20:19:17.444849 Train Epoch: 28 [160/200 ]\tLoss: 0.001436\n",
      "Timestamp 2019-11-27 20:19:19.780791 Train Epoch: 28 [170/200 ]\tLoss: 0.001104\n",
      "Timestamp 2019-11-27 20:19:22.112578 Train Epoch: 28 [180/200 ]\tLoss: 0.000807\n",
      "Timestamp 2019-11-27 20:19:24.449677 Train Epoch: 28 [190/200 ]\tLoss: 0.001202\n",
      "Timestamp 2019-11-27 20:19:26.785958 Train Epoch: 28 [200/200 ]\tLoss: 0.001054\n",
      "====> Timestamp 2019-11-27 20:19:26.826978 Epoch: 28 Average loss: 0.00102798\n",
      "epoch: 28====> Test set loss: 0.14406272\n",
      "Timestamp 2019-11-27 20:19:40.343319 Train Epoch: 29 [10/200 ]\tLoss: 0.000787\n",
      "Timestamp 2019-11-27 20:19:42.685262 Train Epoch: 29 [20/200 ]\tLoss: 0.000869\n",
      "Timestamp 2019-11-27 20:19:45.030343 Train Epoch: 29 [30/200 ]\tLoss: 0.000865\n",
      "Timestamp 2019-11-27 20:19:47.397961 Train Epoch: 29 [40/200 ]\tLoss: 0.001235\n",
      "Timestamp 2019-11-27 20:19:49.741675 Train Epoch: 29 [50/200 ]\tLoss: 0.000972\n",
      "Timestamp 2019-11-27 20:19:52.070740 Train Epoch: 29 [60/200 ]\tLoss: 0.001060\n",
      "Timestamp 2019-11-27 20:19:54.400412 Train Epoch: 29 [70/200 ]\tLoss: 0.001068\n",
      "Timestamp 2019-11-27 20:19:56.731642 Train Epoch: 29 [80/200 ]\tLoss: 0.000968\n",
      "Timestamp 2019-11-27 20:19:59.067418 Train Epoch: 29 [90/200 ]\tLoss: 0.000840\n",
      "Timestamp 2019-11-27 20:20:01.410769 Train Epoch: 29 [100/200 ]\tLoss: 0.001103\n",
      "Timestamp 2019-11-27 20:20:03.744987 Train Epoch: 29 [110/200 ]\tLoss: 0.000863\n",
      "Timestamp 2019-11-27 20:20:06.072504 Train Epoch: 29 [120/200 ]\tLoss: 0.000688\n",
      "Timestamp 2019-11-27 20:20:08.404485 Train Epoch: 29 [130/200 ]\tLoss: 0.001058\n",
      "Timestamp 2019-11-27 20:20:10.754936 Train Epoch: 29 [140/200 ]\tLoss: 0.000999\n",
      "Timestamp 2019-11-27 20:20:13.094238 Train Epoch: 29 [150/200 ]\tLoss: 0.001034\n",
      "Timestamp 2019-11-27 20:20:15.426214 Train Epoch: 29 [160/200 ]\tLoss: 0.001388\n",
      "Timestamp 2019-11-27 20:20:17.761227 Train Epoch: 29 [170/200 ]\tLoss: 0.001057\n",
      "Timestamp 2019-11-27 20:20:20.107088 Train Epoch: 29 [180/200 ]\tLoss: 0.000840\n",
      "Timestamp 2019-11-27 20:20:22.447502 Train Epoch: 29 [190/200 ]\tLoss: 0.001255\n",
      "Timestamp 2019-11-27 20:20:24.783849 Train Epoch: 29 [200/200 ]\tLoss: 0.001130\n",
      "====> Timestamp 2019-11-27 20:20:24.830395 Epoch: 29 Average loss: 0.00102373\n",
      "epoch: 29====> Test set loss: 0.14299831\n",
      "Timestamp 2019-11-27 20:20:38.270032 Train Epoch: 30 [10/200 ]\tLoss: 0.000750\n",
      "Timestamp 2019-11-27 20:20:40.632210 Train Epoch: 30 [20/200 ]\tLoss: 0.000894\n",
      "Timestamp 2019-11-27 20:20:42.974401 Train Epoch: 30 [30/200 ]\tLoss: 0.000894\n",
      "Timestamp 2019-11-27 20:20:45.317956 Train Epoch: 30 [40/200 ]\tLoss: 0.001223\n",
      "Timestamp 2019-11-27 20:20:47.668969 Train Epoch: 30 [50/200 ]\tLoss: 0.000982\n",
      "Timestamp 2019-11-27 20:20:50.009725 Train Epoch: 30 [60/200 ]\tLoss: 0.001081\n",
      "Timestamp 2019-11-27 20:20:52.354756 Train Epoch: 30 [70/200 ]\tLoss: 0.001038\n",
      "Timestamp 2019-11-27 20:20:54.705572 Train Epoch: 30 [80/200 ]\tLoss: 0.000954\n",
      "Timestamp 2019-11-27 20:20:57.056936 Train Epoch: 30 [90/200 ]\tLoss: 0.000832\n",
      "Timestamp 2019-11-27 20:20:59.404362 Train Epoch: 30 [100/200 ]\tLoss: 0.001061\n",
      "Timestamp 2019-11-27 20:21:01.760948 Train Epoch: 30 [110/200 ]\tLoss: 0.000815\n",
      "Timestamp 2019-11-27 20:21:04.109671 Train Epoch: 30 [120/200 ]\tLoss: 0.000714\n",
      "Timestamp 2019-11-27 20:21:06.450548 Train Epoch: 30 [130/200 ]\tLoss: 0.001031\n",
      "Timestamp 2019-11-27 20:21:08.805764 Train Epoch: 30 [140/200 ]\tLoss: 0.000975\n",
      "Timestamp 2019-11-27 20:21:11.176896 Train Epoch: 30 [150/200 ]\tLoss: 0.001027\n",
      "Timestamp 2019-11-27 20:21:13.524291 Train Epoch: 30 [160/200 ]\tLoss: 0.001448\n",
      "Timestamp 2019-11-27 20:21:15.860432 Train Epoch: 30 [170/200 ]\tLoss: 0.001098\n",
      "Timestamp 2019-11-27 20:21:18.218634 Train Epoch: 30 [180/200 ]\tLoss: 0.000824\n",
      "Timestamp 2019-11-27 20:21:20.550679 Train Epoch: 30 [190/200 ]\tLoss: 0.001221\n",
      "Timestamp 2019-11-27 20:21:22.887037 Train Epoch: 30 [200/200 ]\tLoss: 0.001094\n",
      "====> Timestamp 2019-11-27 20:21:22.933283 Epoch: 30 Average loss: 0.00101920\n",
      "epoch: 30====> Test set loss: 0.14276120\n",
      "Timestamp 2019-11-27 20:21:36.345523 Train Epoch: 31 [10/200 ]\tLoss: 0.000759\n",
      "Timestamp 2019-11-27 20:21:38.688916 Train Epoch: 31 [20/200 ]\tLoss: 0.000933\n",
      "Timestamp 2019-11-27 20:21:41.045836 Train Epoch: 31 [30/200 ]\tLoss: 0.000886\n",
      "Timestamp 2019-11-27 20:21:43.397170 Train Epoch: 31 [40/200 ]\tLoss: 0.001229\n",
      "Timestamp 2019-11-27 20:21:45.740916 Train Epoch: 31 [50/200 ]\tLoss: 0.000961\n",
      "Timestamp 2019-11-27 20:21:48.089924 Train Epoch: 31 [60/200 ]\tLoss: 0.001097\n",
      "Timestamp 2019-11-27 20:21:50.430392 Train Epoch: 31 [70/200 ]\tLoss: 0.001017\n",
      "Timestamp 2019-11-27 20:21:52.779135 Train Epoch: 31 [80/200 ]\tLoss: 0.000888\n",
      "Timestamp 2019-11-27 20:21:55.124917 Train Epoch: 31 [90/200 ]\tLoss: 0.000866\n",
      "Timestamp 2019-11-27 20:21:57.462060 Train Epoch: 31 [100/200 ]\tLoss: 0.001069\n",
      "Timestamp 2019-11-27 20:21:59.808524 Train Epoch: 31 [110/200 ]\tLoss: 0.000808\n",
      "Timestamp 2019-11-27 20:22:02.162850 Train Epoch: 31 [120/200 ]\tLoss: 0.000711\n",
      "Timestamp 2019-11-27 20:22:04.504152 Train Epoch: 31 [130/200 ]\tLoss: 0.000998\n",
      "Timestamp 2019-11-27 20:22:06.850016 Train Epoch: 31 [140/200 ]\tLoss: 0.001007\n",
      "Timestamp 2019-11-27 20:22:09.209566 Train Epoch: 31 [150/200 ]\tLoss: 0.000999\n",
      "Timestamp 2019-11-27 20:22:11.554807 Train Epoch: 31 [160/200 ]\tLoss: 0.001400\n",
      "Timestamp 2019-11-27 20:22:13.894568 Train Epoch: 31 [170/200 ]\tLoss: 0.001067\n",
      "Timestamp 2019-11-27 20:22:16.239020 Train Epoch: 31 [180/200 ]\tLoss: 0.000832\n",
      "Timestamp 2019-11-27 20:22:18.604179 Train Epoch: 31 [190/200 ]\tLoss: 0.001252\n",
      "Timestamp 2019-11-27 20:22:20.953644 Train Epoch: 31 [200/200 ]\tLoss: 0.001057\n",
      "====> Timestamp 2019-11-27 20:22:20.998563 Epoch: 31 Average loss: 0.00101382\n",
      "epoch: 31====> Test set loss: 0.14342073\n",
      "Timestamp 2019-11-27 20:22:34.456556 Train Epoch: 32 [10/200 ]\tLoss: 0.000786\n",
      "Timestamp 2019-11-27 20:22:36.807742 Train Epoch: 32 [20/200 ]\tLoss: 0.000864\n",
      "Timestamp 2019-11-27 20:22:39.168007 Train Epoch: 32 [30/200 ]\tLoss: 0.000887\n",
      "Timestamp 2019-11-27 20:22:41.508644 Train Epoch: 32 [40/200 ]\tLoss: 0.001264\n",
      "Timestamp 2019-11-27 20:22:43.852444 Train Epoch: 32 [50/200 ]\tLoss: 0.000983\n",
      "Timestamp 2019-11-27 20:22:46.197023 Train Epoch: 32 [60/200 ]\tLoss: 0.001035\n",
      "Timestamp 2019-11-27 20:22:48.539792 Train Epoch: 32 [70/200 ]\tLoss: 0.001070\n",
      "Timestamp 2019-11-27 20:22:50.899271 Train Epoch: 32 [80/200 ]\tLoss: 0.000961\n",
      "Timestamp 2019-11-27 20:22:53.247420 Train Epoch: 32 [90/200 ]\tLoss: 0.000833\n",
      "Timestamp 2019-11-27 20:22:55.584104 Train Epoch: 32 [100/200 ]\tLoss: 0.001121\n",
      "Timestamp 2019-11-27 20:22:57.925770 Train Epoch: 32 [110/200 ]\tLoss: 0.000807\n",
      "Timestamp 2019-11-27 20:23:00.268192 Train Epoch: 32 [120/200 ]\tLoss: 0.000661\n",
      "Timestamp 2019-11-27 20:23:02.611358 Train Epoch: 32 [130/200 ]\tLoss: 0.001037\n",
      "Timestamp 2019-11-27 20:23:04.954314 Train Epoch: 32 [140/200 ]\tLoss: 0.000997\n",
      "Timestamp 2019-11-27 20:23:07.292255 Train Epoch: 32 [150/200 ]\tLoss: 0.001011\n",
      "Timestamp 2019-11-27 20:23:09.646189 Train Epoch: 32 [160/200 ]\tLoss: 0.001422\n",
      "Timestamp 2019-11-27 20:23:11.998609 Train Epoch: 32 [170/200 ]\tLoss: 0.001096\n",
      "Timestamp 2019-11-27 20:23:14.355929 Train Epoch: 32 [180/200 ]\tLoss: 0.000823\n",
      "Timestamp 2019-11-27 20:23:16.704711 Train Epoch: 32 [190/200 ]\tLoss: 0.001226\n",
      "Timestamp 2019-11-27 20:23:19.040027 Train Epoch: 32 [200/200 ]\tLoss: 0.001062\n",
      "====> Timestamp 2019-11-27 20:23:19.083470 Epoch: 32 Average loss: 0.00100498\n",
      "epoch: 32====> Test set loss: 0.14280051\n",
      "Timestamp 2019-11-27 20:23:32.504689 Train Epoch: 33 [10/200 ]\tLoss: 0.000740\n",
      "Timestamp 2019-11-27 20:23:34.858077 Train Epoch: 33 [20/200 ]\tLoss: 0.000864\n",
      "Timestamp 2019-11-27 20:23:37.201380 Train Epoch: 33 [30/200 ]\tLoss: 0.000873\n",
      "Timestamp 2019-11-27 20:23:39.570219 Train Epoch: 33 [40/200 ]\tLoss: 0.001243\n",
      "Timestamp 2019-11-27 20:23:41.920309 Train Epoch: 33 [50/200 ]\tLoss: 0.000943\n",
      "Timestamp 2019-11-27 20:23:44.262517 Train Epoch: 33 [60/200 ]\tLoss: 0.001071\n",
      "Timestamp 2019-11-27 20:23:46.610290 Train Epoch: 33 [70/200 ]\tLoss: 0.000990\n",
      "Timestamp 2019-11-27 20:23:48.952781 Train Epoch: 33 [80/200 ]\tLoss: 0.000923\n",
      "Timestamp 2019-11-27 20:23:51.291533 Train Epoch: 33 [90/200 ]\tLoss: 0.000791\n",
      "Timestamp 2019-11-27 20:23:53.642810 Train Epoch: 33 [100/200 ]\tLoss: 0.001098\n",
      "Timestamp 2019-11-27 20:23:55.981734 Train Epoch: 33 [110/200 ]\tLoss: 0.000821\n",
      "Timestamp 2019-11-27 20:23:58.333327 Train Epoch: 33 [120/200 ]\tLoss: 0.000705\n",
      "Timestamp 2019-11-27 20:24:00.672814 Train Epoch: 33 [130/200 ]\tLoss: 0.001034\n",
      "Timestamp 2019-11-27 20:24:03.019446 Train Epoch: 33 [140/200 ]\tLoss: 0.000973\n",
      "Timestamp 2019-11-27 20:24:05.363473 Train Epoch: 33 [150/200 ]\tLoss: 0.000967\n",
      "Timestamp 2019-11-27 20:24:07.702576 Train Epoch: 33 [160/200 ]\tLoss: 0.001422\n",
      "Timestamp 2019-11-27 20:24:10.054401 Train Epoch: 33 [170/200 ]\tLoss: 0.001032\n",
      "Timestamp 2019-11-27 20:24:12.384338 Train Epoch: 33 [180/200 ]\tLoss: 0.000807\n",
      "Timestamp 2019-11-27 20:24:14.731851 Train Epoch: 33 [190/200 ]\tLoss: 0.001235\n",
      "Timestamp 2019-11-27 20:24:17.070997 Train Epoch: 33 [200/200 ]\tLoss: 0.001056\n",
      "====> Timestamp 2019-11-27 20:24:17.114733 Epoch: 33 Average loss: 0.00099914\n",
      "epoch: 33====> Test set loss: 0.14417254\n",
      "Timestamp 2019-11-27 20:24:30.467023 Train Epoch: 34 [10/200 ]\tLoss: 0.000708\n",
      "Timestamp 2019-11-27 20:24:32.811818 Train Epoch: 34 [20/200 ]\tLoss: 0.000807\n",
      "Timestamp 2019-11-27 20:24:35.169985 Train Epoch: 34 [30/200 ]\tLoss: 0.000888\n",
      "Timestamp 2019-11-27 20:24:37.529501 Train Epoch: 34 [40/200 ]\tLoss: 0.001141\n",
      "Timestamp 2019-11-27 20:24:39.896056 Train Epoch: 34 [50/200 ]\tLoss: 0.000961\n",
      "Timestamp 2019-11-27 20:24:42.242250 Train Epoch: 34 [60/200 ]\tLoss: 0.001025\n",
      "Timestamp 2019-11-27 20:24:44.581664 Train Epoch: 34 [70/200 ]\tLoss: 0.001023\n",
      "Timestamp 2019-11-27 20:24:46.922794 Train Epoch: 34 [80/200 ]\tLoss: 0.000933\n",
      "Timestamp 2019-11-27 20:24:49.257160 Train Epoch: 34 [90/200 ]\tLoss: 0.000786\n",
      "Timestamp 2019-11-27 20:24:51.596325 Train Epoch: 34 [100/200 ]\tLoss: 0.001070\n",
      "Timestamp 2019-11-27 20:24:53.941561 Train Epoch: 34 [110/200 ]\tLoss: 0.000795\n",
      "Timestamp 2019-11-27 20:24:56.281091 Train Epoch: 34 [120/200 ]\tLoss: 0.000705\n",
      "Timestamp 2019-11-27 20:24:58.636804 Train Epoch: 34 [130/200 ]\tLoss: 0.000984\n",
      "Timestamp 2019-11-27 20:25:00.980969 Train Epoch: 34 [140/200 ]\tLoss: 0.000984\n",
      "Timestamp 2019-11-27 20:25:03.321081 Train Epoch: 34 [150/200 ]\tLoss: 0.000951\n",
      "Timestamp 2019-11-27 20:25:05.666482 Train Epoch: 34 [160/200 ]\tLoss: 0.001417\n",
      "Timestamp 2019-11-27 20:25:08.015094 Train Epoch: 34 [170/200 ]\tLoss: 0.001040\n",
      "Timestamp 2019-11-27 20:25:10.364494 Train Epoch: 34 [180/200 ]\tLoss: 0.000821\n",
      "Timestamp 2019-11-27 20:25:12.702503 Train Epoch: 34 [190/200 ]\tLoss: 0.001208\n",
      "Timestamp 2019-11-27 20:25:15.038902 Train Epoch: 34 [200/200 ]\tLoss: 0.001029\n",
      "====> Timestamp 2019-11-27 20:25:15.082539 Epoch: 34 Average loss: 0.00098896\n",
      "epoch: 34====> Test set loss: 0.14360237\n",
      "Timestamp 2019-11-27 20:25:28.508122 Train Epoch: 35 [10/200 ]\tLoss: 0.000742\n",
      "Timestamp 2019-11-27 20:25:30.855653 Train Epoch: 35 [20/200 ]\tLoss: 0.000880\n",
      "Timestamp 2019-11-27 20:25:33.210489 Train Epoch: 35 [30/200 ]\tLoss: 0.000859\n",
      "Timestamp 2019-11-27 20:25:35.550900 Train Epoch: 35 [40/200 ]\tLoss: 0.001199\n",
      "Timestamp 2019-11-27 20:25:37.902182 Train Epoch: 35 [50/200 ]\tLoss: 0.000964\n",
      "Timestamp 2019-11-27 20:25:40.274743 Train Epoch: 35 [60/200 ]\tLoss: 0.001006\n",
      "Timestamp 2019-11-27 20:25:42.616378 Train Epoch: 35 [70/200 ]\tLoss: 0.000971\n",
      "Timestamp 2019-11-27 20:25:44.966832 Train Epoch: 35 [80/200 ]\tLoss: 0.000907\n",
      "Timestamp 2019-11-27 20:25:47.313841 Train Epoch: 35 [90/200 ]\tLoss: 0.000842\n",
      "Timestamp 2019-11-27 20:25:49.669381 Train Epoch: 35 [100/200 ]\tLoss: 0.001089\n",
      "Timestamp 2019-11-27 20:25:52.016558 Train Epoch: 35 [110/200 ]\tLoss: 0.000795\n",
      "Timestamp 2019-11-27 20:25:54.380514 Train Epoch: 35 [120/200 ]\tLoss: 0.000696\n",
      "Timestamp 2019-11-27 20:25:56.726768 Train Epoch: 35 [130/200 ]\tLoss: 0.000980\n",
      "Timestamp 2019-11-27 20:25:59.073812 Train Epoch: 35 [140/200 ]\tLoss: 0.000961\n",
      "Timestamp 2019-11-27 20:26:01.419420 Train Epoch: 35 [150/200 ]\tLoss: 0.000923\n",
      "Timestamp 2019-11-27 20:26:03.771326 Train Epoch: 35 [160/200 ]\tLoss: 0.001353\n",
      "Timestamp 2019-11-27 20:26:06.120102 Train Epoch: 35 [170/200 ]\tLoss: 0.000989\n",
      "Timestamp 2019-11-27 20:26:08.474648 Train Epoch: 35 [180/200 ]\tLoss: 0.000816\n",
      "Timestamp 2019-11-27 20:26:10.839927 Train Epoch: 35 [190/200 ]\tLoss: 0.001201\n",
      "Timestamp 2019-11-27 20:26:13.185070 Train Epoch: 35 [200/200 ]\tLoss: 0.001030\n",
      "====> Timestamp 2019-11-27 20:26:13.228692 Epoch: 35 Average loss: 0.00098279\n",
      "epoch: 35====> Test set loss: 0.14430714\n",
      "Timestamp 2019-11-27 20:26:26.574402 Train Epoch: 36 [10/200 ]\tLoss: 0.000723\n",
      "Timestamp 2019-11-27 20:26:28.925878 Train Epoch: 36 [20/200 ]\tLoss: 0.000853\n",
      "Timestamp 2019-11-27 20:26:31.273251 Train Epoch: 36 [30/200 ]\tLoss: 0.000809\n",
      "Timestamp 2019-11-27 20:26:33.624756 Train Epoch: 36 [40/200 ]\tLoss: 0.001198\n",
      "Timestamp 2019-11-27 20:26:35.974807 Train Epoch: 36 [50/200 ]\tLoss: 0.000954\n",
      "Timestamp 2019-11-27 20:26:38.322213 Train Epoch: 36 [60/200 ]\tLoss: 0.001024\n",
      "Timestamp 2019-11-27 20:26:40.677461 Train Epoch: 36 [70/200 ]\tLoss: 0.001026\n",
      "Timestamp 2019-11-27 20:26:43.022451 Train Epoch: 36 [80/200 ]\tLoss: 0.000890\n",
      "Timestamp 2019-11-27 20:26:45.368426 Train Epoch: 36 [90/200 ]\tLoss: 0.000834\n",
      "Timestamp 2019-11-27 20:26:47.707038 Train Epoch: 36 [100/200 ]\tLoss: 0.001059\n",
      "Timestamp 2019-11-27 20:26:50.064868 Train Epoch: 36 [110/200 ]\tLoss: 0.000826\n",
      "Timestamp 2019-11-27 20:26:52.411296 Train Epoch: 36 [120/200 ]\tLoss: 0.000662\n",
      "Timestamp 2019-11-27 20:26:54.758450 Train Epoch: 36 [130/200 ]\tLoss: 0.000985\n",
      "Timestamp 2019-11-27 20:26:57.105806 Train Epoch: 36 [140/200 ]\tLoss: 0.000984\n",
      "Timestamp 2019-11-27 20:26:59.453103 Train Epoch: 36 [150/200 ]\tLoss: 0.000973\n",
      "Timestamp 2019-11-27 20:27:01.796450 Train Epoch: 36 [160/200 ]\tLoss: 0.001405\n",
      "Timestamp 2019-11-27 20:27:04.146550 Train Epoch: 36 [170/200 ]\tLoss: 0.001064\n",
      "Timestamp 2019-11-27 20:27:06.495066 Train Epoch: 36 [180/200 ]\tLoss: 0.000770\n",
      "Timestamp 2019-11-27 20:27:08.856769 Train Epoch: 36 [190/200 ]\tLoss: 0.001211\n",
      "Timestamp 2019-11-27 20:27:11.232683 Train Epoch: 36 [200/200 ]\tLoss: 0.001022\n",
      "====> Timestamp 2019-11-27 20:27:11.276365 Epoch: 36 Average loss: 0.00097836\n",
      "epoch: 36====> Test set loss: 0.14568279\n",
      "Timestamp 2019-11-27 20:27:24.585582 Train Epoch: 37 [10/200 ]\tLoss: 0.000719\n",
      "Timestamp 2019-11-27 20:27:26.928969 Train Epoch: 37 [20/200 ]\tLoss: 0.000879\n",
      "Timestamp 2019-11-27 20:27:29.365113 Train Epoch: 37 [30/200 ]\tLoss: 0.000846\n",
      "Timestamp 2019-11-27 20:27:31.786341 Train Epoch: 37 [40/200 ]\tLoss: 0.001177\n",
      "Timestamp 2019-11-27 20:27:34.188984 Train Epoch: 37 [50/200 ]\tLoss: 0.000932\n",
      "Timestamp 2019-11-27 20:27:36.558907 Train Epoch: 37 [60/200 ]\tLoss: 0.000962\n",
      "Timestamp 2019-11-27 20:27:38.877048 Train Epoch: 37 [70/200 ]\tLoss: 0.000979\n",
      "Timestamp 2019-11-27 20:27:41.161593 Train Epoch: 37 [80/200 ]\tLoss: 0.000906\n",
      "Timestamp 2019-11-27 20:27:43.441527 Train Epoch: 37 [90/200 ]\tLoss: 0.000816\n",
      "Timestamp 2019-11-27 20:27:45.724420 Train Epoch: 37 [100/200 ]\tLoss: 0.000998\n",
      "Timestamp 2019-11-27 20:27:48.005643 Train Epoch: 37 [110/200 ]\tLoss: 0.000789\n",
      "Timestamp 2019-11-27 20:27:50.281182 Train Epoch: 37 [120/200 ]\tLoss: 0.000650\n",
      "Timestamp 2019-11-27 20:27:52.554999 Train Epoch: 37 [130/200 ]\tLoss: 0.000964\n",
      "Timestamp 2019-11-27 20:27:54.832261 Train Epoch: 37 [140/200 ]\tLoss: 0.000970\n",
      "Timestamp 2019-11-27 20:27:57.110760 Train Epoch: 37 [150/200 ]\tLoss: 0.000935\n",
      "Timestamp 2019-11-27 20:27:59.387753 Train Epoch: 37 [160/200 ]\tLoss: 0.001402\n",
      "Timestamp 2019-11-27 20:28:01.663463 Train Epoch: 37 [170/200 ]\tLoss: 0.000965\n",
      "Timestamp 2019-11-27 20:28:03.932809 Train Epoch: 37 [180/200 ]\tLoss: 0.000804\n",
      "Timestamp 2019-11-27 20:28:06.200372 Train Epoch: 37 [190/200 ]\tLoss: 0.001271\n",
      "Timestamp 2019-11-27 20:28:08.471761 Train Epoch: 37 [200/200 ]\tLoss: 0.001052\n",
      "====> Timestamp 2019-11-27 20:28:08.516856 Epoch: 37 Average loss: 0.00097169\n",
      "epoch: 37====> Test set loss: 0.14532080\n",
      "Timestamp 2019-11-27 20:28:21.612230 Train Epoch: 38 [10/200 ]\tLoss: 0.000688\n",
      "Timestamp 2019-11-27 20:28:23.897513 Train Epoch: 38 [20/200 ]\tLoss: 0.000905\n",
      "Timestamp 2019-11-27 20:28:26.170798 Train Epoch: 38 [30/200 ]\tLoss: 0.000861\n",
      "Timestamp 2019-11-27 20:28:28.442244 Train Epoch: 38 [40/200 ]\tLoss: 0.001160\n",
      "Timestamp 2019-11-27 20:28:30.709160 Train Epoch: 38 [50/200 ]\tLoss: 0.000938\n",
      "Timestamp 2019-11-27 20:28:32.981992 Train Epoch: 38 [60/200 ]\tLoss: 0.000940\n",
      "Timestamp 2019-11-27 20:28:35.253306 Train Epoch: 38 [70/200 ]\tLoss: 0.001022\n",
      "Timestamp 2019-11-27 20:28:37.524096 Train Epoch: 38 [80/200 ]\tLoss: 0.000880\n",
      "Timestamp 2019-11-27 20:28:39.797404 Train Epoch: 38 [90/200 ]\tLoss: 0.000816\n",
      "Timestamp 2019-11-27 20:28:42.067875 Train Epoch: 38 [100/200 ]\tLoss: 0.000995\n",
      "Timestamp 2019-11-27 20:28:44.339432 Train Epoch: 38 [110/200 ]\tLoss: 0.000761\n",
      "Timestamp 2019-11-27 20:28:46.607338 Train Epoch: 38 [120/200 ]\tLoss: 0.000694\n",
      "Timestamp 2019-11-27 20:28:48.881597 Train Epoch: 38 [130/200 ]\tLoss: 0.001019\n",
      "Timestamp 2019-11-27 20:28:51.156753 Train Epoch: 38 [140/200 ]\tLoss: 0.000984\n",
      "Timestamp 2019-11-27 20:28:53.427866 Train Epoch: 38 [150/200 ]\tLoss: 0.000893\n",
      "Timestamp 2019-11-27 20:28:55.699812 Train Epoch: 38 [160/200 ]\tLoss: 0.001332\n",
      "Timestamp 2019-11-27 20:28:57.963225 Train Epoch: 38 [170/200 ]\tLoss: 0.001033\n",
      "Timestamp 2019-11-27 20:29:00.246761 Train Epoch: 38 [180/200 ]\tLoss: 0.000812\n",
      "Timestamp 2019-11-27 20:29:02.516777 Train Epoch: 38 [190/200 ]\tLoss: 0.001240\n",
      "Timestamp 2019-11-27 20:29:04.787276 Train Epoch: 38 [200/200 ]\tLoss: 0.001030\n",
      "====> Timestamp 2019-11-27 20:29:04.830364 Epoch: 38 Average loss: 0.00096687\n",
      "epoch: 38====> Test set loss: 0.14744465\n",
      "Timestamp 2019-11-27 20:29:17.940581 Train Epoch: 39 [10/200 ]\tLoss: 0.000695\n",
      "Timestamp 2019-11-27 20:29:20.228647 Train Epoch: 39 [20/200 ]\tLoss: 0.000855\n",
      "Timestamp 2019-11-27 20:29:22.508698 Train Epoch: 39 [30/200 ]\tLoss: 0.000877\n",
      "Timestamp 2019-11-27 20:29:24.793840 Train Epoch: 39 [40/200 ]\tLoss: 0.001184\n",
      "Timestamp 2019-11-27 20:29:27.078507 Train Epoch: 39 [50/200 ]\tLoss: 0.000940\n",
      "Timestamp 2019-11-27 20:29:29.357535 Train Epoch: 39 [60/200 ]\tLoss: 0.000964\n",
      "Timestamp 2019-11-27 20:29:31.634491 Train Epoch: 39 [70/200 ]\tLoss: 0.000991\n",
      "Timestamp 2019-11-27 20:29:33.914342 Train Epoch: 39 [80/200 ]\tLoss: 0.000903\n",
      "Timestamp 2019-11-27 20:29:36.188627 Train Epoch: 39 [90/200 ]\tLoss: 0.000849\n",
      "Timestamp 2019-11-27 20:29:38.466265 Train Epoch: 39 [100/200 ]\tLoss: 0.001021\n",
      "Timestamp 2019-11-27 20:29:40.760199 Train Epoch: 39 [110/200 ]\tLoss: 0.000799\n",
      "Timestamp 2019-11-27 20:29:43.039056 Train Epoch: 39 [120/200 ]\tLoss: 0.000650\n",
      "Timestamp 2019-11-27 20:29:45.318539 Train Epoch: 39 [130/200 ]\tLoss: 0.000973\n",
      "Timestamp 2019-11-27 20:29:47.600356 Train Epoch: 39 [140/200 ]\tLoss: 0.000935\n",
      "Timestamp 2019-11-27 20:29:49.892362 Train Epoch: 39 [150/200 ]\tLoss: 0.000918\n",
      "Timestamp 2019-11-27 20:29:52.173947 Train Epoch: 39 [160/200 ]\tLoss: 0.001337\n",
      "Timestamp 2019-11-27 20:29:54.450778 Train Epoch: 39 [170/200 ]\tLoss: 0.001045\n",
      "Timestamp 2019-11-27 20:29:56.731085 Train Epoch: 39 [180/200 ]\tLoss: 0.000771\n",
      "Timestamp 2019-11-27 20:29:59.016250 Train Epoch: 39 [190/200 ]\tLoss: 0.001167\n",
      "Timestamp 2019-11-27 20:30:01.305323 Train Epoch: 39 [200/200 ]\tLoss: 0.001012\n",
      "====> Timestamp 2019-11-27 20:30:01.351218 Epoch: 39 Average loss: 0.00095927\n",
      "epoch: 39====> Test set loss: 0.14801471\n",
      "Timestamp 2019-11-27 20:30:14.466405 Train Epoch: 40 [10/200 ]\tLoss: 0.000652\n",
      "Timestamp 2019-11-27 20:30:16.742564 Train Epoch: 40 [20/200 ]\tLoss: 0.000833\n",
      "Timestamp 2019-11-27 20:30:19.025663 Train Epoch: 40 [30/200 ]\tLoss: 0.000844\n",
      "Timestamp 2019-11-27 20:30:21.305676 Train Epoch: 40 [40/200 ]\tLoss: 0.001125\n",
      "Timestamp 2019-11-27 20:30:23.582713 Train Epoch: 40 [50/200 ]\tLoss: 0.000902\n",
      "Timestamp 2019-11-27 20:30:25.858304 Train Epoch: 40 [60/200 ]\tLoss: 0.000944\n",
      "Timestamp 2019-11-27 20:30:28.136474 Train Epoch: 40 [70/200 ]\tLoss: 0.001018\n",
      "Timestamp 2019-11-27 20:30:30.423622 Train Epoch: 40 [80/200 ]\tLoss: 0.000870\n",
      "Timestamp 2019-11-27 20:30:32.707829 Train Epoch: 40 [90/200 ]\tLoss: 0.000777\n",
      "Timestamp 2019-11-27 20:30:34.987333 Train Epoch: 40 [100/200 ]\tLoss: 0.000998\n",
      "Timestamp 2019-11-27 20:30:37.266513 Train Epoch: 40 [110/200 ]\tLoss: 0.000783\n",
      "Timestamp 2019-11-27 20:30:39.558103 Train Epoch: 40 [120/200 ]\tLoss: 0.000648\n",
      "Timestamp 2019-11-27 20:30:41.840108 Train Epoch: 40 [130/200 ]\tLoss: 0.000970\n",
      "Timestamp 2019-11-27 20:30:44.117843 Train Epoch: 40 [140/200 ]\tLoss: 0.000959\n",
      "Timestamp 2019-11-27 20:30:46.400403 Train Epoch: 40 [150/200 ]\tLoss: 0.000926\n",
      "Timestamp 2019-11-27 20:30:48.673347 Train Epoch: 40 [160/200 ]\tLoss: 0.001363\n",
      "Timestamp 2019-11-27 20:30:50.955848 Train Epoch: 40 [170/200 ]\tLoss: 0.001059\n",
      "Timestamp 2019-11-27 20:30:53.238000 Train Epoch: 40 [180/200 ]\tLoss: 0.000804\n",
      "Timestamp 2019-11-27 20:30:55.520817 Train Epoch: 40 [190/200 ]\tLoss: 0.001164\n",
      "Timestamp 2019-11-27 20:30:57.803998 Train Epoch: 40 [200/200 ]\tLoss: 0.000985\n",
      "====> Timestamp 2019-11-27 20:30:57.850082 Epoch: 40 Average loss: 0.00095326\n",
      "epoch: 40====> Test set loss: 0.14630753\n",
      "Timestamp 2019-11-27 20:31:10.869908 Train Epoch: 41 [10/200 ]\tLoss: 0.000712\n",
      "Timestamp 2019-11-27 20:31:13.155472 Train Epoch: 41 [20/200 ]\tLoss: 0.000793\n",
      "Timestamp 2019-11-27 20:31:15.434498 Train Epoch: 41 [30/200 ]\tLoss: 0.000790\n",
      "Timestamp 2019-11-27 20:31:17.713553 Train Epoch: 41 [40/200 ]\tLoss: 0.001181\n",
      "Timestamp 2019-11-27 20:31:19.995575 Train Epoch: 41 [50/200 ]\tLoss: 0.000891\n",
      "Timestamp 2019-11-27 20:31:22.278104 Train Epoch: 41 [60/200 ]\tLoss: 0.000964\n",
      "Timestamp 2019-11-27 20:31:24.559251 Train Epoch: 41 [70/200 ]\tLoss: 0.000949\n",
      "Timestamp 2019-11-27 20:31:26.841603 Train Epoch: 41 [80/200 ]\tLoss: 0.000873\n",
      "Timestamp 2019-11-27 20:31:29.119253 Train Epoch: 41 [90/200 ]\tLoss: 0.000737\n",
      "Timestamp 2019-11-27 20:31:31.393331 Train Epoch: 41 [100/200 ]\tLoss: 0.000982\n",
      "Timestamp 2019-11-27 20:31:33.673732 Train Epoch: 41 [110/200 ]\tLoss: 0.000776\n",
      "Timestamp 2019-11-27 20:31:35.953725 Train Epoch: 41 [120/200 ]\tLoss: 0.000637\n",
      "Timestamp 2019-11-27 20:31:38.239747 Train Epoch: 41 [130/200 ]\tLoss: 0.000968\n",
      "Timestamp 2019-11-27 20:31:40.528560 Train Epoch: 41 [140/200 ]\tLoss: 0.000937\n",
      "Timestamp 2019-11-27 20:31:42.817071 Train Epoch: 41 [150/200 ]\tLoss: 0.000878\n",
      "Timestamp 2019-11-27 20:31:45.093371 Train Epoch: 41 [160/200 ]\tLoss: 0.001335\n",
      "Timestamp 2019-11-27 20:31:47.376588 Train Epoch: 41 [170/200 ]\tLoss: 0.001000\n",
      "Timestamp 2019-11-27 20:31:49.666230 Train Epoch: 41 [180/200 ]\tLoss: 0.000777\n",
      "Timestamp 2019-11-27 20:31:51.946377 Train Epoch: 41 [190/200 ]\tLoss: 0.001195\n",
      "Timestamp 2019-11-27 20:31:54.227270 Train Epoch: 41 [200/200 ]\tLoss: 0.000956\n",
      "====> Timestamp 2019-11-27 20:31:54.273078 Epoch: 41 Average loss: 0.00094099\n",
      "epoch: 41====> Test set loss: 0.14838422\n",
      "Timestamp 2019-11-27 20:32:07.249640 Train Epoch: 42 [10/200 ]\tLoss: 0.000678\n",
      "Timestamp 2019-11-27 20:32:09.543661 Train Epoch: 42 [20/200 ]\tLoss: 0.000801\n",
      "Timestamp 2019-11-27 20:32:11.817640 Train Epoch: 42 [30/200 ]\tLoss: 0.000789\n",
      "Timestamp 2019-11-27 20:32:14.094680 Train Epoch: 42 [40/200 ]\tLoss: 0.001159\n",
      "Timestamp 2019-11-27 20:32:16.375130 Train Epoch: 42 [50/200 ]\tLoss: 0.000874\n",
      "Timestamp 2019-11-27 20:32:18.661833 Train Epoch: 42 [60/200 ]\tLoss: 0.000973\n",
      "Timestamp 2019-11-27 20:32:20.940550 Train Epoch: 42 [70/200 ]\tLoss: 0.001036\n",
      "Timestamp 2019-11-27 20:32:23.218369 Train Epoch: 42 [80/200 ]\tLoss: 0.000861\n",
      "Timestamp 2019-11-27 20:32:25.499022 Train Epoch: 42 [90/200 ]\tLoss: 0.000756\n",
      "Timestamp 2019-11-27 20:32:27.777371 Train Epoch: 42 [100/200 ]\tLoss: 0.001018\n",
      "Timestamp 2019-11-27 20:32:30.052389 Train Epoch: 42 [110/200 ]\tLoss: 0.000797\n",
      "Timestamp 2019-11-27 20:32:32.328645 Train Epoch: 42 [120/200 ]\tLoss: 0.000662\n",
      "Timestamp 2019-11-27 20:32:34.603146 Train Epoch: 42 [130/200 ]\tLoss: 0.000957\n",
      "Timestamp 2019-11-27 20:32:36.888249 Train Epoch: 42 [140/200 ]\tLoss: 0.000953\n",
      "Timestamp 2019-11-27 20:32:39.174470 Train Epoch: 42 [150/200 ]\tLoss: 0.000906\n",
      "Timestamp 2019-11-27 20:32:41.454967 Train Epoch: 42 [160/200 ]\tLoss: 0.001339\n",
      "Timestamp 2019-11-27 20:32:43.737965 Train Epoch: 42 [170/200 ]\tLoss: 0.000969\n",
      "Timestamp 2019-11-27 20:32:46.018105 Train Epoch: 42 [180/200 ]\tLoss: 0.000794\n",
      "Timestamp 2019-11-27 20:32:48.296363 Train Epoch: 42 [190/200 ]\tLoss: 0.001213\n",
      "Timestamp 2019-11-27 20:32:50.576787 Train Epoch: 42 [200/200 ]\tLoss: 0.000990\n",
      "====> Timestamp 2019-11-27 20:32:50.620561 Epoch: 42 Average loss: 0.00093680\n",
      "epoch: 42====> Test set loss: 0.14823547\n",
      "Timestamp 2019-11-27 20:33:03.673757 Train Epoch: 43 [10/200 ]\tLoss: 0.000661\n",
      "Timestamp 2019-11-27 20:33:05.950524 Train Epoch: 43 [20/200 ]\tLoss: 0.000833\n",
      "Timestamp 2019-11-27 20:33:08.226564 Train Epoch: 43 [30/200 ]\tLoss: 0.000772\n",
      "Timestamp 2019-11-27 20:33:10.515511 Train Epoch: 43 [40/200 ]\tLoss: 0.001132\n",
      "Timestamp 2019-11-27 20:33:12.791756 Train Epoch: 43 [50/200 ]\tLoss: 0.000876\n",
      "Timestamp 2019-11-27 20:33:15.070615 Train Epoch: 43 [60/200 ]\tLoss: 0.000967\n",
      "Timestamp 2019-11-27 20:33:17.348295 Train Epoch: 43 [70/200 ]\tLoss: 0.000993\n",
      "Timestamp 2019-11-27 20:33:19.628572 Train Epoch: 43 [80/200 ]\tLoss: 0.000869\n",
      "Timestamp 2019-11-27 20:33:21.915821 Train Epoch: 43 [90/200 ]\tLoss: 0.000771\n",
      "Timestamp 2019-11-27 20:33:24.200586 Train Epoch: 43 [100/200 ]\tLoss: 0.001021\n",
      "Timestamp 2019-11-27 20:33:26.481289 Train Epoch: 43 [110/200 ]\tLoss: 0.000782\n",
      "Timestamp 2019-11-27 20:33:28.758814 Train Epoch: 43 [120/200 ]\tLoss: 0.000632\n",
      "Timestamp 2019-11-27 20:33:31.036220 Train Epoch: 43 [130/200 ]\tLoss: 0.000932\n",
      "Timestamp 2019-11-27 20:33:33.323582 Train Epoch: 43 [140/200 ]\tLoss: 0.000941\n",
      "Timestamp 2019-11-27 20:33:35.601091 Train Epoch: 43 [150/200 ]\tLoss: 0.000887\n",
      "Timestamp 2019-11-27 20:33:37.887388 Train Epoch: 43 [160/200 ]\tLoss: 0.001341\n",
      "Timestamp 2019-11-27 20:33:40.180091 Train Epoch: 43 [170/200 ]\tLoss: 0.000998\n",
      "Timestamp 2019-11-27 20:33:42.462617 Train Epoch: 43 [180/200 ]\tLoss: 0.000734\n",
      "Timestamp 2019-11-27 20:33:44.750419 Train Epoch: 43 [190/200 ]\tLoss: 0.001181\n",
      "Timestamp 2019-11-27 20:33:47.037107 Train Epoch: 43 [200/200 ]\tLoss: 0.000936\n",
      "====> Timestamp 2019-11-27 20:33:47.083347 Epoch: 43 Average loss: 0.00092862\n",
      "epoch: 43====> Test set loss: 0.14754095\n",
      "Timestamp 2019-11-27 20:34:00.192678 Train Epoch: 44 [10/200 ]\tLoss: 0.000669\n",
      "Timestamp 2019-11-27 20:34:02.473632 Train Epoch: 44 [20/200 ]\tLoss: 0.000815\n",
      "Timestamp 2019-11-27 20:34:04.759525 Train Epoch: 44 [30/200 ]\tLoss: 0.000804\n",
      "Timestamp 2019-11-27 20:34:07.044370 Train Epoch: 44 [40/200 ]\tLoss: 0.001146\n",
      "Timestamp 2019-11-27 20:34:09.338706 Train Epoch: 44 [50/200 ]\tLoss: 0.000905\n",
      "Timestamp 2019-11-27 20:34:11.618899 Train Epoch: 44 [60/200 ]\tLoss: 0.000946\n",
      "Timestamp 2019-11-27 20:34:13.896593 Train Epoch: 44 [70/200 ]\tLoss: 0.000966\n",
      "Timestamp 2019-11-27 20:34:16.181387 Train Epoch: 44 [80/200 ]\tLoss: 0.000870\n",
      "Timestamp 2019-11-27 20:34:18.467011 Train Epoch: 44 [90/200 ]\tLoss: 0.000793\n",
      "Timestamp 2019-11-27 20:34:20.757082 Train Epoch: 44 [100/200 ]\tLoss: 0.000990\n",
      "Timestamp 2019-11-27 20:34:23.048794 Train Epoch: 44 [110/200 ]\tLoss: 0.000715\n",
      "Timestamp 2019-11-27 20:34:25.337293 Train Epoch: 44 [120/200 ]\tLoss: 0.000694\n",
      "Timestamp 2019-11-27 20:34:27.621223 Train Epoch: 44 [130/200 ]\tLoss: 0.000951\n",
      "Timestamp 2019-11-27 20:34:29.897674 Train Epoch: 44 [140/200 ]\tLoss: 0.000941\n",
      "Timestamp 2019-11-27 20:34:32.179419 Train Epoch: 44 [150/200 ]\tLoss: 0.000843\n",
      "Timestamp 2019-11-27 20:34:34.462503 Train Epoch: 44 [160/200 ]\tLoss: 0.001321\n",
      "Timestamp 2019-11-27 20:34:36.742292 Train Epoch: 44 [170/200 ]\tLoss: 0.000978\n",
      "Timestamp 2019-11-27 20:34:39.034568 Train Epoch: 44 [180/200 ]\tLoss: 0.000749\n",
      "Timestamp 2019-11-27 20:34:41.320168 Train Epoch: 44 [190/200 ]\tLoss: 0.001167\n",
      "Timestamp 2019-11-27 20:34:43.599699 Train Epoch: 44 [200/200 ]\tLoss: 0.000924\n",
      "====> Timestamp 2019-11-27 20:34:43.645945 Epoch: 44 Average loss: 0.00092592\n",
      "epoch: 44====> Test set loss: 0.15108590\n",
      "Timestamp 2019-11-27 20:34:56.783417 Train Epoch: 45 [10/200 ]\tLoss: 0.000661\n",
      "Timestamp 2019-11-27 20:34:59.058272 Train Epoch: 45 [20/200 ]\tLoss: 0.000792\n",
      "Timestamp 2019-11-27 20:35:01.340501 Train Epoch: 45 [30/200 ]\tLoss: 0.000786\n",
      "Timestamp 2019-11-27 20:35:03.623483 Train Epoch: 45 [40/200 ]\tLoss: 0.001192\n",
      "Timestamp 2019-11-27 20:35:05.905867 Train Epoch: 45 [50/200 ]\tLoss: 0.000897\n",
      "Timestamp 2019-11-27 20:35:08.192748 Train Epoch: 45 [60/200 ]\tLoss: 0.001003\n",
      "Timestamp 2019-11-27 20:35:10.477996 Train Epoch: 45 [70/200 ]\tLoss: 0.000929\n",
      "Timestamp 2019-11-27 20:35:12.752200 Train Epoch: 45 [80/200 ]\tLoss: 0.000835\n",
      "Timestamp 2019-11-27 20:35:15.030986 Train Epoch: 45 [90/200 ]\tLoss: 0.000736\n",
      "Timestamp 2019-11-27 20:35:17.316209 Train Epoch: 45 [100/200 ]\tLoss: 0.000994\n",
      "Timestamp 2019-11-27 20:35:19.593703 Train Epoch: 45 [110/200 ]\tLoss: 0.000774\n",
      "Timestamp 2019-11-27 20:35:21.872887 Train Epoch: 45 [120/200 ]\tLoss: 0.000609\n",
      "Timestamp 2019-11-27 20:35:24.151439 Train Epoch: 45 [130/200 ]\tLoss: 0.000973\n",
      "Timestamp 2019-11-27 20:35:26.434863 Train Epoch: 45 [140/200 ]\tLoss: 0.000934\n",
      "Timestamp 2019-11-27 20:35:28.703427 Train Epoch: 45 [150/200 ]\tLoss: 0.000867\n",
      "Timestamp 2019-11-27 20:35:30.973713 Train Epoch: 45 [160/200 ]\tLoss: 0.001308\n",
      "Timestamp 2019-11-27 20:35:33.251725 Train Epoch: 45 [170/200 ]\tLoss: 0.000986\n",
      "Timestamp 2019-11-27 20:35:35.526722 Train Epoch: 45 [180/200 ]\tLoss: 0.000782\n",
      "Timestamp 2019-11-27 20:35:37.797201 Train Epoch: 45 [190/200 ]\tLoss: 0.001199\n",
      "Timestamp 2019-11-27 20:35:40.075442 Train Epoch: 45 [200/200 ]\tLoss: 0.000958\n",
      "====> Timestamp 2019-11-27 20:35:40.123121 Epoch: 45 Average loss: 0.00092426\n",
      "epoch: 45====> Test set loss: 0.14846915\n",
      "Timestamp 2019-11-27 20:35:53.169602 Train Epoch: 46 [10/200 ]\tLoss: 0.000679\n",
      "Timestamp 2019-11-27 20:35:55.451167 Train Epoch: 46 [20/200 ]\tLoss: 0.000816\n",
      "Timestamp 2019-11-27 20:35:57.724681 Train Epoch: 46 [30/200 ]\tLoss: 0.000794\n",
      "Timestamp 2019-11-27 20:35:59.997114 Train Epoch: 46 [40/200 ]\tLoss: 0.001112\n",
      "Timestamp 2019-11-27 20:36:02.269111 Train Epoch: 46 [50/200 ]\tLoss: 0.000911\n",
      "Timestamp 2019-11-27 20:36:04.545235 Train Epoch: 46 [60/200 ]\tLoss: 0.000973\n",
      "Timestamp 2019-11-27 20:36:06.817127 Train Epoch: 46 [70/200 ]\tLoss: 0.000933\n",
      "Timestamp 2019-11-27 20:36:09.111157 Train Epoch: 46 [80/200 ]\tLoss: 0.000906\n",
      "Timestamp 2019-11-27 20:36:11.381335 Train Epoch: 46 [90/200 ]\tLoss: 0.000700\n",
      "Timestamp 2019-11-27 20:36:13.650849 Train Epoch: 46 [100/200 ]\tLoss: 0.001012\n",
      "Timestamp 2019-11-27 20:36:15.923685 Train Epoch: 46 [110/200 ]\tLoss: 0.000771\n",
      "Timestamp 2019-11-27 20:36:18.189597 Train Epoch: 46 [120/200 ]\tLoss: 0.000602\n",
      "Timestamp 2019-11-27 20:36:20.463009 Train Epoch: 46 [130/200 ]\tLoss: 0.000965\n",
      "Timestamp 2019-11-27 20:36:22.731396 Train Epoch: 46 [140/200 ]\tLoss: 0.000906\n",
      "Timestamp 2019-11-27 20:36:25.002828 Train Epoch: 46 [150/200 ]\tLoss: 0.000883\n",
      "Timestamp 2019-11-27 20:36:27.275235 Train Epoch: 46 [160/200 ]\tLoss: 0.001275\n",
      "Timestamp 2019-11-27 20:36:29.548648 Train Epoch: 46 [170/200 ]\tLoss: 0.000983\n",
      "Timestamp 2019-11-27 20:36:31.821492 Train Epoch: 46 [180/200 ]\tLoss: 0.000711\n",
      "Timestamp 2019-11-27 20:36:34.091251 Train Epoch: 46 [190/200 ]\tLoss: 0.001137\n",
      "Timestamp 2019-11-27 20:36:36.363930 Train Epoch: 46 [200/200 ]\tLoss: 0.000951\n",
      "====> Timestamp 2019-11-27 20:36:36.407034 Epoch: 46 Average loss: 0.00091784\n",
      "epoch: 46====> Test set loss: 0.15087677\n",
      "Timestamp 2019-11-27 20:36:49.457701 Train Epoch: 47 [10/200 ]\tLoss: 0.000641\n",
      "Timestamp 2019-11-27 20:36:51.741046 Train Epoch: 47 [20/200 ]\tLoss: 0.000806\n",
      "Timestamp 2019-11-27 20:36:54.016396 Train Epoch: 47 [30/200 ]\tLoss: 0.000786\n",
      "Timestamp 2019-11-27 20:36:56.293814 Train Epoch: 47 [40/200 ]\tLoss: 0.001046\n",
      "Timestamp 2019-11-27 20:36:58.572813 Train Epoch: 47 [50/200 ]\tLoss: 0.000900\n",
      "Timestamp 2019-11-27 20:37:00.860825 Train Epoch: 47 [60/200 ]\tLoss: 0.000954\n",
      "Timestamp 2019-11-27 20:37:03.139958 Train Epoch: 47 [70/200 ]\tLoss: 0.000954\n",
      "Timestamp 2019-11-27 20:37:05.421586 Train Epoch: 47 [80/200 ]\tLoss: 0.000820\n",
      "Timestamp 2019-11-27 20:37:07.702109 Train Epoch: 47 [90/200 ]\tLoss: 0.000735\n",
      "Timestamp 2019-11-27 20:37:10.001430 Train Epoch: 47 [100/200 ]\tLoss: 0.001021\n",
      "Timestamp 2019-11-27 20:37:12.280561 Train Epoch: 47 [110/200 ]\tLoss: 0.000745\n",
      "Timestamp 2019-11-27 20:37:14.561367 Train Epoch: 47 [120/200 ]\tLoss: 0.000588\n",
      "Timestamp 2019-11-27 20:37:16.846152 Train Epoch: 47 [130/200 ]\tLoss: 0.000911\n",
      "Timestamp 2019-11-27 20:37:19.134727 Train Epoch: 47 [140/200 ]\tLoss: 0.000929\n",
      "Timestamp 2019-11-27 20:37:21.418234 Train Epoch: 47 [150/200 ]\tLoss: 0.000883\n",
      "Timestamp 2019-11-27 20:37:23.700733 Train Epoch: 47 [160/200 ]\tLoss: 0.001254\n",
      "Timestamp 2019-11-27 20:37:25.982522 Train Epoch: 47 [170/200 ]\tLoss: 0.000931\n",
      "Timestamp 2019-11-27 20:37:28.261507 Train Epoch: 47 [180/200 ]\tLoss: 0.000767\n",
      "Timestamp 2019-11-27 20:37:30.544096 Train Epoch: 47 [190/200 ]\tLoss: 0.001136\n",
      "Timestamp 2019-11-27 20:37:32.813675 Train Epoch: 47 [200/200 ]\tLoss: 0.000906\n",
      "====> Timestamp 2019-11-27 20:37:32.857083 Epoch: 47 Average loss: 0.00091423\n",
      "epoch: 47====> Test set loss: 0.15040521\n",
      "Timestamp 2019-11-27 20:37:46.068440 Train Epoch: 48 [10/200 ]\tLoss: 0.000698\n",
      "Timestamp 2019-11-27 20:37:48.344134 Train Epoch: 48 [20/200 ]\tLoss: 0.000747\n",
      "Timestamp 2019-11-27 20:37:50.621537 Train Epoch: 48 [30/200 ]\tLoss: 0.000832\n",
      "Timestamp 2019-11-27 20:37:52.892204 Train Epoch: 48 [40/200 ]\tLoss: 0.001138\n",
      "Timestamp 2019-11-27 20:37:55.160159 Train Epoch: 48 [50/200 ]\tLoss: 0.000872\n",
      "Timestamp 2019-11-27 20:37:57.433853 Train Epoch: 48 [60/200 ]\tLoss: 0.000889\n",
      "Timestamp 2019-11-27 20:37:59.703989 Train Epoch: 48 [70/200 ]\tLoss: 0.000933\n",
      "Timestamp 2019-11-27 20:38:01.981584 Train Epoch: 48 [80/200 ]\tLoss: 0.000858\n",
      "Timestamp 2019-11-27 20:38:04.255642 Train Epoch: 48 [90/200 ]\tLoss: 0.000728\n",
      "Timestamp 2019-11-27 20:38:06.527670 Train Epoch: 48 [100/200 ]\tLoss: 0.000988\n",
      "Timestamp 2019-11-27 20:38:08.808821 Train Epoch: 48 [110/200 ]\tLoss: 0.000774\n",
      "Timestamp 2019-11-27 20:38:11.084109 Train Epoch: 48 [120/200 ]\tLoss: 0.000605\n",
      "Timestamp 2019-11-27 20:38:13.352975 Train Epoch: 48 [130/200 ]\tLoss: 0.000895\n",
      "Timestamp 2019-11-27 20:38:15.626507 Train Epoch: 48 [140/200 ]\tLoss: 0.000941\n",
      "Timestamp 2019-11-27 20:38:17.898212 Train Epoch: 48 [150/200 ]\tLoss: 0.000866\n",
      "Timestamp 2019-11-27 20:38:20.173997 Train Epoch: 48 [160/200 ]\tLoss: 0.001300\n",
      "Timestamp 2019-11-27 20:38:22.447261 Train Epoch: 48 [170/200 ]\tLoss: 0.000972\n",
      "Timestamp 2019-11-27 20:38:24.723923 Train Epoch: 48 [180/200 ]\tLoss: 0.000724\n",
      "Timestamp 2019-11-27 20:38:26.994459 Train Epoch: 48 [190/200 ]\tLoss: 0.001136\n",
      "Timestamp 2019-11-27 20:38:29.274884 Train Epoch: 48 [200/200 ]\tLoss: 0.000932\n",
      "====> Timestamp 2019-11-27 20:38:29.317958 Epoch: 48 Average loss: 0.00090475\n",
      "epoch: 48====> Test set loss: 0.14888398\n",
      "Timestamp 2019-11-27 20:38:42.318017 Train Epoch: 49 [10/200 ]\tLoss: 0.000644\n",
      "Timestamp 2019-11-27 20:38:44.594812 Train Epoch: 49 [20/200 ]\tLoss: 0.000777\n",
      "Timestamp 2019-11-27 20:38:46.874744 Train Epoch: 49 [30/200 ]\tLoss: 0.000810\n",
      "Timestamp 2019-11-27 20:38:49.157972 Train Epoch: 49 [40/200 ]\tLoss: 0.001091\n",
      "Timestamp 2019-11-27 20:38:51.449214 Train Epoch: 49 [50/200 ]\tLoss: 0.000844\n",
      "Timestamp 2019-11-27 20:38:53.730929 Train Epoch: 49 [60/200 ]\tLoss: 0.000924\n",
      "Timestamp 2019-11-27 20:38:56.005394 Train Epoch: 49 [70/200 ]\tLoss: 0.000956\n",
      "Timestamp 2019-11-27 20:38:58.274810 Train Epoch: 49 [80/200 ]\tLoss: 0.000810\n",
      "Timestamp 2019-11-27 20:39:00.544716 Train Epoch: 49 [90/200 ]\tLoss: 0.000715\n",
      "Timestamp 2019-11-27 20:39:02.821288 Train Epoch: 49 [100/200 ]\tLoss: 0.000991\n",
      "Timestamp 2019-11-27 20:39:05.091959 Train Epoch: 49 [110/200 ]\tLoss: 0.000709\n",
      "Timestamp 2019-11-27 20:39:07.368648 Train Epoch: 49 [120/200 ]\tLoss: 0.000615\n",
      "Timestamp 2019-11-27 20:39:09.661713 Train Epoch: 49 [130/200 ]\tLoss: 0.000921\n",
      "Timestamp 2019-11-27 20:39:11.930947 Train Epoch: 49 [140/200 ]\tLoss: 0.000927\n",
      "Timestamp 2019-11-27 20:39:14.200683 Train Epoch: 49 [150/200 ]\tLoss: 0.000847\n",
      "Timestamp 2019-11-27 20:39:16.469652 Train Epoch: 49 [160/200 ]\tLoss: 0.001255\n",
      "Timestamp 2019-11-27 20:39:18.739613 Train Epoch: 49 [170/200 ]\tLoss: 0.000969\n",
      "Timestamp 2019-11-27 20:39:21.021228 Train Epoch: 49 [180/200 ]\tLoss: 0.000770\n",
      "Timestamp 2019-11-27 20:39:23.290032 Train Epoch: 49 [190/200 ]\tLoss: 0.001115\n",
      "Timestamp 2019-11-27 20:39:25.568133 Train Epoch: 49 [200/200 ]\tLoss: 0.000901\n",
      "====> Timestamp 2019-11-27 20:39:25.611210 Epoch: 49 Average loss: 0.00090297\n",
      "epoch: 49====> Test set loss: 0.14905296\n",
      "Timestamp 2019-11-27 20:39:38.765414 Train Epoch: 50 [10/200 ]\tLoss: 0.000625\n",
      "Timestamp 2019-11-27 20:39:41.057328 Train Epoch: 50 [20/200 ]\tLoss: 0.000797\n",
      "Timestamp 2019-11-27 20:39:43.339139 Train Epoch: 50 [30/200 ]\tLoss: 0.000830\n",
      "Timestamp 2019-11-27 20:39:45.626824 Train Epoch: 50 [40/200 ]\tLoss: 0.001154\n",
      "Timestamp 2019-11-27 20:39:47.908853 Train Epoch: 50 [50/200 ]\tLoss: 0.000889\n",
      "Timestamp 2019-11-27 20:39:50.191890 Train Epoch: 50 [60/200 ]\tLoss: 0.000931\n",
      "Timestamp 2019-11-27 20:39:52.467714 Train Epoch: 50 [70/200 ]\tLoss: 0.000933\n",
      "Timestamp 2019-11-27 20:39:54.748072 Train Epoch: 50 [80/200 ]\tLoss: 0.000853\n",
      "Timestamp 2019-11-27 20:39:57.027298 Train Epoch: 50 [90/200 ]\tLoss: 0.000705\n",
      "Timestamp 2019-11-27 20:39:59.309931 Train Epoch: 50 [100/200 ]\tLoss: 0.000967\n",
      "Timestamp 2019-11-27 20:40:01.600234 Train Epoch: 50 [110/200 ]\tLoss: 0.000750\n",
      "Timestamp 2019-11-27 20:40:03.879281 Train Epoch: 50 [120/200 ]\tLoss: 0.000635\n",
      "Timestamp 2019-11-27 20:40:06.175220 Train Epoch: 50 [130/200 ]\tLoss: 0.000879\n",
      "Timestamp 2019-11-27 20:40:08.452095 Train Epoch: 50 [140/200 ]\tLoss: 0.000926\n",
      "Timestamp 2019-11-27 20:40:10.738909 Train Epoch: 50 [150/200 ]\tLoss: 0.000888\n",
      "Timestamp 2019-11-27 20:40:13.024044 Train Epoch: 50 [160/200 ]\tLoss: 0.001265\n",
      "Timestamp 2019-11-27 20:40:15.300201 Train Epoch: 50 [170/200 ]\tLoss: 0.000971\n",
      "Timestamp 2019-11-27 20:40:17.576023 Train Epoch: 50 [180/200 ]\tLoss: 0.000706\n",
      "Timestamp 2019-11-27 20:40:19.867613 Train Epoch: 50 [190/200 ]\tLoss: 0.001153\n",
      "Timestamp 2019-11-27 20:40:22.150296 Train Epoch: 50 [200/200 ]\tLoss: 0.000955\n",
      "====> Timestamp 2019-11-27 20:40:22.194960 Epoch: 50 Average loss: 0.00089986\n",
      "epoch: 50====> Test set loss: 0.14999741\n",
      "Timestamp 2019-11-27 20:40:35.372897 Train Epoch: 51 [10/200 ]\tLoss: 0.000694\n",
      "Timestamp 2019-11-27 20:40:37.650152 Train Epoch: 51 [20/200 ]\tLoss: 0.000775\n",
      "Timestamp 2019-11-27 20:40:39.925824 Train Epoch: 51 [30/200 ]\tLoss: 0.000777\n",
      "Timestamp 2019-11-27 20:40:42.196449 Train Epoch: 51 [40/200 ]\tLoss: 0.001130\n",
      "Timestamp 2019-11-27 20:40:44.464681 Train Epoch: 51 [50/200 ]\tLoss: 0.000841\n",
      "Timestamp 2019-11-27 20:40:46.731678 Train Epoch: 51 [60/200 ]\tLoss: 0.000952\n",
      "Timestamp 2019-11-27 20:40:49.020924 Train Epoch: 51 [70/200 ]\tLoss: 0.000986\n",
      "Timestamp 2019-11-27 20:40:51.291128 Train Epoch: 51 [80/200 ]\tLoss: 0.000806\n",
      "Timestamp 2019-11-27 20:40:53.571591 Train Epoch: 51 [90/200 ]\tLoss: 0.000693\n",
      "Timestamp 2019-11-27 20:40:55.851493 Train Epoch: 51 [100/200 ]\tLoss: 0.000967\n",
      "Timestamp 2019-11-27 20:40:58.125542 Train Epoch: 51 [110/200 ]\tLoss: 0.000773\n",
      "Timestamp 2019-11-27 20:41:00.399839 Train Epoch: 51 [120/200 ]\tLoss: 0.000585\n",
      "Timestamp 2019-11-27 20:41:02.676841 Train Epoch: 51 [130/200 ]\tLoss: 0.000920\n",
      "Timestamp 2019-11-27 20:41:04.946515 Train Epoch: 51 [140/200 ]\tLoss: 0.000911\n",
      "Timestamp 2019-11-27 20:41:07.223407 Train Epoch: 51 [150/200 ]\tLoss: 0.000833\n",
      "Timestamp 2019-11-27 20:41:09.514148 Train Epoch: 51 [160/200 ]\tLoss: 0.001247\n",
      "Timestamp 2019-11-27 20:41:11.789895 Train Epoch: 51 [170/200 ]\tLoss: 0.000925\n",
      "Timestamp 2019-11-27 20:41:14.063119 Train Epoch: 51 [180/200 ]\tLoss: 0.000706\n",
      "Timestamp 2019-11-27 20:41:16.333150 Train Epoch: 51 [190/200 ]\tLoss: 0.001094\n",
      "Timestamp 2019-11-27 20:41:18.608851 Train Epoch: 51 [200/200 ]\tLoss: 0.000922\n",
      "====> Timestamp 2019-11-27 20:41:18.652137 Epoch: 51 Average loss: 0.00088904\n",
      "epoch: 51====> Test set loss: 0.15101721\n",
      "Timestamp 2019-11-27 20:41:31.701551 Train Epoch: 52 [10/200 ]\tLoss: 0.000600\n",
      "Timestamp 2019-11-27 20:41:33.982139 Train Epoch: 52 [20/200 ]\tLoss: 0.000785\n",
      "Timestamp 2019-11-27 20:41:36.268146 Train Epoch: 52 [30/200 ]\tLoss: 0.000765\n",
      "Timestamp 2019-11-27 20:41:38.546422 Train Epoch: 52 [40/200 ]\tLoss: 0.001101\n",
      "Timestamp 2019-11-27 20:41:40.842094 Train Epoch: 52 [50/200 ]\tLoss: 0.000866\n",
      "Timestamp 2019-11-27 20:41:43.125704 Train Epoch: 52 [60/200 ]\tLoss: 0.000875\n",
      "Timestamp 2019-11-27 20:41:45.408666 Train Epoch: 52 [70/200 ]\tLoss: 0.000964\n",
      "Timestamp 2019-11-27 20:41:47.681517 Train Epoch: 52 [80/200 ]\tLoss: 0.000835\n",
      "Timestamp 2019-11-27 20:41:49.949889 Train Epoch: 52 [90/200 ]\tLoss: 0.000667\n",
      "Timestamp 2019-11-27 20:41:52.222199 Train Epoch: 52 [100/200 ]\tLoss: 0.000958\n",
      "Timestamp 2019-11-27 20:41:54.498572 Train Epoch: 52 [110/200 ]\tLoss: 0.000705\n",
      "Timestamp 2019-11-27 20:41:56.769137 Train Epoch: 52 [120/200 ]\tLoss: 0.000558\n",
      "Timestamp 2019-11-27 20:41:59.045057 Train Epoch: 52 [130/200 ]\tLoss: 0.000902\n",
      "Timestamp 2019-11-27 20:42:01.316797 Train Epoch: 52 [140/200 ]\tLoss: 0.000912\n",
      "Timestamp 2019-11-27 20:42:03.588883 Train Epoch: 52 [150/200 ]\tLoss: 0.000901\n",
      "Timestamp 2019-11-27 20:42:05.859172 Train Epoch: 52 [160/200 ]\tLoss: 0.001237\n",
      "Timestamp 2019-11-27 20:42:08.128391 Train Epoch: 52 [170/200 ]\tLoss: 0.000941\n",
      "Timestamp 2019-11-27 20:42:10.414503 Train Epoch: 52 [180/200 ]\tLoss: 0.000717\n",
      "Timestamp 2019-11-27 20:42:12.683471 Train Epoch: 52 [190/200 ]\tLoss: 0.001129\n",
      "Timestamp 2019-11-27 20:42:14.960929 Train Epoch: 52 [200/200 ]\tLoss: 0.000882\n",
      "====> Timestamp 2019-11-27 20:42:15.004197 Epoch: 52 Average loss: 0.00088192\n",
      "epoch: 52====> Test set loss: 0.15089899\n",
      "Timestamp 2019-11-27 20:42:28.091801 Train Epoch: 53 [10/200 ]\tLoss: 0.000626\n",
      "Timestamp 2019-11-27 20:42:30.382425 Train Epoch: 53 [20/200 ]\tLoss: 0.000794\n",
      "Timestamp 2019-11-27 20:42:32.660504 Train Epoch: 53 [30/200 ]\tLoss: 0.000828\n",
      "Timestamp 2019-11-27 20:42:34.940853 Train Epoch: 53 [40/200 ]\tLoss: 0.001084\n",
      "Timestamp 2019-11-27 20:42:37.221058 Train Epoch: 53 [50/200 ]\tLoss: 0.000817\n",
      "Timestamp 2019-11-27 20:42:39.515207 Train Epoch: 53 [60/200 ]\tLoss: 0.000906\n",
      "Timestamp 2019-11-27 20:42:41.791336 Train Epoch: 53 [70/200 ]\tLoss: 0.000973\n",
      "Timestamp 2019-11-27 20:42:44.076827 Train Epoch: 53 [80/200 ]\tLoss: 0.000815\n",
      "Timestamp 2019-11-27 20:42:46.354230 Train Epoch: 53 [90/200 ]\tLoss: 0.000732\n",
      "Timestamp 2019-11-27 20:42:48.641928 Train Epoch: 53 [100/200 ]\tLoss: 0.000914\n",
      "Timestamp 2019-11-27 20:42:50.923290 Train Epoch: 53 [110/200 ]\tLoss: 0.000736\n",
      "Timestamp 2019-11-27 20:42:53.212825 Train Epoch: 53 [120/200 ]\tLoss: 0.000570\n",
      "Timestamp 2019-11-27 20:42:55.496935 Train Epoch: 53 [130/200 ]\tLoss: 0.000851\n",
      "Timestamp 2019-11-27 20:42:57.778318 Train Epoch: 53 [140/200 ]\tLoss: 0.000880\n",
      "Timestamp 2019-11-27 20:43:00.060398 Train Epoch: 53 [150/200 ]\tLoss: 0.000857\n",
      "Timestamp 2019-11-27 20:43:02.346992 Train Epoch: 53 [160/200 ]\tLoss: 0.001328\n",
      "Timestamp 2019-11-27 20:43:04.630709 Train Epoch: 53 [170/200 ]\tLoss: 0.000911\n",
      "Timestamp 2019-11-27 20:43:06.908402 Train Epoch: 53 [180/200 ]\tLoss: 0.000718\n",
      "Timestamp 2019-11-27 20:43:09.195039 Train Epoch: 53 [190/200 ]\tLoss: 0.001131\n",
      "Timestamp 2019-11-27 20:43:11.470326 Train Epoch: 53 [200/200 ]\tLoss: 0.000839\n",
      "====> Timestamp 2019-11-27 20:43:11.513620 Epoch: 53 Average loss: 0.00088055\n",
      "epoch: 53====> Test set loss: 0.15270991\n",
      "Timestamp 2019-11-27 20:43:24.598101 Train Epoch: 54 [10/200 ]\tLoss: 0.000623\n",
      "Timestamp 2019-11-27 20:43:26.883199 Train Epoch: 54 [20/200 ]\tLoss: 0.000778\n",
      "Timestamp 2019-11-27 20:43:29.163220 Train Epoch: 54 [30/200 ]\tLoss: 0.000784\n",
      "Timestamp 2019-11-27 20:43:31.445038 Train Epoch: 54 [40/200 ]\tLoss: 0.001070\n",
      "Timestamp 2019-11-27 20:43:33.730469 Train Epoch: 54 [50/200 ]\tLoss: 0.000842\n",
      "Timestamp 2019-11-27 20:43:36.010159 Train Epoch: 54 [60/200 ]\tLoss: 0.000898\n",
      "Timestamp 2019-11-27 20:43:38.288107 Train Epoch: 54 [70/200 ]\tLoss: 0.000925\n",
      "Timestamp 2019-11-27 20:43:40.563322 Train Epoch: 54 [80/200 ]\tLoss: 0.000790\n",
      "Timestamp 2019-11-27 20:43:42.836554 Train Epoch: 54 [90/200 ]\tLoss: 0.000642\n",
      "Timestamp 2019-11-27 20:43:45.111395 Train Epoch: 54 [100/200 ]\tLoss: 0.000957\n",
      "Timestamp 2019-11-27 20:43:47.382977 Train Epoch: 54 [110/200 ]\tLoss: 0.000711\n",
      "Timestamp 2019-11-27 20:43:49.661414 Train Epoch: 54 [120/200 ]\tLoss: 0.000621\n",
      "Timestamp 2019-11-27 20:43:51.933075 Train Epoch: 54 [130/200 ]\tLoss: 0.000895\n",
      "Timestamp 2019-11-27 20:43:54.205003 Train Epoch: 54 [140/200 ]\tLoss: 0.000887\n",
      "Timestamp 2019-11-27 20:43:56.482260 Train Epoch: 54 [150/200 ]\tLoss: 0.000824\n",
      "Timestamp 2019-11-27 20:43:58.755373 Train Epoch: 54 [160/200 ]\tLoss: 0.001222\n",
      "Timestamp 2019-11-27 20:44:01.041923 Train Epoch: 54 [170/200 ]\tLoss: 0.000933\n",
      "Timestamp 2019-11-27 20:44:03.320745 Train Epoch: 54 [180/200 ]\tLoss: 0.000738\n",
      "Timestamp 2019-11-27 20:44:05.590976 Train Epoch: 54 [190/200 ]\tLoss: 0.001081\n",
      "Timestamp 2019-11-27 20:44:07.865006 Train Epoch: 54 [200/200 ]\tLoss: 0.000877\n",
      "====> Timestamp 2019-11-27 20:44:07.908623 Epoch: 54 Average loss: 0.00087301\n",
      "epoch: 54====> Test set loss: 0.15195408\n",
      "Timestamp 2019-11-27 20:44:20.893634 Train Epoch: 55 [10/200 ]\tLoss: 0.000635\n",
      "Timestamp 2019-11-27 20:44:23.173483 Train Epoch: 55 [20/200 ]\tLoss: 0.000799\n",
      "Timestamp 2019-11-27 20:44:25.458385 Train Epoch: 55 [30/200 ]\tLoss: 0.000761\n",
      "Timestamp 2019-11-27 20:44:27.738316 Train Epoch: 55 [40/200 ]\tLoss: 0.001055\n",
      "Timestamp 2019-11-27 20:44:30.016858 Train Epoch: 55 [50/200 ]\tLoss: 0.000792\n",
      "Timestamp 2019-11-27 20:44:32.291327 Train Epoch: 55 [60/200 ]\tLoss: 0.000905\n",
      "Timestamp 2019-11-27 20:44:34.572878 Train Epoch: 55 [70/200 ]\tLoss: 0.000983\n",
      "Timestamp 2019-11-27 20:44:36.858090 Train Epoch: 55 [80/200 ]\tLoss: 0.000832\n",
      "Timestamp 2019-11-27 20:44:39.163299 Train Epoch: 55 [90/200 ]\tLoss: 0.000667\n",
      "Timestamp 2019-11-27 20:44:41.445114 Train Epoch: 55 [100/200 ]\tLoss: 0.000927\n",
      "Timestamp 2019-11-27 20:44:43.724129 Train Epoch: 55 [110/200 ]\tLoss: 0.000709\n",
      "Timestamp 2019-11-27 20:44:46.012909 Train Epoch: 55 [120/200 ]\tLoss: 0.000588\n",
      "Timestamp 2019-11-27 20:44:48.296735 Train Epoch: 55 [130/200 ]\tLoss: 0.000871\n",
      "Timestamp 2019-11-27 20:44:50.575256 Train Epoch: 55 [140/200 ]\tLoss: 0.000883\n",
      "Timestamp 2019-11-27 20:44:52.848219 Train Epoch: 55 [150/200 ]\tLoss: 0.000818\n",
      "Timestamp 2019-11-27 20:44:55.120556 Train Epoch: 55 [160/200 ]\tLoss: 0.001310\n",
      "Timestamp 2019-11-27 20:44:57.390831 Train Epoch: 55 [170/200 ]\tLoss: 0.000884\n",
      "Timestamp 2019-11-27 20:44:59.659069 Train Epoch: 55 [180/200 ]\tLoss: 0.000698\n",
      "Timestamp 2019-11-27 20:45:01.942020 Train Epoch: 55 [190/200 ]\tLoss: 0.001110\n",
      "Timestamp 2019-11-27 20:45:04.213924 Train Epoch: 55 [200/200 ]\tLoss: 0.000869\n",
      "====> Timestamp 2019-11-27 20:45:04.259532 Epoch: 55 Average loss: 0.00087255\n",
      "epoch: 55====> Test set loss: 0.15258205\n",
      "Timestamp 2019-11-27 20:45:17.308737 Train Epoch: 56 [10/200 ]\tLoss: 0.000627\n",
      "Timestamp 2019-11-27 20:45:19.583149 Train Epoch: 56 [20/200 ]\tLoss: 0.000773\n",
      "Timestamp 2019-11-27 20:45:21.860988 Train Epoch: 56 [30/200 ]\tLoss: 0.000772\n",
      "Timestamp 2019-11-27 20:45:24.134565 Train Epoch: 56 [40/200 ]\tLoss: 0.001062\n",
      "Timestamp 2019-11-27 20:45:26.415192 Train Epoch: 56 [50/200 ]\tLoss: 0.000819\n",
      "Timestamp 2019-11-27 20:45:28.687008 Train Epoch: 56 [60/200 ]\tLoss: 0.000904\n",
      "Timestamp 2019-11-27 20:45:30.963308 Train Epoch: 56 [70/200 ]\tLoss: 0.000920\n",
      "Timestamp 2019-11-27 20:45:33.241481 Train Epoch: 56 [80/200 ]\tLoss: 0.000798\n",
      "Timestamp 2019-11-27 20:45:35.516703 Train Epoch: 56 [90/200 ]\tLoss: 0.000656\n",
      "Timestamp 2019-11-27 20:45:37.795329 Train Epoch: 56 [100/200 ]\tLoss: 0.000980\n",
      "Timestamp 2019-11-27 20:45:40.088800 Train Epoch: 56 [110/200 ]\tLoss: 0.000690\n",
      "Timestamp 2019-11-27 20:45:42.366488 Train Epoch: 56 [120/200 ]\tLoss: 0.000582\n",
      "Timestamp 2019-11-27 20:45:44.654604 Train Epoch: 56 [130/200 ]\tLoss: 0.000899\n",
      "Timestamp 2019-11-27 20:45:46.929397 Train Epoch: 56 [140/200 ]\tLoss: 0.000905\n",
      "Timestamp 2019-11-27 20:45:49.203916 Train Epoch: 56 [150/200 ]\tLoss: 0.000805\n",
      "Timestamp 2019-11-27 20:45:51.476491 Train Epoch: 56 [160/200 ]\tLoss: 0.001247\n",
      "Timestamp 2019-11-27 20:45:53.754921 Train Epoch: 56 [170/200 ]\tLoss: 0.000902\n",
      "Timestamp 2019-11-27 20:45:56.036747 Train Epoch: 56 [180/200 ]\tLoss: 0.000717\n",
      "Timestamp 2019-11-27 20:45:58.304697 Train Epoch: 56 [190/200 ]\tLoss: 0.001102\n",
      "Timestamp 2019-11-27 20:46:00.577270 Train Epoch: 56 [200/200 ]\tLoss: 0.000836\n",
      "====> Timestamp 2019-11-27 20:46:00.620493 Epoch: 56 Average loss: 0.00086271\n",
      "epoch: 56====> Test set loss: 0.15254609\n",
      "Timestamp 2019-11-27 20:46:13.781434 Train Epoch: 57 [10/200 ]\tLoss: 0.000629\n",
      "Timestamp 2019-11-27 20:46:16.059401 Train Epoch: 57 [20/200 ]\tLoss: 0.000717\n",
      "Timestamp 2019-11-27 20:46:18.344950 Train Epoch: 57 [30/200 ]\tLoss: 0.000783\n",
      "Timestamp 2019-11-27 20:46:20.625632 Train Epoch: 57 [40/200 ]\tLoss: 0.001022\n",
      "Timestamp 2019-11-27 20:46:22.907154 Train Epoch: 57 [50/200 ]\tLoss: 0.000815\n",
      "Timestamp 2019-11-27 20:46:25.182635 Train Epoch: 57 [60/200 ]\tLoss: 0.000886\n",
      "Timestamp 2019-11-27 20:46:27.465980 Train Epoch: 57 [70/200 ]\tLoss: 0.000921\n",
      "Timestamp 2019-11-27 20:46:29.748348 Train Epoch: 57 [80/200 ]\tLoss: 0.000763\n",
      "Timestamp 2019-11-27 20:46:32.033183 Train Epoch: 57 [90/200 ]\tLoss: 0.000619\n",
      "Timestamp 2019-11-27 20:46:34.318968 Train Epoch: 57 [100/200 ]\tLoss: 0.000896\n",
      "Timestamp 2019-11-27 20:46:36.595978 Train Epoch: 57 [110/200 ]\tLoss: 0.000707\n",
      "Timestamp 2019-11-27 20:46:38.870338 Train Epoch: 57 [120/200 ]\tLoss: 0.000598\n",
      "Timestamp 2019-11-27 20:46:41.162701 Train Epoch: 57 [130/200 ]\tLoss: 0.000914\n",
      "Timestamp 2019-11-27 20:46:43.449506 Train Epoch: 57 [140/200 ]\tLoss: 0.000867\n",
      "Timestamp 2019-11-27 20:46:45.733154 Train Epoch: 57 [150/200 ]\tLoss: 0.000811\n",
      "Timestamp 2019-11-27 20:46:48.009171 Train Epoch: 57 [160/200 ]\tLoss: 0.001219\n",
      "Timestamp 2019-11-27 20:46:50.287361 Train Epoch: 57 [170/200 ]\tLoss: 0.000867\n",
      "Timestamp 2019-11-27 20:46:52.563415 Train Epoch: 57 [180/200 ]\tLoss: 0.000662\n",
      "Timestamp 2019-11-27 20:46:54.848866 Train Epoch: 57 [190/200 ]\tLoss: 0.001050\n",
      "Timestamp 2019-11-27 20:46:57.126920 Train Epoch: 57 [200/200 ]\tLoss: 0.000811\n",
      "====> Timestamp 2019-11-27 20:46:57.172818 Epoch: 57 Average loss: 0.00085265\n",
      "epoch: 57====> Test set loss: 0.15420727\n",
      "Timestamp 2019-11-27 20:47:10.168374 Train Epoch: 58 [10/200 ]\tLoss: 0.000604\n",
      "Timestamp 2019-11-27 20:47:12.441669 Train Epoch: 58 [20/200 ]\tLoss: 0.000794\n",
      "Timestamp 2019-11-27 20:47:14.728430 Train Epoch: 58 [30/200 ]\tLoss: 0.000758\n",
      "Timestamp 2019-11-27 20:47:17.003926 Train Epoch: 58 [40/200 ]\tLoss: 0.001069\n",
      "Timestamp 2019-11-27 20:47:19.287297 Train Epoch: 58 [50/200 ]\tLoss: 0.000770\n",
      "Timestamp 2019-11-27 20:47:21.565536 Train Epoch: 58 [60/200 ]\tLoss: 0.000883\n",
      "Timestamp 2019-11-27 20:47:23.834857 Train Epoch: 58 [70/200 ]\tLoss: 0.000911\n",
      "Timestamp 2019-11-27 20:47:26.113258 Train Epoch: 58 [80/200 ]\tLoss: 0.000766\n",
      "Timestamp 2019-11-27 20:47:28.378812 Train Epoch: 58 [90/200 ]\tLoss: 0.000666\n",
      "Timestamp 2019-11-27 20:47:30.651641 Train Epoch: 58 [100/200 ]\tLoss: 0.000915\n",
      "Timestamp 2019-11-27 20:47:32.920013 Train Epoch: 58 [110/200 ]\tLoss: 0.000686\n",
      "Timestamp 2019-11-27 20:47:35.196729 Train Epoch: 58 [120/200 ]\tLoss: 0.000549\n",
      "Timestamp 2019-11-27 20:47:37.468760 Train Epoch: 58 [130/200 ]\tLoss: 0.000873\n",
      "Timestamp 2019-11-27 20:47:39.744922 Train Epoch: 58 [140/200 ]\tLoss: 0.000857\n",
      "Timestamp 2019-11-27 20:47:42.018859 Train Epoch: 58 [150/200 ]\tLoss: 0.000840\n",
      "Timestamp 2019-11-27 20:47:44.294385 Train Epoch: 58 [160/200 ]\tLoss: 0.001246\n",
      "Timestamp 2019-11-27 20:47:46.562588 Train Epoch: 58 [170/200 ]\tLoss: 0.000918\n",
      "Timestamp 2019-11-27 20:47:48.836102 Train Epoch: 58 [180/200 ]\tLoss: 0.000717\n",
      "Timestamp 2019-11-27 20:47:51.106554 Train Epoch: 58 [190/200 ]\tLoss: 0.001078\n",
      "Timestamp 2019-11-27 20:47:53.380506 Train Epoch: 58 [200/200 ]\tLoss: 0.000852\n",
      "====> Timestamp 2019-11-27 20:47:53.424049 Epoch: 58 Average loss: 0.00085210\n",
      "epoch: 58====> Test set loss: 0.15500520\n",
      "Timestamp 2019-11-27 20:48:06.477276 Train Epoch: 59 [10/200 ]\tLoss: 0.000601\n",
      "Timestamp 2019-11-27 20:48:08.763987 Train Epoch: 59 [20/200 ]\tLoss: 0.000784\n",
      "Timestamp 2019-11-27 20:48:11.050912 Train Epoch: 59 [30/200 ]\tLoss: 0.000716\n",
      "Timestamp 2019-11-27 20:48:13.323884 Train Epoch: 59 [40/200 ]\tLoss: 0.001040\n",
      "Timestamp 2019-11-27 20:48:15.595914 Train Epoch: 59 [50/200 ]\tLoss: 0.000837\n",
      "Timestamp 2019-11-27 20:48:17.870843 Train Epoch: 59 [60/200 ]\tLoss: 0.000884\n",
      "Timestamp 2019-11-27 20:48:20.143566 Train Epoch: 59 [70/200 ]\tLoss: 0.000957\n",
      "Timestamp 2019-11-27 20:48:22.413812 Train Epoch: 59 [80/200 ]\tLoss: 0.000763\n",
      "Timestamp 2019-11-27 20:48:24.681987 Train Epoch: 59 [90/200 ]\tLoss: 0.000624\n",
      "Timestamp 2019-11-27 20:48:26.965316 Train Epoch: 59 [100/200 ]\tLoss: 0.000924\n",
      "Timestamp 2019-11-27 20:48:29.245551 Train Epoch: 59 [110/200 ]\tLoss: 0.000644\n",
      "Timestamp 2019-11-27 20:48:31.534953 Train Epoch: 59 [120/200 ]\tLoss: 0.000548\n",
      "Timestamp 2019-11-27 20:48:33.808768 Train Epoch: 59 [130/200 ]\tLoss: 0.000874\n",
      "Timestamp 2019-11-27 20:48:36.089394 Train Epoch: 59 [140/200 ]\tLoss: 0.000891\n",
      "Timestamp 2019-11-27 20:48:38.354048 Train Epoch: 59 [150/200 ]\tLoss: 0.000879\n",
      "Timestamp 2019-11-27 20:48:40.641842 Train Epoch: 59 [160/200 ]\tLoss: 0.001252\n",
      "Timestamp 2019-11-27 20:48:42.922703 Train Epoch: 59 [170/200 ]\tLoss: 0.000896\n",
      "Timestamp 2019-11-27 20:48:45.190084 Train Epoch: 59 [180/200 ]\tLoss: 0.000663\n",
      "Timestamp 2019-11-27 20:48:47.462030 Train Epoch: 59 [190/200 ]\tLoss: 0.001022\n",
      "Timestamp 2019-11-27 20:48:49.734823 Train Epoch: 59 [200/200 ]\tLoss: 0.000833\n",
      "====> Timestamp 2019-11-27 20:48:49.783894 Epoch: 59 Average loss: 0.00084550\n",
      "epoch: 59====> Test set loss: 0.15448727\n",
      "Timestamp 2019-11-27 20:49:02.840791 Train Epoch: 60 [10/200 ]\tLoss: 0.000613\n",
      "Timestamp 2019-11-27 20:49:05.117990 Train Epoch: 60 [20/200 ]\tLoss: 0.000728\n",
      "Timestamp 2019-11-27 20:49:07.414025 Train Epoch: 60 [30/200 ]\tLoss: 0.000705\n",
      "Timestamp 2019-11-27 20:49:09.697944 Train Epoch: 60 [40/200 ]\tLoss: 0.001039\n",
      "Timestamp 2019-11-27 20:49:11.975727 Train Epoch: 60 [50/200 ]\tLoss: 0.000790\n",
      "Timestamp 2019-11-27 20:49:14.252666 Train Epoch: 60 [60/200 ]\tLoss: 0.000873\n",
      "Timestamp 2019-11-27 20:49:16.532503 Train Epoch: 60 [70/200 ]\tLoss: 0.000927\n",
      "Timestamp 2019-11-27 20:49:18.810244 Train Epoch: 60 [80/200 ]\tLoss: 0.000772\n",
      "Timestamp 2019-11-27 20:49:21.088121 Train Epoch: 60 [90/200 ]\tLoss: 0.000644\n",
      "Timestamp 2019-11-27 20:49:23.370654 Train Epoch: 60 [100/200 ]\tLoss: 0.000902\n",
      "Timestamp 2019-11-27 20:49:25.659754 Train Epoch: 60 [110/200 ]\tLoss: 0.000661\n",
      "Timestamp 2019-11-27 20:49:27.944400 Train Epoch: 60 [120/200 ]\tLoss: 0.000574\n",
      "Timestamp 2019-11-27 20:49:30.227018 Train Epoch: 60 [130/200 ]\tLoss: 0.000836\n",
      "Timestamp 2019-11-27 20:49:32.517630 Train Epoch: 60 [140/200 ]\tLoss: 0.000850\n",
      "Timestamp 2019-11-27 20:49:34.795109 Train Epoch: 60 [150/200 ]\tLoss: 0.000768\n",
      "Timestamp 2019-11-27 20:49:37.077622 Train Epoch: 60 [160/200 ]\tLoss: 0.001171\n",
      "Timestamp 2019-11-27 20:49:39.367219 Train Epoch: 60 [170/200 ]\tLoss: 0.000846\n",
      "Timestamp 2019-11-27 20:49:41.651651 Train Epoch: 60 [180/200 ]\tLoss: 0.000676\n",
      "Timestamp 2019-11-27 20:49:43.934206 Train Epoch: 60 [190/200 ]\tLoss: 0.001062\n",
      "Timestamp 2019-11-27 20:49:46.217981 Train Epoch: 60 [200/200 ]\tLoss: 0.000874\n",
      "====> Timestamp 2019-11-27 20:49:46.261906 Epoch: 60 Average loss: 0.00083983\n",
      "epoch: 60====> Test set loss: 0.15365837\n",
      "Timestamp 2019-11-27 20:49:59.281769 Train Epoch: 61 [10/200 ]\tLoss: 0.000603\n",
      "Timestamp 2019-11-27 20:50:01.565520 Train Epoch: 61 [20/200 ]\tLoss: 0.000745\n",
      "Timestamp 2019-11-27 20:50:03.846040 Train Epoch: 61 [30/200 ]\tLoss: 0.000691\n",
      "Timestamp 2019-11-27 20:50:06.126062 Train Epoch: 61 [40/200 ]\tLoss: 0.001033\n",
      "Timestamp 2019-11-27 20:50:08.408658 Train Epoch: 61 [50/200 ]\tLoss: 0.000785\n",
      "Timestamp 2019-11-27 20:50:10.705373 Train Epoch: 61 [60/200 ]\tLoss: 0.000866\n",
      "Timestamp 2019-11-27 20:50:12.983216 Train Epoch: 61 [70/200 ]\tLoss: 0.000911\n",
      "Timestamp 2019-11-27 20:50:15.261861 Train Epoch: 61 [80/200 ]\tLoss: 0.000790\n",
      "Timestamp 2019-11-27 20:50:17.544674 Train Epoch: 61 [90/200 ]\tLoss: 0.000706\n",
      "Timestamp 2019-11-27 20:50:19.823887 Train Epoch: 61 [100/200 ]\tLoss: 0.000895\n",
      "Timestamp 2019-11-27 20:50:22.108398 Train Epoch: 61 [110/200 ]\tLoss: 0.000649\n",
      "Timestamp 2019-11-27 20:50:24.387355 Train Epoch: 61 [120/200 ]\tLoss: 0.000532\n",
      "Timestamp 2019-11-27 20:50:26.671531 Train Epoch: 61 [130/200 ]\tLoss: 0.000914\n",
      "Timestamp 2019-11-27 20:50:28.958844 Train Epoch: 61 [140/200 ]\tLoss: 0.000854\n",
      "Timestamp 2019-11-27 20:50:31.236806 Train Epoch: 61 [150/200 ]\tLoss: 0.000758\n",
      "Timestamp 2019-11-27 20:50:33.502124 Train Epoch: 61 [160/200 ]\tLoss: 0.001179\n",
      "Timestamp 2019-11-27 20:50:35.770723 Train Epoch: 61 [170/200 ]\tLoss: 0.000880\n",
      "Timestamp 2019-11-27 20:50:38.047353 Train Epoch: 61 [180/200 ]\tLoss: 0.000703\n",
      "Timestamp 2019-11-27 20:50:40.327689 Train Epoch: 61 [190/200 ]\tLoss: 0.001072\n",
      "Timestamp 2019-11-27 20:50:42.593544 Train Epoch: 61 [200/200 ]\tLoss: 0.000806\n",
      "====> Timestamp 2019-11-27 20:50:42.636890 Epoch: 61 Average loss: 0.00083536\n",
      "epoch: 61====> Test set loss: 0.15437039\n",
      "Timestamp 2019-11-27 20:50:55.851046 Train Epoch: 62 [10/200 ]\tLoss: 0.000596\n",
      "Timestamp 2019-11-27 20:50:58.124864 Train Epoch: 62 [20/200 ]\tLoss: 0.000724\n",
      "Timestamp 2019-11-27 20:51:00.413711 Train Epoch: 62 [30/200 ]\tLoss: 0.000747\n",
      "Timestamp 2019-11-27 20:51:02.688016 Train Epoch: 62 [40/200 ]\tLoss: 0.001016\n",
      "Timestamp 2019-11-27 20:51:04.968690 Train Epoch: 62 [50/200 ]\tLoss: 0.000804\n",
      "Timestamp 2019-11-27 20:51:07.244780 Train Epoch: 62 [60/200 ]\tLoss: 0.000898\n",
      "Timestamp 2019-11-27 20:51:09.534921 Train Epoch: 62 [70/200 ]\tLoss: 0.000934\n",
      "Timestamp 2019-11-27 20:51:11.816814 Train Epoch: 62 [80/200 ]\tLoss: 0.000732\n",
      "Timestamp 2019-11-27 20:51:14.099556 Train Epoch: 62 [90/200 ]\tLoss: 0.000614\n",
      "Timestamp 2019-11-27 20:51:16.381844 Train Epoch: 62 [100/200 ]\tLoss: 0.000906\n",
      "Timestamp 2019-11-27 20:51:18.660722 Train Epoch: 62 [110/200 ]\tLoss: 0.000670\n",
      "Timestamp 2019-11-27 20:51:20.943317 Train Epoch: 62 [120/200 ]\tLoss: 0.000583\n",
      "Timestamp 2019-11-27 20:51:23.220041 Train Epoch: 62 [130/200 ]\tLoss: 0.000885\n",
      "Timestamp 2019-11-27 20:51:25.499705 Train Epoch: 62 [140/200 ]\tLoss: 0.000869\n",
      "Timestamp 2019-11-27 20:51:27.781813 Train Epoch: 62 [150/200 ]\tLoss: 0.000851\n",
      "Timestamp 2019-11-27 20:51:30.065300 Train Epoch: 62 [160/200 ]\tLoss: 0.001201\n",
      "Timestamp 2019-11-27 20:51:32.342463 Train Epoch: 62 [170/200 ]\tLoss: 0.000862\n",
      "Timestamp 2019-11-27 20:51:34.618325 Train Epoch: 62 [180/200 ]\tLoss: 0.000643\n",
      "Timestamp 2019-11-27 20:51:36.894833 Train Epoch: 62 [190/200 ]\tLoss: 0.001024\n",
      "Timestamp 2019-11-27 20:51:39.188141 Train Epoch: 62 [200/200 ]\tLoss: 0.000771\n",
      "====> Timestamp 2019-11-27 20:51:39.234497 Epoch: 62 Average loss: 0.00082958\n",
      "epoch: 62====> Test set loss: 0.15524567\n",
      "Timestamp 2019-11-27 20:51:52.224428 Train Epoch: 63 [10/200 ]\tLoss: 0.000597\n",
      "Timestamp 2019-11-27 20:51:54.502379 Train Epoch: 63 [20/200 ]\tLoss: 0.000715\n",
      "Timestamp 2019-11-27 20:51:56.782204 Train Epoch: 63 [30/200 ]\tLoss: 0.000729\n",
      "Timestamp 2019-11-27 20:51:59.066365 Train Epoch: 63 [40/200 ]\tLoss: 0.001039\n",
      "Timestamp 2019-11-27 20:52:01.348863 Train Epoch: 63 [50/200 ]\tLoss: 0.000767\n",
      "Timestamp 2019-11-27 20:52:03.624925 Train Epoch: 63 [60/200 ]\tLoss: 0.000853\n",
      "Timestamp 2019-11-27 20:52:05.913971 Train Epoch: 63 [70/200 ]\tLoss: 0.000946\n",
      "Timestamp 2019-11-27 20:52:08.200281 Train Epoch: 63 [80/200 ]\tLoss: 0.000762\n",
      "Timestamp 2019-11-27 20:52:10.484161 Train Epoch: 63 [90/200 ]\tLoss: 0.000665\n",
      "Timestamp 2019-11-27 20:52:12.765670 Train Epoch: 63 [100/200 ]\tLoss: 0.000911\n",
      "Timestamp 2019-11-27 20:52:15.044786 Train Epoch: 63 [110/200 ]\tLoss: 0.000696\n",
      "Timestamp 2019-11-27 20:52:17.319459 Train Epoch: 63 [120/200 ]\tLoss: 0.000556\n",
      "Timestamp 2019-11-27 20:52:19.603006 Train Epoch: 63 [130/200 ]\tLoss: 0.000845\n",
      "Timestamp 2019-11-27 20:52:21.876424 Train Epoch: 63 [140/200 ]\tLoss: 0.000834\n",
      "Timestamp 2019-11-27 20:52:24.148123 Train Epoch: 63 [150/200 ]\tLoss: 0.000749\n",
      "Timestamp 2019-11-27 20:52:26.419502 Train Epoch: 63 [160/200 ]\tLoss: 0.001159\n",
      "Timestamp 2019-11-27 20:52:28.706008 Train Epoch: 63 [170/200 ]\tLoss: 0.000834\n",
      "Timestamp 2019-11-27 20:52:30.973084 Train Epoch: 63 [180/200 ]\tLoss: 0.000655\n",
      "Timestamp 2019-11-27 20:52:33.241326 Train Epoch: 63 [190/200 ]\tLoss: 0.001033\n",
      "Timestamp 2019-11-27 20:52:35.510055 Train Epoch: 63 [200/200 ]\tLoss: 0.000817\n",
      "====> Timestamp 2019-11-27 20:52:35.553220 Epoch: 63 Average loss: 0.00082533\n",
      "epoch: 63====> Test set loss: 0.15733288\n",
      "Timestamp 2019-11-27 20:52:48.648968 Train Epoch: 64 [10/200 ]\tLoss: 0.000575\n",
      "Timestamp 2019-11-27 20:52:50.929301 Train Epoch: 64 [20/200 ]\tLoss: 0.000708\n",
      "Timestamp 2019-11-27 20:52:53.206967 Train Epoch: 64 [30/200 ]\tLoss: 0.000706\n",
      "Timestamp 2019-11-27 20:52:55.481100 Train Epoch: 64 [40/200 ]\tLoss: 0.001025\n",
      "Timestamp 2019-11-27 20:52:57.764709 Train Epoch: 64 [50/200 ]\tLoss: 0.000743\n",
      "Timestamp 2019-11-27 20:53:00.042204 Train Epoch: 64 [60/200 ]\tLoss: 0.000855\n",
      "Timestamp 2019-11-27 20:53:02.314276 Train Epoch: 64 [70/200 ]\tLoss: 0.000886\n",
      "Timestamp 2019-11-27 20:53:04.585022 Train Epoch: 64 [80/200 ]\tLoss: 0.000761\n",
      "Timestamp 2019-11-27 20:53:06.857682 Train Epoch: 64 [90/200 ]\tLoss: 0.000644\n",
      "Timestamp 2019-11-27 20:53:09.145350 Train Epoch: 64 [100/200 ]\tLoss: 0.000870\n",
      "Timestamp 2019-11-27 20:53:11.419781 Train Epoch: 64 [110/200 ]\tLoss: 0.000684\n",
      "Timestamp 2019-11-27 20:53:13.693848 Train Epoch: 64 [120/200 ]\tLoss: 0.000561\n",
      "Timestamp 2019-11-27 20:53:15.968901 Train Epoch: 64 [130/200 ]\tLoss: 0.000781\n",
      "Timestamp 2019-11-27 20:53:18.238986 Train Epoch: 64 [140/200 ]\tLoss: 0.000837\n",
      "Timestamp 2019-11-27 20:53:20.518579 Train Epoch: 64 [150/200 ]\tLoss: 0.000765\n",
      "Timestamp 2019-11-27 20:53:22.785925 Train Epoch: 64 [160/200 ]\tLoss: 0.001175\n",
      "Timestamp 2019-11-27 20:53:25.054257 Train Epoch: 64 [170/200 ]\tLoss: 0.000893\n",
      "Timestamp 2019-11-27 20:53:27.327850 Train Epoch: 64 [180/200 ]\tLoss: 0.000663\n",
      "Timestamp 2019-11-27 20:53:29.601981 Train Epoch: 64 [190/200 ]\tLoss: 0.001024\n",
      "Timestamp 2019-11-27 20:53:31.874862 Train Epoch: 64 [200/200 ]\tLoss: 0.000761\n",
      "====> Timestamp 2019-11-27 20:53:31.917960 Epoch: 64 Average loss: 0.00081721\n",
      "epoch: 64====> Test set loss: 0.15825654\n",
      "Timestamp 2019-11-27 20:53:45.067424 Train Epoch: 65 [10/200 ]\tLoss: 0.000560\n",
      "Timestamp 2019-11-27 20:53:47.353692 Train Epoch: 65 [20/200 ]\tLoss: 0.000685\n",
      "Timestamp 2019-11-27 20:53:49.639041 Train Epoch: 65 [30/200 ]\tLoss: 0.000709\n",
      "Timestamp 2019-11-27 20:53:51.926644 Train Epoch: 65 [40/200 ]\tLoss: 0.001019\n",
      "Timestamp 2019-11-27 20:53:54.212289 Train Epoch: 65 [50/200 ]\tLoss: 0.000815\n",
      "Timestamp 2019-11-27 20:53:56.499469 Train Epoch: 65 [60/200 ]\tLoss: 0.000848\n",
      "Timestamp 2019-11-27 20:53:58.784381 Train Epoch: 65 [70/200 ]\tLoss: 0.000913\n",
      "Timestamp 2019-11-27 20:54:01.069373 Train Epoch: 65 [80/200 ]\tLoss: 0.000703\n",
      "Timestamp 2019-11-27 20:54:03.343595 Train Epoch: 65 [90/200 ]\tLoss: 0.000620\n",
      "Timestamp 2019-11-27 20:54:05.627293 Train Epoch: 65 [100/200 ]\tLoss: 0.000858\n",
      "Timestamp 2019-11-27 20:54:07.908072 Train Epoch: 65 [110/200 ]\tLoss: 0.000622\n",
      "Timestamp 2019-11-27 20:54:10.195472 Train Epoch: 65 [120/200 ]\tLoss: 0.000529\n",
      "Timestamp 2019-11-27 20:54:12.474812 Train Epoch: 65 [130/200 ]\tLoss: 0.000807\n",
      "Timestamp 2019-11-27 20:54:14.755415 Train Epoch: 65 [140/200 ]\tLoss: 0.000834\n",
      "Timestamp 2019-11-27 20:54:17.038897 Train Epoch: 65 [150/200 ]\tLoss: 0.000761\n",
      "Timestamp 2019-11-27 20:54:19.327470 Train Epoch: 65 [160/200 ]\tLoss: 0.001181\n",
      "Timestamp 2019-11-27 20:54:21.619149 Train Epoch: 65 [170/200 ]\tLoss: 0.000905\n",
      "Timestamp 2019-11-27 20:54:23.906282 Train Epoch: 65 [180/200 ]\tLoss: 0.000654\n",
      "Timestamp 2019-11-27 20:54:26.190428 Train Epoch: 65 [190/200 ]\tLoss: 0.001057\n",
      "Timestamp 2019-11-27 20:54:28.472738 Train Epoch: 65 [200/200 ]\tLoss: 0.000796\n",
      "====> Timestamp 2019-11-27 20:54:28.520018 Epoch: 65 Average loss: 0.00081182\n",
      "epoch: 65====> Test set loss: 0.15931356\n",
      "Timestamp 2019-11-27 20:54:41.554847 Train Epoch: 66 [10/200 ]\tLoss: 0.000562\n",
      "Timestamp 2019-11-27 20:54:43.834917 Train Epoch: 66 [20/200 ]\tLoss: 0.000697\n",
      "Timestamp 2019-11-27 20:54:46.112060 Train Epoch: 66 [30/200 ]\tLoss: 0.000728\n",
      "Timestamp 2019-11-27 20:54:48.402088 Train Epoch: 66 [40/200 ]\tLoss: 0.000960\n",
      "Timestamp 2019-11-27 20:54:50.689742 Train Epoch: 66 [50/200 ]\tLoss: 0.000772\n",
      "Timestamp 2019-11-27 20:54:52.969041 Train Epoch: 66 [60/200 ]\tLoss: 0.000833\n",
      "Timestamp 2019-11-27 20:54:55.262708 Train Epoch: 66 [70/200 ]\tLoss: 0.000933\n",
      "Timestamp 2019-11-27 20:54:57.538784 Train Epoch: 66 [80/200 ]\tLoss: 0.000731\n",
      "Timestamp 2019-11-27 20:54:59.823400 Train Epoch: 66 [90/200 ]\tLoss: 0.000639\n",
      "Timestamp 2019-11-27 20:55:02.110442 Train Epoch: 66 [100/200 ]\tLoss: 0.000918\n",
      "Timestamp 2019-11-27 20:55:04.403520 Train Epoch: 66 [110/200 ]\tLoss: 0.000628\n",
      "Timestamp 2019-11-27 20:55:06.685651 Train Epoch: 66 [120/200 ]\tLoss: 0.000546\n",
      "Timestamp 2019-11-27 20:55:08.979716 Train Epoch: 66 [130/200 ]\tLoss: 0.000845\n",
      "Timestamp 2019-11-27 20:55:11.261378 Train Epoch: 66 [140/200 ]\tLoss: 0.000852\n",
      "Timestamp 2019-11-27 20:55:13.536966 Train Epoch: 66 [150/200 ]\tLoss: 0.000734\n",
      "Timestamp 2019-11-27 20:55:15.819574 Train Epoch: 66 [160/200 ]\tLoss: 0.001148\n",
      "Timestamp 2019-11-27 20:55:18.083941 Train Epoch: 66 [170/200 ]\tLoss: 0.000851\n",
      "Timestamp 2019-11-27 20:55:20.357251 Train Epoch: 66 [180/200 ]\tLoss: 0.000645\n",
      "Timestamp 2019-11-27 20:55:22.626875 Train Epoch: 66 [190/200 ]\tLoss: 0.001032\n",
      "Timestamp 2019-11-27 20:55:24.898096 Train Epoch: 66 [200/200 ]\tLoss: 0.000783\n",
      "====> Timestamp 2019-11-27 20:55:24.941983 Epoch: 66 Average loss: 0.00081160\n",
      "epoch: 66====> Test set loss: 0.15853953\n",
      "Timestamp 2019-11-27 20:55:38.098902 Train Epoch: 67 [10/200 ]\tLoss: 0.000559\n",
      "Timestamp 2019-11-27 20:55:40.382614 Train Epoch: 67 [20/200 ]\tLoss: 0.000735\n",
      "Timestamp 2019-11-27 20:55:42.666105 Train Epoch: 67 [30/200 ]\tLoss: 0.000704\n",
      "Timestamp 2019-11-27 20:55:44.945847 Train Epoch: 67 [40/200 ]\tLoss: 0.000994\n",
      "Timestamp 2019-11-27 20:55:47.226509 Train Epoch: 67 [50/200 ]\tLoss: 0.000781\n",
      "Timestamp 2019-11-27 20:55:49.504288 Train Epoch: 67 [60/200 ]\tLoss: 0.000833\n",
      "Timestamp 2019-11-27 20:55:51.786070 Train Epoch: 67 [70/200 ]\tLoss: 0.000877\n",
      "Timestamp 2019-11-27 20:55:54.060120 Train Epoch: 67 [80/200 ]\tLoss: 0.000736\n",
      "Timestamp 2019-11-27 20:55:56.336379 Train Epoch: 67 [90/200 ]\tLoss: 0.000623\n",
      "Timestamp 2019-11-27 20:55:58.620641 Train Epoch: 67 [100/200 ]\tLoss: 0.000889\n",
      "Timestamp 2019-11-27 20:56:00.905521 Train Epoch: 67 [110/200 ]\tLoss: 0.000641\n",
      "Timestamp 2019-11-27 20:56:03.186666 Train Epoch: 67 [120/200 ]\tLoss: 0.000591\n",
      "Timestamp 2019-11-27 20:56:05.459854 Train Epoch: 67 [130/200 ]\tLoss: 0.000817\n",
      "Timestamp 2019-11-27 20:56:07.737361 Train Epoch: 67 [140/200 ]\tLoss: 0.000863\n",
      "Timestamp 2019-11-27 20:56:10.040971 Train Epoch: 67 [150/200 ]\tLoss: 0.000742\n",
      "Timestamp 2019-11-27 20:56:12.328042 Train Epoch: 67 [160/200 ]\tLoss: 0.001119\n",
      "Timestamp 2019-11-27 20:56:14.605807 Train Epoch: 67 [170/200 ]\tLoss: 0.000874\n",
      "Timestamp 2019-11-27 20:56:16.888624 Train Epoch: 67 [180/200 ]\tLoss: 0.000614\n",
      "Timestamp 2019-11-27 20:56:19.170970 Train Epoch: 67 [190/200 ]\tLoss: 0.001021\n",
      "Timestamp 2019-11-27 20:56:21.454757 Train Epoch: 67 [200/200 ]\tLoss: 0.000800\n",
      "====> Timestamp 2019-11-27 20:56:21.501167 Epoch: 67 Average loss: 0.00080446\n",
      "epoch: 67====> Test set loss: 0.15764107\n",
      "Timestamp 2019-11-27 20:56:34.592454 Train Epoch: 68 [10/200 ]\tLoss: 0.000558\n",
      "Timestamp 2019-11-27 20:56:36.872960 Train Epoch: 68 [20/200 ]\tLoss: 0.000665\n",
      "Timestamp 2019-11-27 20:56:39.163486 Train Epoch: 68 [30/200 ]\tLoss: 0.000679\n",
      "Timestamp 2019-11-27 20:56:41.438634 Train Epoch: 68 [40/200 ]\tLoss: 0.001002\n",
      "Timestamp 2019-11-27 20:56:43.709445 Train Epoch: 68 [50/200 ]\tLoss: 0.000742\n",
      "Timestamp 2019-11-27 20:56:45.990349 Train Epoch: 68 [60/200 ]\tLoss: 0.000828\n",
      "Timestamp 2019-11-27 20:56:48.272990 Train Epoch: 68 [70/200 ]\tLoss: 0.000866\n",
      "Timestamp 2019-11-27 20:56:50.550998 Train Epoch: 68 [80/200 ]\tLoss: 0.000729\n",
      "Timestamp 2019-11-27 20:56:52.832258 Train Epoch: 68 [90/200 ]\tLoss: 0.000546\n",
      "Timestamp 2019-11-27 20:56:55.117104 Train Epoch: 68 [100/200 ]\tLoss: 0.000894\n",
      "Timestamp 2019-11-27 20:56:57.400701 Train Epoch: 68 [110/200 ]\tLoss: 0.000629\n",
      "Timestamp 2019-11-27 20:56:59.683933 Train Epoch: 68 [120/200 ]\tLoss: 0.000512\n",
      "Timestamp 2019-11-27 20:57:01.964303 Train Epoch: 68 [130/200 ]\tLoss: 0.000824\n",
      "Timestamp 2019-11-27 20:57:04.239948 Train Epoch: 68 [140/200 ]\tLoss: 0.000822\n",
      "Timestamp 2019-11-27 20:57:06.523561 Train Epoch: 68 [150/200 ]\tLoss: 0.000809\n",
      "Timestamp 2019-11-27 20:57:08.801599 Train Epoch: 68 [160/200 ]\tLoss: 0.001168\n",
      "Timestamp 2019-11-27 20:57:11.092856 Train Epoch: 68 [170/200 ]\tLoss: 0.000807\n",
      "Timestamp 2019-11-27 20:57:13.374954 Train Epoch: 68 [180/200 ]\tLoss: 0.000643\n",
      "Timestamp 2019-11-27 20:57:15.645878 Train Epoch: 68 [190/200 ]\tLoss: 0.000988\n",
      "Timestamp 2019-11-27 20:57:17.912959 Train Epoch: 68 [200/200 ]\tLoss: 0.000731\n",
      "====> Timestamp 2019-11-27 20:57:17.953943 Epoch: 68 Average loss: 0.00079552\n",
      "epoch: 68====> Test set loss: 0.15985994\n",
      "Timestamp 2019-11-27 20:57:31.065697 Train Epoch: 69 [10/200 ]\tLoss: 0.000557\n",
      "Timestamp 2019-11-27 20:57:33.344804 Train Epoch: 69 [20/200 ]\tLoss: 0.000683\n",
      "Timestamp 2019-11-27 20:57:35.625154 Train Epoch: 69 [30/200 ]\tLoss: 0.000681\n",
      "Timestamp 2019-11-27 20:57:37.899811 Train Epoch: 69 [40/200 ]\tLoss: 0.000980\n",
      "Timestamp 2019-11-27 20:57:40.189658 Train Epoch: 69 [50/200 ]\tLoss: 0.000739\n",
      "Timestamp 2019-11-27 20:57:42.465415 Train Epoch: 69 [60/200 ]\tLoss: 0.000854\n",
      "Timestamp 2019-11-27 20:57:44.753268 Train Epoch: 69 [70/200 ]\tLoss: 0.000868\n",
      "Timestamp 2019-11-27 20:57:47.020703 Train Epoch: 69 [80/200 ]\tLoss: 0.000709\n",
      "Timestamp 2019-11-27 20:57:49.298258 Train Epoch: 69 [90/200 ]\tLoss: 0.000619\n",
      "Timestamp 2019-11-27 20:57:51.568375 Train Epoch: 69 [100/200 ]\tLoss: 0.000863\n",
      "Timestamp 2019-11-27 20:57:53.841998 Train Epoch: 69 [110/200 ]\tLoss: 0.000612\n",
      "Timestamp 2019-11-27 20:57:56.113361 Train Epoch: 69 [120/200 ]\tLoss: 0.000595\n",
      "Timestamp 2019-11-27 20:57:58.384064 Train Epoch: 69 [130/200 ]\tLoss: 0.000799\n",
      "Timestamp 2019-11-27 20:58:00.655674 Train Epoch: 69 [140/200 ]\tLoss: 0.000834\n",
      "Timestamp 2019-11-27 20:58:02.923531 Train Epoch: 69 [150/200 ]\tLoss: 0.000793\n",
      "Timestamp 2019-11-27 20:58:05.196876 Train Epoch: 69 [160/200 ]\tLoss: 0.001162\n",
      "Timestamp 2019-11-27 20:58:07.468718 Train Epoch: 69 [170/200 ]\tLoss: 0.000854\n",
      "Timestamp 2019-11-27 20:58:09.746095 Train Epoch: 69 [180/200 ]\tLoss: 0.000657\n",
      "Timestamp 2019-11-27 20:58:12.018619 Train Epoch: 69 [190/200 ]\tLoss: 0.000980\n",
      "Timestamp 2019-11-27 20:58:14.289641 Train Epoch: 69 [200/200 ]\tLoss: 0.000794\n",
      "====> Timestamp 2019-11-27 20:58:14.332758 Epoch: 69 Average loss: 0.00078967\n",
      "epoch: 69====> Test set loss: 0.16161578\n",
      "Timestamp 2019-11-27 20:58:27.381296 Train Epoch: 70 [10/200 ]\tLoss: 0.000584\n",
      "Timestamp 2019-11-27 20:58:29.662413 Train Epoch: 70 [20/200 ]\tLoss: 0.000674\n",
      "Timestamp 2019-11-27 20:58:31.942568 Train Epoch: 70 [30/200 ]\tLoss: 0.000691\n",
      "Timestamp 2019-11-27 20:58:34.222171 Train Epoch: 70 [40/200 ]\tLoss: 0.000952\n",
      "Timestamp 2019-11-27 20:58:36.496156 Train Epoch: 70 [50/200 ]\tLoss: 0.000719\n",
      "Timestamp 2019-11-27 20:58:38.765471 Train Epoch: 70 [60/200 ]\tLoss: 0.000847\n",
      "Timestamp 2019-11-27 20:58:41.052411 Train Epoch: 70 [70/200 ]\tLoss: 0.000892\n",
      "Timestamp 2019-11-27 20:58:43.331151 Train Epoch: 70 [80/200 ]\tLoss: 0.000703\n",
      "Timestamp 2019-11-27 20:58:45.602545 Train Epoch: 70 [90/200 ]\tLoss: 0.000613\n",
      "Timestamp 2019-11-27 20:58:47.875216 Train Epoch: 70 [100/200 ]\tLoss: 0.000894\n",
      "Timestamp 2019-11-27 20:58:50.156739 Train Epoch: 70 [110/200 ]\tLoss: 0.000676\n",
      "Timestamp 2019-11-27 20:58:52.435921 Train Epoch: 70 [120/200 ]\tLoss: 0.000510\n",
      "Timestamp 2019-11-27 20:58:54.707302 Train Epoch: 70 [130/200 ]\tLoss: 0.000808\n",
      "Timestamp 2019-11-27 20:58:56.977619 Train Epoch: 70 [140/200 ]\tLoss: 0.000864\n",
      "Timestamp 2019-11-27 20:58:59.247801 Train Epoch: 70 [150/200 ]\tLoss: 0.000796\n",
      "Timestamp 2019-11-27 20:59:01.519328 Train Epoch: 70 [160/200 ]\tLoss: 0.001138\n",
      "Timestamp 2019-11-27 20:59:03.792759 Train Epoch: 70 [170/200 ]\tLoss: 0.000851\n",
      "Timestamp 2019-11-27 20:59:06.068804 Train Epoch: 70 [180/200 ]\tLoss: 0.000635\n",
      "Timestamp 2019-11-27 20:59:08.340524 Train Epoch: 70 [190/200 ]\tLoss: 0.001060\n",
      "Timestamp 2019-11-27 20:59:10.625124 Train Epoch: 70 [200/200 ]\tLoss: 0.000795\n",
      "====> Timestamp 2019-11-27 20:59:10.668564 Epoch: 70 Average loss: 0.00079224\n",
      "epoch: 70====> Test set loss: 0.15939780\n",
      "Timestamp 2019-11-27 20:59:23.689275 Train Epoch: 71 [10/200 ]\tLoss: 0.000565\n",
      "Timestamp 2019-11-27 20:59:25.972704 Train Epoch: 71 [20/200 ]\tLoss: 0.000665\n",
      "Timestamp 2019-11-27 20:59:28.257976 Train Epoch: 71 [30/200 ]\tLoss: 0.000659\n",
      "Timestamp 2019-11-27 20:59:30.536940 Train Epoch: 71 [40/200 ]\tLoss: 0.000924\n",
      "Timestamp 2019-11-27 20:59:32.813127 Train Epoch: 71 [50/200 ]\tLoss: 0.000697\n",
      "Timestamp 2019-11-27 20:59:35.090505 Train Epoch: 71 [60/200 ]\tLoss: 0.000796\n",
      "Timestamp 2019-11-27 20:59:37.369703 Train Epoch: 71 [70/200 ]\tLoss: 0.000894\n",
      "Timestamp 2019-11-27 20:59:39.666798 Train Epoch: 71 [80/200 ]\tLoss: 0.000717\n",
      "Timestamp 2019-11-27 20:59:41.948799 Train Epoch: 71 [90/200 ]\tLoss: 0.000609\n",
      "Timestamp 2019-11-27 20:59:44.227970 Train Epoch: 71 [100/200 ]\tLoss: 0.000848\n",
      "Timestamp 2019-11-27 20:59:46.507874 Train Epoch: 71 [110/200 ]\tLoss: 0.000629\n",
      "Timestamp 2019-11-27 20:59:48.788778 Train Epoch: 71 [120/200 ]\tLoss: 0.000505\n",
      "Timestamp 2019-11-27 20:59:51.071880 Train Epoch: 71 [130/200 ]\tLoss: 0.000784\n",
      "Timestamp 2019-11-27 20:59:53.358560 Train Epoch: 71 [140/200 ]\tLoss: 0.000851\n",
      "Timestamp 2019-11-27 20:59:55.631013 Train Epoch: 71 [150/200 ]\tLoss: 0.000783\n",
      "Timestamp 2019-11-27 20:59:57.908994 Train Epoch: 71 [160/200 ]\tLoss: 0.001101\n",
      "Timestamp 2019-11-27 21:00:00.178291 Train Epoch: 71 [170/200 ]\tLoss: 0.000860\n",
      "Timestamp 2019-11-27 21:00:02.449692 Train Epoch: 71 [180/200 ]\tLoss: 0.000644\n",
      "Timestamp 2019-11-27 21:00:04.724878 Train Epoch: 71 [190/200 ]\tLoss: 0.001000\n",
      "Timestamp 2019-11-27 21:00:07.005372 Train Epoch: 71 [200/200 ]\tLoss: 0.000778\n",
      "====> Timestamp 2019-11-27 21:00:07.046827 Epoch: 71 Average loss: 0.00078463\n",
      "epoch: 71====> Test set loss: 0.15966656\n",
      "Timestamp 2019-11-27 21:00:20.092074 Train Epoch: 72 [10/200 ]\tLoss: 0.000560\n",
      "Timestamp 2019-11-27 21:00:22.369652 Train Epoch: 72 [20/200 ]\tLoss: 0.000684\n",
      "Timestamp 2019-11-27 21:00:24.654623 Train Epoch: 72 [30/200 ]\tLoss: 0.000671\n",
      "Timestamp 2019-11-27 21:00:26.940427 Train Epoch: 72 [40/200 ]\tLoss: 0.000940\n",
      "Timestamp 2019-11-27 21:00:29.221356 Train Epoch: 72 [50/200 ]\tLoss: 0.000709\n",
      "Timestamp 2019-11-27 21:00:31.493600 Train Epoch: 72 [60/200 ]\tLoss: 0.000844\n",
      "Timestamp 2019-11-27 21:00:33.774059 Train Epoch: 72 [70/200 ]\tLoss: 0.000823\n",
      "Timestamp 2019-11-27 21:00:36.058855 Train Epoch: 72 [80/200 ]\tLoss: 0.000753\n",
      "Timestamp 2019-11-27 21:00:38.344118 Train Epoch: 72 [90/200 ]\tLoss: 0.000566\n",
      "Timestamp 2019-11-27 21:00:40.635524 Train Epoch: 72 [100/200 ]\tLoss: 0.000905\n",
      "Timestamp 2019-11-27 21:00:42.913711 Train Epoch: 72 [110/200 ]\tLoss: 0.000592\n",
      "Timestamp 2019-11-27 21:00:45.197982 Train Epoch: 72 [120/200 ]\tLoss: 0.000535\n",
      "Timestamp 2019-11-27 21:00:47.477431 Train Epoch: 72 [130/200 ]\tLoss: 0.000808\n",
      "Timestamp 2019-11-27 21:00:49.762418 Train Epoch: 72 [140/200 ]\tLoss: 0.000775\n",
      "Timestamp 2019-11-27 21:00:52.042648 Train Epoch: 72 [150/200 ]\tLoss: 0.000734\n",
      "Timestamp 2019-11-27 21:00:54.323865 Train Epoch: 72 [160/200 ]\tLoss: 0.001114\n",
      "Timestamp 2019-11-27 21:00:56.601128 Train Epoch: 72 [170/200 ]\tLoss: 0.000830\n",
      "Timestamp 2019-11-27 21:00:58.883962 Train Epoch: 72 [180/200 ]\tLoss: 0.000649\n",
      "Timestamp 2019-11-27 21:01:01.165547 Train Epoch: 72 [190/200 ]\tLoss: 0.000966\n",
      "Timestamp 2019-11-27 21:01:03.445640 Train Epoch: 72 [200/200 ]\tLoss: 0.000788\n",
      "====> Timestamp 2019-11-27 21:01:03.489767 Epoch: 72 Average loss: 0.00077449\n",
      "epoch: 72====> Test set loss: 0.16062481\n",
      "Timestamp 2019-11-27 21:01:16.499325 Train Epoch: 73 [10/200 ]\tLoss: 0.000571\n",
      "Timestamp 2019-11-27 21:01:18.774678 Train Epoch: 73 [20/200 ]\tLoss: 0.000656\n",
      "Timestamp 2019-11-27 21:01:21.054086 Train Epoch: 73 [30/200 ]\tLoss: 0.000651\n",
      "Timestamp 2019-11-27 21:01:23.334457 Train Epoch: 73 [40/200 ]\tLoss: 0.000879\n",
      "Timestamp 2019-11-27 21:01:25.619121 Train Epoch: 73 [50/200 ]\tLoss: 0.000719\n",
      "Timestamp 2019-11-27 21:01:27.906464 Train Epoch: 73 [60/200 ]\tLoss: 0.000795\n",
      "Timestamp 2019-11-27 21:01:30.183296 Train Epoch: 73 [70/200 ]\tLoss: 0.000851\n",
      "Timestamp 2019-11-27 21:01:32.465147 Train Epoch: 73 [80/200 ]\tLoss: 0.000716\n",
      "Timestamp 2019-11-27 21:01:34.745394 Train Epoch: 73 [90/200 ]\tLoss: 0.000564\n",
      "Timestamp 2019-11-27 21:01:37.026828 Train Epoch: 73 [100/200 ]\tLoss: 0.000834\n",
      "Timestamp 2019-11-27 21:01:39.323168 Train Epoch: 73 [110/200 ]\tLoss: 0.000614\n",
      "Timestamp 2019-11-27 21:01:41.602995 Train Epoch: 73 [120/200 ]\tLoss: 0.000517\n",
      "Timestamp 2019-11-27 21:01:43.882029 Train Epoch: 73 [130/200 ]\tLoss: 0.000804\n",
      "Timestamp 2019-11-27 21:01:46.162943 Train Epoch: 73 [140/200 ]\tLoss: 0.000817\n",
      "Timestamp 2019-11-27 21:01:48.447693 Train Epoch: 73 [150/200 ]\tLoss: 0.000734\n",
      "Timestamp 2019-11-27 21:01:50.730285 Train Epoch: 73 [160/200 ]\tLoss: 0.001108\n",
      "Timestamp 2019-11-27 21:01:53.013763 Train Epoch: 73 [170/200 ]\tLoss: 0.000791\n",
      "Timestamp 2019-11-27 21:01:55.294252 Train Epoch: 73 [180/200 ]\tLoss: 0.000610\n",
      "Timestamp 2019-11-27 21:01:57.568936 Train Epoch: 73 [190/200 ]\tLoss: 0.001009\n",
      "Timestamp 2019-11-27 21:01:59.844855 Train Epoch: 73 [200/200 ]\tLoss: 0.000734\n",
      "====> Timestamp 2019-11-27 21:01:59.888167 Epoch: 73 Average loss: 0.00077063\n",
      "epoch: 73====> Test set loss: 0.16058099\n",
      "Timestamp 2019-11-27 21:02:12.952553 Train Epoch: 74 [10/200 ]\tLoss: 0.000540\n",
      "Timestamp 2019-11-27 21:02:15.233878 Train Epoch: 74 [20/200 ]\tLoss: 0.000678\n",
      "Timestamp 2019-11-27 21:02:17.509087 Train Epoch: 74 [30/200 ]\tLoss: 0.000607\n",
      "Timestamp 2019-11-27 21:02:19.789229 Train Epoch: 74 [40/200 ]\tLoss: 0.000880\n",
      "Timestamp 2019-11-27 21:02:22.065730 Train Epoch: 74 [50/200 ]\tLoss: 0.000727\n",
      "Timestamp 2019-11-27 21:02:24.353545 Train Epoch: 74 [60/200 ]\tLoss: 0.000826\n",
      "Timestamp 2019-11-27 21:02:26.630245 Train Epoch: 74 [70/200 ]\tLoss: 0.000892\n",
      "Timestamp 2019-11-27 21:02:28.903919 Train Epoch: 74 [80/200 ]\tLoss: 0.000710\n",
      "Timestamp 2019-11-27 21:02:31.177727 Train Epoch: 74 [90/200 ]\tLoss: 0.000577\n",
      "Timestamp 2019-11-27 21:02:33.445548 Train Epoch: 74 [100/200 ]\tLoss: 0.000858\n",
      "Timestamp 2019-11-27 21:02:35.722785 Train Epoch: 74 [110/200 ]\tLoss: 0.000636\n",
      "Timestamp 2019-11-27 21:02:37.997934 Train Epoch: 74 [120/200 ]\tLoss: 0.000549\n",
      "Timestamp 2019-11-27 21:02:40.284532 Train Epoch: 74 [130/200 ]\tLoss: 0.000790\n",
      "Timestamp 2019-11-27 21:02:42.551374 Train Epoch: 74 [140/200 ]\tLoss: 0.000811\n",
      "Timestamp 2019-11-27 21:02:44.826322 Train Epoch: 74 [150/200 ]\tLoss: 0.000712\n",
      "Timestamp 2019-11-27 21:02:47.096424 Train Epoch: 74 [160/200 ]\tLoss: 0.001120\n",
      "Timestamp 2019-11-27 21:02:49.367511 Train Epoch: 74 [170/200 ]\tLoss: 0.000816\n",
      "Timestamp 2019-11-27 21:02:51.641439 Train Epoch: 74 [180/200 ]\tLoss: 0.000589\n",
      "Timestamp 2019-11-27 21:02:53.917706 Train Epoch: 74 [190/200 ]\tLoss: 0.000988\n",
      "Timestamp 2019-11-27 21:02:56.193924 Train Epoch: 74 [200/200 ]\tLoss: 0.000791\n",
      "====> Timestamp 2019-11-27 21:02:56.240247 Epoch: 74 Average loss: 0.00076684\n",
      "epoch: 74====> Test set loss: 0.16482335\n",
      "Timestamp 2019-11-27 21:03:09.252019 Train Epoch: 75 [10/200 ]\tLoss: 0.000537\n",
      "Timestamp 2019-11-27 21:03:11.527906 Train Epoch: 75 [20/200 ]\tLoss: 0.000618\n",
      "Timestamp 2019-11-27 21:03:13.801871 Train Epoch: 75 [30/200 ]\tLoss: 0.000667\n",
      "Timestamp 2019-11-27 21:03:16.073401 Train Epoch: 75 [40/200 ]\tLoss: 0.000930\n",
      "Timestamp 2019-11-27 21:03:18.352880 Train Epoch: 75 [50/200 ]\tLoss: 0.000733\n",
      "Timestamp 2019-11-27 21:03:20.624979 Train Epoch: 75 [60/200 ]\tLoss: 0.000787\n",
      "Timestamp 2019-11-27 21:03:22.901742 Train Epoch: 75 [70/200 ]\tLoss: 0.000811\n",
      "Timestamp 2019-11-27 21:03:25.168600 Train Epoch: 75 [80/200 ]\tLoss: 0.000686\n",
      "Timestamp 2019-11-27 21:03:27.442566 Train Epoch: 75 [90/200 ]\tLoss: 0.000540\n",
      "Timestamp 2019-11-27 21:03:29.709748 Train Epoch: 75 [100/200 ]\tLoss: 0.000853\n",
      "Timestamp 2019-11-27 21:03:31.975105 Train Epoch: 75 [110/200 ]\tLoss: 0.000625\n",
      "Timestamp 2019-11-27 21:03:34.253677 Train Epoch: 75 [120/200 ]\tLoss: 0.000488\n",
      "Timestamp 2019-11-27 21:03:36.535126 Train Epoch: 75 [130/200 ]\tLoss: 0.000799\n",
      "Timestamp 2019-11-27 21:03:38.802028 Train Epoch: 75 [140/200 ]\tLoss: 0.000833\n",
      "Timestamp 2019-11-27 21:03:41.080974 Train Epoch: 75 [150/200 ]\tLoss: 0.000730\n",
      "Timestamp 2019-11-27 21:03:43.358027 Train Epoch: 75 [160/200 ]\tLoss: 0.001151\n",
      "Timestamp 2019-11-27 21:03:45.626218 Train Epoch: 75 [170/200 ]\tLoss: 0.000805\n",
      "Timestamp 2019-11-27 21:03:47.901160 Train Epoch: 75 [180/200 ]\tLoss: 0.000633\n",
      "Timestamp 2019-11-27 21:03:50.183142 Train Epoch: 75 [190/200 ]\tLoss: 0.000961\n",
      "Timestamp 2019-11-27 21:03:52.459458 Train Epoch: 75 [200/200 ]\tLoss: 0.000699\n",
      "====> Timestamp 2019-11-27 21:03:52.506166 Epoch: 75 Average loss: 0.00076795\n",
      "epoch: 75====> Test set loss: 0.16415793\n",
      "Timestamp 2019-11-27 21:04:05.641315 Train Epoch: 76 [10/200 ]\tLoss: 0.000508\n",
      "Timestamp 2019-11-27 21:04:07.921274 Train Epoch: 76 [20/200 ]\tLoss: 0.000610\n",
      "Timestamp 2019-11-27 21:04:10.211031 Train Epoch: 76 [30/200 ]\tLoss: 0.000624\n",
      "Timestamp 2019-11-27 21:04:12.492534 Train Epoch: 76 [40/200 ]\tLoss: 0.000939\n",
      "Timestamp 2019-11-27 21:04:14.776589 Train Epoch: 76 [50/200 ]\tLoss: 0.000717\n",
      "Timestamp 2019-11-27 21:04:17.052706 Train Epoch: 76 [60/200 ]\tLoss: 0.000814\n",
      "Timestamp 2019-11-27 21:04:19.344815 Train Epoch: 76 [70/200 ]\tLoss: 0.000848\n",
      "Timestamp 2019-11-27 21:04:21.619996 Train Epoch: 76 [80/200 ]\tLoss: 0.000711\n",
      "Timestamp 2019-11-27 21:04:23.902100 Train Epoch: 76 [90/200 ]\tLoss: 0.000561\n",
      "Timestamp 2019-11-27 21:04:26.180283 Train Epoch: 76 [100/200 ]\tLoss: 0.000811\n",
      "Timestamp 2019-11-27 21:04:28.466570 Train Epoch: 76 [110/200 ]\tLoss: 0.000602\n",
      "Timestamp 2019-11-27 21:04:30.755803 Train Epoch: 76 [120/200 ]\tLoss: 0.000479\n",
      "Timestamp 2019-11-27 21:04:33.037528 Train Epoch: 76 [130/200 ]\tLoss: 0.000813\n",
      "Timestamp 2019-11-27 21:04:35.315963 Train Epoch: 76 [140/200 ]\tLoss: 0.000808\n",
      "Timestamp 2019-11-27 21:04:37.596236 Train Epoch: 76 [150/200 ]\tLoss: 0.000716\n",
      "Timestamp 2019-11-27 21:04:39.893745 Train Epoch: 76 [160/200 ]\tLoss: 0.001114\n",
      "Timestamp 2019-11-27 21:04:42.171036 Train Epoch: 76 [170/200 ]\tLoss: 0.000800\n",
      "Timestamp 2019-11-27 21:04:44.444697 Train Epoch: 76 [180/200 ]\tLoss: 0.000610\n",
      "Timestamp 2019-11-27 21:04:46.721310 Train Epoch: 76 [190/200 ]\tLoss: 0.000987\n",
      "Timestamp 2019-11-27 21:04:48.990917 Train Epoch: 76 [200/200 ]\tLoss: 0.000700\n",
      "====> Timestamp 2019-11-27 21:04:49.034009 Epoch: 76 Average loss: 0.00075597\n",
      "epoch: 76====> Test set loss: 0.16419071\n",
      "Timestamp 2019-11-27 21:05:02.214818 Train Epoch: 77 [10/200 ]\tLoss: 0.000545\n",
      "Timestamp 2019-11-27 21:05:04.492727 Train Epoch: 77 [20/200 ]\tLoss: 0.000624\n",
      "Timestamp 2019-11-27 21:05:06.770266 Train Epoch: 77 [30/200 ]\tLoss: 0.000640\n",
      "Timestamp 2019-11-27 21:05:09.054433 Train Epoch: 77 [40/200 ]\tLoss: 0.000904\n",
      "Timestamp 2019-11-27 21:05:11.348154 Train Epoch: 77 [50/200 ]\tLoss: 0.000717\n",
      "Timestamp 2019-11-27 21:05:13.625353 Train Epoch: 77 [60/200 ]\tLoss: 0.000817\n",
      "Timestamp 2019-11-27 21:05:15.906907 Train Epoch: 77 [70/200 ]\tLoss: 0.000861\n",
      "Timestamp 2019-11-27 21:05:18.194967 Train Epoch: 77 [80/200 ]\tLoss: 0.000696\n",
      "Timestamp 2019-11-27 21:05:20.470024 Train Epoch: 77 [90/200 ]\tLoss: 0.000582\n",
      "Timestamp 2019-11-27 21:05:22.750915 Train Epoch: 77 [100/200 ]\tLoss: 0.000839\n",
      "Timestamp 2019-11-27 21:05:25.035064 Train Epoch: 77 [110/200 ]\tLoss: 0.000607\n",
      "Timestamp 2019-11-27 21:05:27.311142 Train Epoch: 77 [120/200 ]\tLoss: 0.000545\n",
      "Timestamp 2019-11-27 21:05:29.588588 Train Epoch: 77 [130/200 ]\tLoss: 0.000787\n",
      "Timestamp 2019-11-27 21:05:31.866774 Train Epoch: 77 [140/200 ]\tLoss: 0.000834\n",
      "Timestamp 2019-11-27 21:05:34.141307 Train Epoch: 77 [150/200 ]\tLoss: 0.000727\n",
      "Timestamp 2019-11-27 21:05:36.413309 Train Epoch: 77 [160/200 ]\tLoss: 0.001155\n",
      "Timestamp 2019-11-27 21:05:38.697816 Train Epoch: 77 [170/200 ]\tLoss: 0.000765\n",
      "Timestamp 2019-11-27 21:05:40.983814 Train Epoch: 77 [180/200 ]\tLoss: 0.000583\n",
      "Timestamp 2019-11-27 21:05:43.260533 Train Epoch: 77 [190/200 ]\tLoss: 0.000990\n",
      "Timestamp 2019-11-27 21:05:45.543157 Train Epoch: 77 [200/200 ]\tLoss: 0.000769\n",
      "====> Timestamp 2019-11-27 21:05:45.588992 Epoch: 77 Average loss: 0.00075486\n",
      "epoch: 77====> Test set loss: 0.16504288\n",
      "Timestamp 2019-11-27 21:05:58.704664 Train Epoch: 78 [10/200 ]\tLoss: 0.000534\n",
      "Timestamp 2019-11-27 21:06:01.052142 Train Epoch: 78 [20/200 ]\tLoss: 0.000594\n",
      "Timestamp 2019-11-27 21:06:03.428269 Train Epoch: 78 [30/200 ]\tLoss: 0.000607\n",
      "Timestamp 2019-11-27 21:06:05.874346 Train Epoch: 78 [40/200 ]\tLoss: 0.000897\n",
      "Timestamp 2019-11-27 21:06:08.294758 Train Epoch: 78 [50/200 ]\tLoss: 0.000694\n",
      "Timestamp 2019-11-27 21:06:10.658379 Train Epoch: 78 [60/200 ]\tLoss: 0.000802\n",
      "Timestamp 2019-11-27 21:06:13.032757 Train Epoch: 78 [70/200 ]\tLoss: 0.000808\n",
      "Timestamp 2019-11-27 21:06:15.448728 Train Epoch: 78 [80/200 ]\tLoss: 0.000668\n",
      "Timestamp 2019-11-27 21:06:17.841792 Train Epoch: 78 [90/200 ]\tLoss: 0.000590\n",
      "Timestamp 2019-11-27 21:06:20.195969 Train Epoch: 78 [100/200 ]\tLoss: 0.000792\n",
      "Timestamp 2019-11-27 21:06:22.536077 Train Epoch: 78 [110/200 ]\tLoss: 0.000592\n",
      "Timestamp 2019-11-27 21:06:24.885233 Train Epoch: 78 [120/200 ]\tLoss: 0.000510\n",
      "Timestamp 2019-11-27 21:06:27.246967 Train Epoch: 78 [130/200 ]\tLoss: 0.000767\n",
      "Timestamp 2019-11-27 21:06:29.591498 Train Epoch: 78 [140/200 ]\tLoss: 0.000815\n",
      "Timestamp 2019-11-27 21:06:31.980297 Train Epoch: 78 [150/200 ]\tLoss: 0.000712\n",
      "Timestamp 2019-11-27 21:06:34.381916 Train Epoch: 78 [160/200 ]\tLoss: 0.001073\n",
      "Timestamp 2019-11-27 21:06:36.764878 Train Epoch: 78 [170/200 ]\tLoss: 0.000798\n",
      "Timestamp 2019-11-27 21:06:39.162037 Train Epoch: 78 [180/200 ]\tLoss: 0.000594\n",
      "====> Timestamp 2019-11-27 21:06:39.205613 Epoch: 78 Average loss: 0.00067521\n",
      "epoch: 78====> Test set loss: 0.16276648\n",
      "CPU times: user 46min 34s, sys: 27min 32s, total: 1h 14min 7s\n",
      "Wall time: 1h 14min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epoch_count = 1\n",
    "for e in epochs:\n",
    "    batches = chunks(e, batch_size, dim=0)\n",
    "    eloss = train(model, optimizer, loss_function, batches, epoch_count, epoch_size, device, log_interval=10)\n",
    "    test(model, loss_function, test_data, epoch_count, device, max_data=50)\n",
    "    epoch_count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# epoch_count = 2\n",
    "# eloss = train(model, optimizer, loss_function, batches, epoch_count, len(data), device, log_interval=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.save_model(\"./trained_models/conv1dcol\", \"conv1dcol_nll-loss_pretrained_epoch-{}\".format(epoch_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried different Nx50 sizes for batches but the only one that works is 50, it seems will be the maximum number of samples in each batch for the training in my GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue is that training does not seem to work correctly.\n",
    "\n",
    "All training losses (kl_div, mse_loss) seem to learn well only the first 100 batches and then nothing, it oscilates. After several different initializations with kl_div it worked better (the first loss was about initialized to -1 ... ) so initialization seems to take an important role here.\n",
    "\n",
    "I need to write a test function now to be able to measure with the test datasets and see the real accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37723136"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2617245696"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37723136"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48234496"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
