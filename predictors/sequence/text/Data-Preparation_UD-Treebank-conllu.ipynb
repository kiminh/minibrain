{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Multi-Language Supervised Part of Speech training.\n",
    "\n",
    "This notebook prepares the data pre-processed from the conllu ud-treebank v2.4.\n",
    "\n",
    "First load all datasets in memory (just because I can)\n",
    "\n",
    "Count the number of samples for each and do some statistics. \n",
    "\n",
    "Here I need to take into account the different sampling strategies. \n",
    "\n",
    "There is the need for each batch to contain samples from all the languages, if not the training will not be optimal. The sampling strategies impact the performance in over-sampled and sub-sampled languages.\n",
    "\n",
    "Mainly (TODO look back to the source and note it here) the different sampling strategies and their conditions are:\n",
    "\n",
    "- Sampling the same amount from each language: Benefits the languages with less training samples and they take advantage from the learning of the languages with most samples. Penalises the languages with more samples.\n",
    "- Rate based: benefits transfer from languages with more samples to less ones and does not penalises too much the languages with more data. \n",
    "- Proportional: penalises the most the languages with less data.\n",
    "\n",
    "\n",
    "Data on the datasets with the least should not be repeated (at least too much) to avoid overfitting during this stage. The issue with overfitting now (I will be working on that later, testing what I can accomplish with overfitting)\n",
    "\n",
    "A supposition that I have is that more complex languages (syntactically and semantically) might be better for training and transferring knowledge to less complex and/or languages with less training data. I won't be trying to test this hypothesis (for the moment at least)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langmodels.utils.preprocess_conllu import *\n",
    "from utf8_encoder import *\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfiles = get_all_files_recurse(base_dir)\n",
    "charseq_files = [f for f in allfiles if f.endswith(\".pkl\") and \"charseq_code\" in f]  # typo in the file saving (fixed now in the .py file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(charseq_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "charseq_train = [ f for f in charseq_files if \"-train-\" in f]\n",
    "charseq_test = [ f for f in charseq_files if \"-test-\" in f]\n",
    "charseq_dev = [ f for f in charseq_files if \"-dev-\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 88, 130, 80)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(charseq_files), len(charseq_train), len(charseq_test), len(charseq_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load all data and start counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_list):\n",
    "    data = []\n",
    "    for fname in file_list:\n",
    "#         name = path_leaf(fname)\n",
    "        name = fname\n",
    "        with open(fname, \"rb\") as f:\n",
    "            d = pickle.load(f)\n",
    "            data.append((name, d))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.19 s, sys: 437 ms, total: 1.63 s\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_train = load_data(charseq_train)\n",
    "data_test = load_data(charseq_test)\n",
    "data_dev = load_data(charseq_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 130, 80)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train), len(data_test), len(data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count_train = [(n,len(d)) for n,d in data_train]\n",
    "data_count_test = [(n,len(d)) for n,d in data_test]\n",
    "data_count_dev = [(n,len(d)) for n,d in data_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data_count_train)\n",
    "df_train.columns = [\"name\", \"count\"]\n",
    "df_train = df_train.sort_values(\"count\")\n",
    "\n",
    "df_test = pd.DataFrame(data_count_test)\n",
    "df_test.columns = [\"name\", \"count\"]\n",
    "df_test = df_test.sort_values(\"count\")\n",
    "\n",
    "df_dev = pd.DataFrame(data_count_dev)\n",
    "df_dev.columns = [\"name\", \"count\"]\n",
    "df_dev = df_dev.sort_values(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>24633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>40801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>48814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>68495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>153035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name   count\n",
       "57  /home/leo/projects/Datasets/text/UniversalDepe...      19\n",
       "35  /home/leo/projects/Datasets/text/UniversalDepe...      19\n",
       "42  /home/leo/projects/Datasets/text/UniversalDepe...      23\n",
       "37  /home/leo/projects/Datasets/text/UniversalDepe...      87\n",
       "16  /home/leo/projects/Datasets/text/UniversalDepe...     153\n",
       "..                                                ...     ...\n",
       "44  /home/leo/projects/Datasets/text/UniversalDepe...   24633\n",
       "38  /home/leo/projects/Datasets/text/UniversalDepe...   40801\n",
       "83  /home/leo/projects/Datasets/text/UniversalDepe...   48814\n",
       "68  /home/leo/projects/Datasets/text/UniversalDepe...   68495\n",
       "66  /home/leo/projects/Datasets/text/UniversalDepe...  153035\n",
       "\n",
       "[88 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>3214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>6491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>7881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>10148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>18459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  count\n",
       "51   /home/leo/projects/Datasets/text/UniversalDepe...     34\n",
       "126  /home/leo/projects/Datasets/text/UniversalDepe...     36\n",
       "12   /home/leo/projects/Datasets/text/UniversalDepe...     49\n",
       "24   /home/leo/projects/Datasets/text/UniversalDepe...     55\n",
       "37   /home/leo/projects/Datasets/text/UniversalDepe...     57\n",
       "..                                                 ...    ...\n",
       "59   /home/leo/projects/Datasets/text/UniversalDepe...   3214\n",
       "124  /home/leo/projects/Datasets/text/UniversalDepe...   6491\n",
       "52   /home/leo/projects/Datasets/text/UniversalDepe...   7881\n",
       "96   /home/leo/projects/Datasets/text/UniversalDepe...  10148\n",
       "93   /home/leo/projects/Datasets/text/UniversalDepe...  18459\n",
       "\n",
       "[130 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>6584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>8427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>9270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>18434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  count\n",
       "15  /home/leo/projects/Datasets/text/UniversalDepe...     55\n",
       "20  /home/leo/projects/Datasets/text/UniversalDepe...     65\n",
       "34  /home/leo/projects/Datasets/text/UniversalDepe...     82\n",
       "58  /home/leo/projects/Datasets/text/UniversalDepe...    107\n",
       "10  /home/leo/projects/Datasets/text/UniversalDepe...    129\n",
       "..                                                ...    ...\n",
       "40  /home/leo/projects/Datasets/text/UniversalDepe...   3125\n",
       "75  /home/leo/projects/Datasets/text/UniversalDepe...   6584\n",
       "35  /home/leo/projects/Datasets/text/UniversalDepe...   8427\n",
       "61  /home/leo/projects/Datasets/text/UniversalDepe...   9270\n",
       "59  /home/leo/projects/Datasets/text/UniversalDepe...  18434\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10177.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18609.989946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1781.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5382.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13436.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>153035.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count\n",
       "count      88.000000\n",
       "mean    10177.272727\n",
       "std     18609.989946\n",
       "min        19.000000\n",
       "25%      1781.000000\n",
       "50%      5382.000000\n",
       "75%     13436.750000\n",
       "max    153035.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>130.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1201.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1990.188413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>471.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>923.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1131.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18459.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "count    130.000000\n",
       "mean    1201.100000\n",
       "std     1990.188413\n",
       "min       34.000000\n",
       "25%      471.750000\n",
       "50%      923.500000\n",
       "75%     1131.000000\n",
       "max    18459.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1443.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2447.523588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>529.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>894.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1419.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18434.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "count     80.000000\n",
       "mean    1443.787500\n",
       "std     2447.523588\n",
       "min       55.000000\n",
       "25%      529.750000\n",
       "50%      894.000000\n",
       "75%     1419.000000\n",
       "max    18434.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3690.684210526316"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "70123/19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportional sampling might be difficult as the difference between number of samples is too much. \n",
    "19 samples for the dataset with least data and 70123 for the most complete dataset. \n",
    "\n",
    "This means that I must do some sampling strategy that is proportional somehow but a rate of 3690 times is too much for it.\n",
    "\n",
    "Also the training order might be important, so better use the ones with least data at the end of the training, so they benefit from the previous training instead of initializing. \n",
    "\n",
    "Maybe repeating there a few times will not necessarilly overfit?\n",
    "\n",
    "So I will do that, I will order the trainig in a way that the last batches contain the samples from the languages with the least training data and the first batches will not contain them.\n",
    "\n",
    "Also all batches will be of a length that can contain at least a sample from each training (language) dataset.\n",
    "\n",
    "Also, for the languages with the lest number of samples might be good to merge the training with the dev datasets.\n",
    "\n",
    "There are also many datasets that don't contain train, test and or dev dataset. Some have only one of those, these are good for testing the generalization of the network on languages that are not trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  count\n",
       "57  /home/leo/projects/Datasets/text/UniversalDepe...     19\n",
       "35  /home/leo/projects/Datasets/text/UniversalDepe...     19\n",
       "42  /home/leo/projects/Datasets/text/UniversalDepe...     23\n",
       "37  /home/leo/projects/Datasets/text/UniversalDepe...     87\n",
       "16  /home/leo/projects/Datasets/text/UniversalDepe...    153\n",
       "21  /home/leo/projects/Datasets/text/UniversalDepe...    319\n",
       "2   /home/leo/projects/Datasets/text/UniversalDepe...    600\n",
       "65  /home/leo/projects/Datasets/text/UniversalDepe...    803\n",
       "4   /home/leo/projects/Datasets/text/UniversalDepe...    858\n",
       "11  /home/leo/projects/Datasets/text/UniversalDepe...    860\n",
       "79  /home/leo/projects/Datasets/text/UniversalDepe...    910\n",
       "80  /home/leo/projects/Datasets/text/UniversalDepe...   1015\n",
       "73  /home/leo/projects/Datasets/text/UniversalDepe...   1116\n",
       "3   /home/leo/projects/Datasets/text/UniversalDepe...   1123\n",
       "84  /home/leo/projects/Datasets/text/UniversalDepe...   1138\n",
       "9   /home/leo/projects/Datasets/text/UniversalDepe...   1156\n",
       "15  /home/leo/projects/Datasets/text/UniversalDepe...   1188\n",
       "33  /home/leo/projects/Datasets/text/UniversalDepe...   1315\n",
       "56  /home/leo/projects/Datasets/text/UniversalDepe...   1334\n",
       "8   /home/leo/projects/Datasets/text/UniversalDepe...   1435"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>6584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>8427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>9270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>18434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  count\n",
       "28  /home/leo/projects/Datasets/text/UniversalDepe...   1476\n",
       "77  /home/leo/projects/Datasets/text/UniversalDepe...   1654\n",
       "5   /home/leo/projects/Datasets/text/UniversalDepe...   1664\n",
       "30  /home/leo/projects/Datasets/text/UniversalDepe...   1709\n",
       "18  /home/leo/projects/Datasets/text/UniversalDepe...   1745\n",
       "0   /home/leo/projects/Datasets/text/UniversalDepe...   1798\n",
       "62  /home/leo/projects/Datasets/text/UniversalDepe...   1842\n",
       "64  /home/leo/projects/Datasets/text/UniversalDepe...   1852\n",
       "37  /home/leo/projects/Datasets/text/UniversalDepe...   1875\n",
       "9   /home/leo/projects/Datasets/text/UniversalDepe...   1890\n",
       "74  /home/leo/projects/Datasets/text/UniversalDepe...   1986\n",
       "55  /home/leo/projects/Datasets/text/UniversalDepe...   2002\n",
       "69  /home/leo/projects/Datasets/text/UniversalDepe...   2101\n",
       "56  /home/leo/projects/Datasets/text/UniversalDepe...   2215\n",
       "33  /home/leo/projects/Datasets/text/UniversalDepe...   2409\n",
       "40  /home/leo/projects/Datasets/text/UniversalDepe...   3125\n",
       "75  /home/leo/projects/Datasets/text/UniversalDepe...   6584\n",
       "35  /home/leo/projects/Datasets/text/UniversalDepe...   8427\n",
       "61  /home/leo/projects/Datasets/text/UniversalDepe...   9270\n",
       "59  /home/leo/projects/Datasets/text/UniversalDepe...  18434"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_name(fname):\n",
    "    rt = path_leaf(fname).split(\"-ud-\")[0]\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['name_root'] = df_train.name.apply(get_root_name)\n",
    "df_test['name_root'] = df_test.name.apply(get_root_name)\n",
    "df_dev['name_root'] = df_dev.name.apply(get_root_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "      <th>name_root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>19</td>\n",
       "      <td>bxr_bdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>19</td>\n",
       "      <td>olo_kkpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>23</td>\n",
       "      <td>hsb_ufal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>87</td>\n",
       "      <td>swl_sslc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>153</td>\n",
       "      <td>lt_hse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  count name_root\n",
       "57  /home/leo/projects/Datasets/text/UniversalDepe...     19   bxr_bdt\n",
       "35  /home/leo/projects/Datasets/text/UniversalDepe...     19  olo_kkpp\n",
       "42  /home/leo/projects/Datasets/text/UniversalDepe...     23  hsb_ufal\n",
       "37  /home/leo/projects/Datasets/text/UniversalDepe...     87  swl_sslc\n",
       "16  /home/leo/projects/Datasets/text/UniversalDepe...    153    lt_hse"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "smax_train = max([i[1] for i in data_count_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153035"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smax_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the issue is to create a sampling strategy. What should be done I don't know, but I'll create a strategy anyways with my supositions.\n",
    "\n",
    "So I'll do the following:\n",
    "- First I'll merge the language files per language, train and dev datasets will be merged to benefit the smaller langs\n",
    "- The batch size will be the number of languages that I'll be training the network\n",
    "- batches might not (will not) contain the same number of languages, but batches will be saved with the number of languages as reference\n",
    "- for training I'll first send the batches with the least language variability and at the end of each epoch the ones with the most variability (meaning the ones containing more languages)\n",
    "- The number of batches will be defined by .... ???\n",
    "\n",
    "Also for the languages that have more data I'll clean the datasets by filtering the language files according to the rating on the UD-treebank page. I'll start by the languages with more data by order.\n",
    "\n",
    "The datasets that I'm cleaning are the onces from German and Czeck:\n",
    "* Czech-CAC\n",
    "* Czech-CLTT\n",
    "* Czech-PUD\n",
    "\n",
    "For the German datasets I'll avoid merging the dev datasets and the following datasets are not used for the training:\n",
    "* German-GSD\n",
    "* German-PUD\n",
    "* German-LIT\n",
    "\n",
    "For Russian, German and Czech I won't merge the dev sets\n",
    "\n",
    "For the German HDT dataset there are two sets, a and b, dataset b is taken out because this dataset contains a lot of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging by language, also merging train and dev datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.55 s, sys: 305 ms, total: 5.85 s\n",
      "Wall time: 5.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_sentence_len = 1024\n",
    "\n",
    "# the pre-processing of the test data is much simpler, making it per file, not needing to merge and only filtering strings that are longer than the max_sentence data\n",
    "test_lang_dict = {}\n",
    "\n",
    "# filter data that is too big and padding data\n",
    "def filter_pad_data(data, max_len):\n",
    "    dta = [d for d in data if d.shape[1] <=max_sentence_len]\n",
    "    pad_dta = [np.pad(d, [(0,0),(0,1024 - d.shape[1])], mode='constant') for d in dta]\n",
    "    pad_ta = np.stack(pad_dta, axis=0).astype(\"uint16\")\n",
    "    return pad_dta\n",
    "\n",
    "for fname,data in data_test:\n",
    "    test_lang_dict[fname] = filter_pad_data(data, max_sentence_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_lang_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 242 ms, sys: 830 ms, total: 1.07 s\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save all data for testing in vectorized format already\n",
    "\n",
    "for oname, data in test_lang_dict.items():\n",
    "    fname = oname.replace(\".pkl\", \"_test-pad-3x1024_uint16.npy\")\n",
    "    np.save(fname, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dict = {}\n",
    "\n",
    "for fname,data in data_train + data_dev:\n",
    "    lang = fname.split(\"_\")[0]  # language is as the first 2 or 3 chars of the filename\n",
    "    # avoid merging dev sets for the languages with more data\n",
    "    if lang in [\"de\", \"cs\", \"ru\"]:\n",
    "        print(\"lang \", lang, \" fname: \", fname)\n",
    "        if \"-dev-\" in fname or \"de_hdt-ud-train-b\" in fname:\n",
    "            print(\"skipping: \", fname)\n",
    "            continue\n",
    "    if not lang in lang_dict:\n",
    "        lang_dict[lang] = data\n",
    "    else:\n",
    "        lang_dict[lang] += data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lang_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count_traindev = [(k,len(d)) for k,d in lang_dict.items()]\n",
    "df_traindev = pd.DataFrame(data_count_traindev)\n",
    "df_traindev.columns = [\"name\", \"count\"]\n",
    "df_traindev = df_traindev.sort_values(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1011103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name    count\n",
       "0  /home/leo/projects/Datasets/text/UniversalDepe...  1011103"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_traindev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1011103"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_traindev[\"count\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The threshold for the number of batches will be chosen as to maximize the number of complete batches, this will also give the number of languages in each batch set.\n",
    "~~Just because (arbitrary number) I decide that the batches with the least languages will be 10, this might give enough language variability for the training. ~~\n",
    "\n",
    "As there are 50 languages, the batches will contain 50 samples (from REVISITING SMALL BATCH TRAINING FOR DEEP NEURAL NETWORKS https://arxiv.org/pdf/1804.07612.pdf small batches are better)~~, so the batches with the least n# of languages will contain 5 samples per lang, and the ones with 50 languages one sample per batch.~~\n",
    "\n",
    "To complete the batch for the ones that are not with all the languages I intend to randomly choose from the ~~10~~ N languages with the most samples, this is done by randomly shuffling the remaining data from the threshold sampling chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_len = 1024\n",
    "\n",
    "# creating a list to fill the missing data in the batches, data will be then randomly shuffled\n",
    "# I explore here the minimum number of languages that will give me the maximum number of batches.\n",
    "# I'm looking only in the number of samples of the languages, not other point.\n",
    "\n",
    "fi_len = 30437  # with this threshold I only keep up to 17 languages and 17524 batches\n",
    "ar_len = 24759  # with this threshold I only keep up to 14 languages and 20953 batches\n",
    "ro_len = 19991  # with this threshold I only keep up to 15 languages and 19991 batches \n",
    "# is the SWEET SPOT for the max number of batches\n",
    "ca_len = 14832 # with this threshold I only keep up to 20 languages and 14832 batches  and there are 749 extra batches with up to 19 languages\n",
    "threshold_len = ca_len\n",
    "\n",
    "fill_data =[]\n",
    "# create batches, later\n",
    "for lang, data in lang_dict.items():\n",
    "    if len(data)> threshold_len:\n",
    "        dta = [d for d in data[threshold_len:] if d.shape[1] <= max_sentence_len]\n",
    "        fill_data.extend(dta)\n",
    "        \n",
    "# ensure that the data chosen to fill the missing elements is random \n",
    "# (and will statistically be proportional to the number of datapoints of each language)\n",
    "random.shuffle(fill_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996211"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fill_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "batches = []\n",
    "\n",
    "# create batches, later\n",
    "for i in range(threshold_len):  \n",
    "    bid=0\n",
    "    langs=[]\n",
    "    datas=[]\n",
    "    for lang, data in lang_dict.items():\n",
    "        if len(data)> i and data[i].shape[1] <= max_sentence_len:\n",
    "            langs.append(lang)\n",
    "            datas.append(data[i])\n",
    "    while len(datas) < len(lang_dict.keys()):\n",
    "        datas.append(fill_data.pop())\n",
    "    batch = (bid, langs, datas)\n",
    "    batches.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996209"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fill_data)  # there is data still left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_samples_10 = len(fill_data) //50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19924"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_samples_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_10_langs = list(chunks(fill_data, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all batches are 50 samples long\n",
    "batch_lens = list(map(lambda x: len(x[2]), batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14832, 1, 1, 19925)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_lens), max(batch_lens), min(batch_lens), len(batches_10_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741600"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14832 * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779050"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are then a maximum\n",
    "(14832 + 749) * 50\n",
    "# datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that the data is OK $ 779078  > 779050$ \n",
    "So the number of original samples is bigger than the number of samples on the prepared dataset. This is OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many languages and how many batches with each amount of languages\n",
    "b_stats = {}\n",
    "for bid, blangs, bdatas in batches:\n",
    "    l = len(blangs)\n",
    "    if l in b_stats:\n",
    "        b_stats[l] +=1\n",
    "    else:\n",
    "        b_stats[l] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 14830, 0: 2}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to make something for the data shape such as all batches are the same shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I need now to create the list of batches, reverse the order as the training order will be from the least diverse to the most diverse batches up to 50 languages in the last 19 batches (the number of samples the language with least training data has).\n",
    "\n",
    "I take out the last array from the batches_10_langs at it is not complete with 50 samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_data = list(map(lambda x: x[2], batches)) + batches_10_langs[:-1]\n",
    "batches_data.reverse()  # have to train first with the least diverse, and at the end with the most diverse ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1737800"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches_data) * 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find the maximum lenght of all the data samples, this will be the dimension needed for the numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = []\n",
    "for b in batches_data:\n",
    "    for s in b:\n",
    "        seq_len.append(s.shape[1])\n",
    "\n",
    "min_seq_len, max_seq_len = min(seq_len), max(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1019)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_seq_len, max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many languages and how many batches with each amount of languages\n",
    "len_stats = {}\n",
    "for l in seq_len:\n",
    "    if l in len_stats:\n",
    "        len_stats[l] +=1\n",
    "    else:\n",
    "        len_stats[l] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_stats = SortedDict(sorted(len_stats.items(), key=lambda kv: kv[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SortedDict({1: 934, 2: 1277, 3: 1850, 4: 2850, 5: 3802, 6: 3973, 7: 4733, 8: 4689, 9: 4922, 10: 5179, 11: 5331, 12: 5453, 13: 6166, 14: 5840, 15: 6603, 16: 6124, 17: 6754, 18: 6346, 19: 7926, 20: 6398, 21: 7076, 22: 6639, 23: 7291, 24: 6958, 25: 7502, 26: 7123, 27: 7618, 28: 7212, 29: 7694, 30: 7050, 31: 7915, 32: 7237, 33: 7734, 34: 7167, 35: 7764, 36: 7326, 37: 7865, 38: 6955, 39: 7491, 40: 7084, 41: 7628, 42: 6967, 43: 7656, 44: 6860, 45: 7439, 46: 6806, 47: 7341, 48: 6670, 49: 7229, 50: 6697, 51: 7020, 52: 6463, 53: 7247, 54: 6628, 55: 7020, 56: 6376, 57: 6922, 58: 6465, 59: 6744, 60: 6400, 61: 6779, 62: 6251, 63: 6478, 64: 6158, 65: 6530, 66: 6171, 67: 6537, 68: 6209, 69: 6511, 70: 6074, 71: 6409, 72: 6022, 73: 6333, 74: 6082, 75: 6237, 76: 5852, 77: 6312, 78: 5956, 79: 6197, 80: 5882, 81: 6160, 82: 5721, 83: 6173, 84: 5678, 85: 6044, 86: 5719, 87: 5940, 88: 5642, 89: 5857, 90: 5482, 91: 5585, 92: 5514, 93: 5583, 94: 5356, 95: 5387, 96: 5341, 97: 5397, 98: 5149, 99: 5378, 100: 5015, 101: 5103, 102: 5106, 103: 5145, 104: 5195, 105: 5214, 106: 4979, 107: 5062, 108: 4694, 109: 4805, 110: 4729, 111: 4807, 112: 4706, 113: 4707, 114: 4610, 115: 4664, 116: 4445, 117: 4522, 118: 4274, 119: 4358, 120: 4382, 121: 4271, 122: 4313, 123: 4369, 124: 4158, 125: 4149, 126: 4096, 127: 3989, 128: 3958, 129: 4041, 130: 3991, 131: 3947, 132: 3799, 133: 3857, 134: 3806, 135: 3872, 136: 3828, 137: 3707, 138: 3662, 139: 3684, 140: 3490, 141: 3451, 142: 3254, 143: 3180, 144: 3192, 145: 3196, 146: 3181, 147: 3182, 148: 3043, 149: 3089, 150: 2987, 151: 3005, 152: 2865, 153: 2871, 154: 2844, 155: 2680, 156: 2730, 157: 2672, 158: 2676, 159: 2643, 160: 2625, 161: 2563, 162: 2521, 163: 2524, 164: 2413, 165: 2411, 166: 2305, 167: 2416, 168: 2373, 169: 2246, 170: 2183, 171: 2248, 172: 2215, 173: 2205, 174: 2088, 175: 1996, 176: 2045, 177: 2051, 178: 1967, 179: 2095, 180: 1943, 181: 1951, 182: 1888, 183: 1830, 184: 1851, 185: 1767, 186: 1784, 187: 1715, 188: 1775, 189: 1629, 190: 1602, 191: 1658, 192: 1581, 193: 1587, 194: 1505, 195: 1530, 196: 1481, 197: 1526, 198: 1466, 199: 1395, 200: 1356, 201: 1360, 202: 1329, 203: 1344, 204: 1278, 205: 1257, 206: 1174, 207: 1221, 208: 1263, 209: 1225, 210: 1191, 211: 1152, 212: 1171, 213: 1144, 214: 1063, 215: 1038, 216: 1020, 217: 1093, 218: 1043, 219: 1019, 220: 1016, 221: 1013, 222: 988, 223: 984, 224: 915, 225: 890, 226: 936, 227: 882, 228: 811, 229: 869, 230: 848, 231: 814, 232: 800, 233: 804, 234: 797, 235: 773, 236: 731, 237: 757, 238: 773, 239: 715, 240: 684, 241: 732, 242: 707, 243: 683, 244: 675, 245: 646, 246: 652, 247: 647, 248: 585, 249: 620, 250: 590, 251: 580, 252: 545, 253: 535, 254: 550, 255: 542, 256: 534, 257: 500, 258: 496, 259: 553, 260: 483, 261: 458, 262: 472, 263: 460, 264: 446, 265: 488, 266: 468, 267: 431, 268: 455, 269: 450, 270: 416, 271: 400, 272: 393, 273: 406, 274: 371, 275: 325, 276: 377, 277: 374, 278: 352, 279: 345, 280: 358, 281: 308, 282: 291, 283: 343, 284: 318, 285: 329, 286: 304, 287: 296, 288: 313, 289: 323, 290: 294, 291: 277, 292: 283, 293: 271, 294: 258, 295: 282, 296: 261, 297: 231, 298: 237, 299: 223, 300: 239, 301: 229, 302: 222, 303: 232, 304: 230, 305: 216, 306: 225, 307: 213, 308: 212, 309: 201, 310: 192, 311: 221, 312: 170, 313: 186, 314: 169, 315: 199, 316: 188, 317: 172, 318: 184, 319: 188, 320: 150, 321: 174, 322: 137, 323: 151, 324: 150, 325: 150, 326: 161, 327: 123, 328: 150, 329: 152, 330: 136, 331: 125, 332: 130, 333: 127, 334: 152, 335: 124, 336: 136, 337: 140, 338: 115, 339: 94, 340: 95, 341: 119, 342: 103, 343: 105, 344: 109, 345: 107, 346: 115, 347: 110, 348: 92, 349: 103, 350: 106, 351: 81, 352: 93, 353: 97, 354: 95, 355: 100, 356: 88, 357: 73, 358: 74, 359: 79, 360: 72, 361: 79, 362: 73, 363: 80, 364: 72, 365: 84, 366: 62, 367: 71, 368: 72, 369: 63, 370: 71, 371: 73, 372: 64, 373: 61, 374: 61, 375: 58, 376: 67, 377: 72, 378: 66, 379: 66, 380: 67, 381: 63, 382: 55, 383: 54, 384: 54, 385: 61, 386: 40, 387: 50, 388: 47, 389: 53, 390: 58, 391: 52, 392: 45, 393: 61, 394: 47, 395: 48, 396: 37, 397: 42, 398: 44, 399: 41, 400: 36, 401: 50, 402: 50, 403: 34, 404: 38, 405: 35, 406: 39, 407: 23, 408: 36, 409: 31, 410: 46, 411: 39, 412: 43, 413: 44, 414: 36, 415: 27, 416: 30, 417: 36, 418: 26, 419: 30, 420: 29, 421: 35, 422: 30, 423: 25, 424: 30, 425: 17, 426: 31, 427: 19, 428: 30, 429: 22, 430: 25, 431: 33, 432: 28, 433: 22, 434: 22, 435: 24, 436: 19, 437: 29, 438: 21, 439: 28, 440: 21, 441: 28, 442: 26, 443: 19, 444: 25, 445: 15, 446: 18, 447: 27, 448: 11, 449: 15, 450: 12, 451: 22, 452: 15, 453: 18, 454: 14, 455: 16, 456: 14, 457: 9, 458: 15, 459: 16, 460: 14, 461: 19, 462: 20, 463: 13, 464: 9, 465: 10, 466: 18, 467: 10, 468: 16, 469: 19, 470: 14, 471: 19, 472: 12, 473: 6, 474: 14, 475: 16, 476: 15, 477: 15, 478: 17, 479: 12, 480: 11, 481: 14, 482: 16, 483: 12, 484: 16, 485: 13, 486: 19, 487: 20, 488: 6, 489: 9, 490: 11, 491: 10, 492: 9, 493: 9, 494: 9, 495: 9, 496: 11, 497: 13, 498: 14, 499: 11, 500: 10, 501: 9, 502: 18, 503: 9, 504: 8, 505: 7, 506: 6, 507: 13, 508: 8, 509: 5, 510: 11, 511: 10, 512: 11, 513: 8, 514: 10, 515: 7, 516: 8, 517: 6, 518: 7, 519: 3, 520: 6, 521: 5, 522: 9, 523: 7, 524: 10, 525: 6, 526: 3, 527: 7, 528: 8, 529: 4, 530: 6, 531: 7, 532: 2, 533: 11, 534: 6, 535: 9, 536: 12, 537: 6, 538: 6, 539: 3, 540: 5, 541: 7, 542: 5, 543: 6, 544: 4, 545: 6, 546: 6, 547: 5, 548: 9, 549: 3, 550: 4, 551: 4, 552: 4, 553: 3, 554: 5, 555: 4, 556: 5, 557: 5, 558: 2, 559: 3, 560: 2, 561: 3, 562: 5, 563: 7, 564: 6, 565: 5, 566: 4, 567: 9, 568: 2, 569: 3, 570: 3, 571: 1, 572: 3, 573: 6, 574: 5, 575: 5, 576: 4, 577: 5, 578: 4, 579: 4, 580: 4, 581: 3, 582: 4, 583: 2, 584: 4, 585: 1, 586: 4, 587: 2, 588: 3, 589: 2, 590: 4, 591: 2, 592: 7, 593: 2, 594: 4, 595: 2, 597: 4, 598: 1, 599: 7, 600: 3, 601: 1, 602: 2, 603: 4, 604: 2, 605: 2, 606: 2, 607: 1, 608: 3, 609: 1, 610: 5, 611: 4, 612: 4, 613: 3, 614: 1, 615: 3, 617: 1, 618: 3, 619: 1, 620: 5, 621: 2, 622: 1, 623: 2, 624: 2, 625: 2, 626: 3, 627: 3, 628: 2, 629: 1, 630: 3, 631: 4, 632: 2, 633: 2, 634: 4, 635: 4, 636: 4, 638: 2, 639: 5, 640: 1, 641: 4, 642: 3, 643: 1, 644: 1, 646: 5, 647: 3, 648: 3, 650: 1, 652: 3, 653: 5, 654: 1, 655: 2, 657: 2, 658: 3, 659: 4, 660: 3, 662: 2, 664: 4, 665: 1, 666: 3, 668: 1, 671: 1, 672: 1, 673: 1, 674: 3, 675: 1, 676: 1, 677: 1, 678: 2, 679: 2, 681: 2, 682: 1, 683: 1, 684: 1, 685: 2, 687: 3, 688: 2, 689: 1, 690: 1, 691: 4, 692: 1, 693: 2, 694: 1, 697: 2, 700: 2, 702: 2, 703: 2, 704: 1, 707: 1, 709: 2, 710: 4, 711: 1, 714: 2, 715: 1, 716: 1, 717: 2, 719: 3, 721: 2, 725: 1, 727: 4, 728: 1, 732: 1, 733: 1, 734: 1, 735: 1, 736: 1, 738: 1, 739: 1, 741: 1, 743: 1, 744: 1, 746: 1, 747: 1, 749: 2, 750: 1, 751: 3, 753: 2, 756: 4, 761: 1, 762: 1, 765: 1, 767: 1, 770: 1, 771: 1, 773: 3, 774: 1, 775: 1, 776: 1, 778: 1, 780: 1, 783: 1, 785: 3, 793: 1, 794: 1, 796: 1, 800: 1, 801: 1, 803: 1, 806: 2, 807: 2, 810: 2, 811: 1, 815: 2, 817: 1, 819: 1, 821: 1, 822: 3, 826: 1, 827: 1, 828: 1, 831: 1, 834: 1, 844: 1, 846: 1, 847: 1, 849: 1, 852: 1, 855: 1, 858: 1, 869: 1, 878: 1, 881: 2, 882: 1, 885: 2, 888: 1, 895: 1, 896: 1, 898: 1, 904: 1, 906: 1, 912: 1, 913: 1, 915: 1, 918: 1, 929: 1, 935: 1, 950: 1, 954: 1, 960: 1, 973: 1, 974: 1, 975: 1, 986: 1, 997: 2, 1004: 1, 1008: 1, 1017: 1, 1019: 1})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1011032"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len_stats.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([v for k,v in len_stats.items() if k > 1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10713"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([v for k,v in len_stats.items() if k <= 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data still seems quite bad, there are many samples with lenght that is suspiciously low (85 len 1, 500 len 2, etc) so I should go back to the data generation and will filter out everything that is below a threshold.\n",
    "\n",
    "Also I'll need to manually check the files that contain data that seems bad. But maybe the number of languages (and/or samples) will still be cut down in order to improve data quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will need to filter data by a minimum and maximum length, for this I need to calculate and decide on the (minimum maybe) and maximum size of the input data for the network.\n",
    "\n",
    "Nevertheless, for the moment I'll have then to work on the network to define the input and output shapes.\n",
    "\n",
    "Input will be maximum 1024 char in length, this is to avoid overcomplications and big networks on my setup, but can be changed later.\n",
    "\n",
    "I might leave the sentences with small length (1,2,...) just to have some \"noisy\" input ... ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.7 s, sys: 2.74 s, total: 37.5 s\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "padded_data = []\n",
    "for batch in batches_data:\n",
    "    for s in batch:\n",
    "        padded_data.append(np.pad(s, [(0,0),(0,1024 - s.shape[1])], mode='constant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data_np = np.stack(padded_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data_np.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce precision (everything is below the maximum utf-8 encoding for 2 segments index < 2^11)\n",
    "np_data = all_train_data_np.astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint16')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1011032, 3, 1024)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = \"/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4\"\n",
    "# train_fname = os.path.join(base_dir, \"traindev_np_batches_779000x3x1024_int32.npy\")\n",
    "# np.save(train_fname, all_train_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file is 4.8GB on disk ... can't fit in my GPU and also have the models there, nice I do have \n",
    "train_fname = os.path.join(base_dir, \"traindev_np_batches_779000x3x1024_uint16.npy\")\n",
    "np.save(train_fname, np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1011032, 3, 1024)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 71, 101, 114, ...,   0,   0,   0],\n",
       "       [  2,   2,   2, ...,   0,   0,   0],\n",
       "       [ 21,  21,  21, ...,   0,   0,   0]], dtype=uint16)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data[-1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 115)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np_data[0,:,:]), np.count_nonzero(np_data[-1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
