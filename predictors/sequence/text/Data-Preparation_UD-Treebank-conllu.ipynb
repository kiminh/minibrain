{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Multi-Language Supervised Part of Speech training.\n",
    "\n",
    "This notebook prepares the data pre-processed from the conllu ud-treebank v2.4.\n",
    "\n",
    "First load all datasets in memory (just because I can)\n",
    "\n",
    "Count the number of samples for each and do some statistics. \n",
    "\n",
    "Here I need to take into account the different sampling strategies. \n",
    "\n",
    "There is the need for each batch to contain samples from all the languages, if not the training will not be optimal. The sampling strategies impact the performance in over-sampled and sub-sampled languages.\n",
    "\n",
    "Mainly (TODO look back to the source and note it here) the different sampling strategies and their conditions are:\n",
    "\n",
    "- Sampling the same amount from each language: Benefits the languages with less training samples and they take advantage from the learning of the languages with most samples. Penalises the languages with more samples.\n",
    "- Rate based: benefits transfer from languages with more samples to less ones and does not penalises too much the languages with more data. \n",
    "- Proportional: penalises the most the languages with less data.\n",
    "\n",
    "\n",
    "Data on the datasets with the least should not be repeated (at least too much) to avoid overfitting during this stage. The issue with overfitting now (I will be working on that later, testing what I can accomplish with overfitting)\n",
    "\n",
    "A supposition that I have is that more complex languages (syntactically and semantically) might be better for training and transferring knowledge to less complex and/or languages with less training data. I won't be trying to test this hypothesis (for the moment at least)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langmodels.utils.preprocess_conllu import *\n",
    "from utf8_encoder import *\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfiles = get_all_files_recurse(base_dir)\n",
    "charseq_files = [f for f in allfiles if f.endswith(\".pkl\") and \"charsec_code\" in f]  # typo in the file saving (fixed now in the .py file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(charseq_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "charseq_train = [ f for f in charseq_files if \"-train-\" in f]\n",
    "charseq_test = [ f for f in charseq_files if \"-test-\" in f]\n",
    "charseq_dev = [ f for f in charseq_files if \"-dev-\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271, 81, 117, 73)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(charseq_files), len(charseq_train), len(charseq_test), len(charseq_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load all data and start counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_list):\n",
    "    data = []\n",
    "    for fname in file_list:\n",
    "#         name = path_leaf(fname)\n",
    "        name = fname\n",
    "        with open(fname, \"rb\") as f:\n",
    "            d = pickle.load(f)\n",
    "            data.append((name, d))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.09 s, sys: 309 ms, total: 1.4 s\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_train = load_data(charseq_train)\n",
    "data_test = load_data(charseq_test)\n",
    "data_dev = load_data(charseq_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 117, 73)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train), len(data_test), len(data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count_train = [(n,len(d)) for n,d in data_train]\n",
    "data_count_test = [(n,len(d)) for n,d in data_test]\n",
    "data_count_dev = [(n,len(d)) for n,d in data_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data_count_train)\n",
    "df_train.columns = [\"name\", \"count\"]\n",
    "df_train = df_train.sort_values(\"count\")\n",
    "\n",
    "df_test = pd.DataFrame(data_count_test)\n",
    "df_test.columns = [\"name\", \"count\"]\n",
    "df_test = df_test.sort_values(\"count\")\n",
    "\n",
    "df_dev = pd.DataFrame(data_count_dev)\n",
    "df_dev.columns = [\"name\", \"count\"]\n",
    "df_dev = df_dev.sort_values(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>3328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>3387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>3412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>8907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>9664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>9664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>10144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>11476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>12217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>12269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>12543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>13121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>13123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>13336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>13774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>13909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>14174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>14187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>14305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>14450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>14759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>14981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>15014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>15696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>15789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>15917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>16809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>17766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>24384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>48814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>68495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>68800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>70123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  count\n",
       "51  /home/leo/projects/Datasets/text/UniversalDepe...     19\n",
       "37  /home/leo/projects/Datasets/text/UniversalDepe...     23\n",
       "33  /home/leo/projects/Datasets/text/UniversalDepe...     87\n",
       "15  /home/leo/projects/Datasets/text/UniversalDepe...    153\n",
       "20  /home/leo/projects/Datasets/text/UniversalDepe...    319\n",
       "..                                                ...    ...\n",
       "39  /home/leo/projects/Datasets/text/UniversalDepe...  24384\n",
       "77  /home/leo/projects/Datasets/text/UniversalDepe...  48814\n",
       "63  /home/leo/projects/Datasets/text/UniversalDepe...  68495\n",
       "60  /home/leo/projects/Datasets/text/UniversalDepe...  68800\n",
       "61  /home/leo/projects/Datasets/text/UniversalDepe...  70123\n",
       "\n",
       "[81 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>3214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>6491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>10148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>17028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  count\n",
       "46   /home/leo/projects/Datasets/text/UniversalDepe...     34\n",
       "22   /home/leo/projects/Datasets/text/UniversalDepe...     55\n",
       "34   /home/leo/projects/Datasets/text/UniversalDepe...     57\n",
       "92   /home/leo/projects/Datasets/text/UniversalDepe...     98\n",
       "64   /home/leo/projects/Datasets/text/UniversalDepe...    100\n",
       "..                                                 ...    ...\n",
       "50   /home/leo/projects/Datasets/text/UniversalDepe...   2802\n",
       "53   /home/leo/projects/Datasets/text/UniversalDepe...   3214\n",
       "113  /home/leo/projects/Datasets/text/UniversalDepe...   6491\n",
       "90   /home/leo/projects/Datasets/text/UniversalDepe...  10148\n",
       "87   /home/leo/projects/Datasets/text/UniversalDepe...  17028\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>6584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>9270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>17294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  count\n",
       "13  /home/leo/projects/Datasets/text/UniversalDepe...     55\n",
       "18  /home/leo/projects/Datasets/text/UniversalDepe...     65\n",
       "31  /home/leo/projects/Datasets/text/UniversalDepe...     82\n",
       "53  /home/leo/projects/Datasets/text/UniversalDepe...    107\n",
       "11  /home/leo/projects/Datasets/text/UniversalDepe...    156\n",
       "..                                                ...    ...\n",
       "30  /home/leo/projects/Datasets/text/UniversalDepe...   2409\n",
       "36  /home/leo/projects/Datasets/text/UniversalDepe...   3125\n",
       "69  /home/leo/projects/Datasets/text/UniversalDepe...   6584\n",
       "56  /home/leo/projects/Datasets/text/UniversalDepe...   9270\n",
       "54  /home/leo/projects/Datasets/text/UniversalDepe...  17294\n",
       "\n",
       "[73 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9653.876543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13826.426142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1781.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70123.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "count     81.000000\n",
       "mean    9653.876543\n",
       "std    13826.426142\n",
       "min       19.000000\n",
       "25%     1781.000000\n",
       "50%     5396.000000\n",
       "75%    13123.000000\n",
       "max    70123.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>117.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1225.042735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1874.395771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>518.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>957.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17028.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "count    117.000000\n",
       "mean    1225.042735\n",
       "std     1874.395771\n",
       "min       34.000000\n",
       "25%      518.000000\n",
       "50%      957.000000\n",
       "75%     1204.000000\n",
       "max    17028.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1413.945205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2298.393490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>564.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>912.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17294.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "count     73.000000\n",
       "mean    1413.945205\n",
       "std     2298.393490\n",
       "min       55.000000\n",
       "25%      564.000000\n",
       "50%      912.000000\n",
       "75%     1476.000000\n",
       "max    17294.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3690.684210526316"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "70123/19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportional sampling might be difficult as the difference between number of samples is too much. \n",
    "19 samples for the dataset with least data and 70123 for the most complete dataset. \n",
    "\n",
    "This means that I must do some sampling strategy that is proportional somehow but a rate of 3690 times is too much for it.\n",
    "\n",
    "Also the training order might be important, so better use the ones with least data at the end of the training, so they benefit from the previous training instead of initializing. \n",
    "\n",
    "Maybe repeating there a few times will not necessarilly overfit?\n",
    "\n",
    "So I will do that, I will order the trainig in a way that the last batches contain the samples from the languages with the least training data and the first batches will not contain them.\n",
    "\n",
    "Also all batches will be of a length that can contain at least a sample from each training (language) dataset.\n",
    "\n",
    "Also, for the languages with the lest number of samples might be good to merge the training with the dev datasets.\n",
    "\n",
    "There are also many datasets that don't contain train, test and or dev dataset. Some have only one of those, these are good for testing the generalization of the network on languages that are not trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  count\n",
       "51  /home/leo/projects/Datasets/text/UniversalDepe...     19\n",
       "37  /home/leo/projects/Datasets/text/UniversalDepe...     23\n",
       "33  /home/leo/projects/Datasets/text/UniversalDepe...     87\n",
       "15  /home/leo/projects/Datasets/text/UniversalDepe...    153\n",
       "20  /home/leo/projects/Datasets/text/UniversalDepe...    319\n",
       "4   /home/leo/projects/Datasets/text/UniversalDepe...    566\n",
       "2   /home/leo/projects/Datasets/text/UniversalDepe...    600\n",
       "41  /home/leo/projects/Datasets/text/UniversalDepe...    672\n",
       "59  /home/leo/projects/Datasets/text/UniversalDepe...    803\n",
       "74  /home/leo/projects/Datasets/text/UniversalDepe...    910\n",
       "75  /home/leo/projects/Datasets/text/UniversalDepe...   1056\n",
       "68  /home/leo/projects/Datasets/text/UniversalDepe...   1116\n",
       "3   /home/leo/projects/Datasets/text/UniversalDepe...   1123\n",
       "9   /home/leo/projects/Datasets/text/UniversalDepe...   1153\n",
       "14  /home/leo/projects/Datasets/text/UniversalDepe...   1188\n",
       "30  /home/leo/projects/Datasets/text/UniversalDepe...   1315\n",
       "50  /home/leo/projects/Datasets/text/UniversalDepe...   1334\n",
       "8   /home/leo/projects/Datasets/text/UniversalDepe...   1435\n",
       "71  /home/leo/projects/Datasets/text/UniversalDepe...   1662\n",
       "73  /home/leo/projects/Datasets/text/UniversalDepe...   1781"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>2409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>6584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>9270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>17294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  count\n",
       "9   /home/leo/projects/Datasets/text/UniversalDepe...   1400\n",
       "26  /home/leo/projects/Datasets/text/UniversalDepe...   1476\n",
       "4   /home/leo/projects/Datasets/text/UniversalDepe...   1622\n",
       "70  /home/leo/projects/Datasets/text/UniversalDepe...   1654\n",
       "28  /home/leo/projects/Datasets/text/UniversalDepe...   1709\n",
       "16  /home/leo/projects/Datasets/text/UniversalDepe...   1745\n",
       "0   /home/leo/projects/Datasets/text/UniversalDepe...   1798\n",
       "57  /home/leo/projects/Datasets/text/UniversalDepe...   1842\n",
       "59  /home/leo/projects/Datasets/text/UniversalDepe...   1852\n",
       "33  /home/leo/projects/Datasets/text/UniversalDepe...   1875\n",
       "8   /home/leo/projects/Datasets/text/UniversalDepe...   1890\n",
       "68  /home/leo/projects/Datasets/text/UniversalDepe...   1986\n",
       "50  /home/leo/projects/Datasets/text/UniversalDepe...   2002\n",
       "64  /home/leo/projects/Datasets/text/UniversalDepe...   2101\n",
       "51  /home/leo/projects/Datasets/text/UniversalDepe...   2221\n",
       "30  /home/leo/projects/Datasets/text/UniversalDepe...   2409\n",
       "36  /home/leo/projects/Datasets/text/UniversalDepe...   3125\n",
       "69  /home/leo/projects/Datasets/text/UniversalDepe...   6584\n",
       "56  /home/leo/projects/Datasets/text/UniversalDepe...   9270\n",
       "54  /home/leo/projects/Datasets/text/UniversalDepe...  17294"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_name(fname):\n",
    "    rt = path_leaf(fname).split(\"-ud-\")[0]\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['name_root'] = df_train.name.apply(get_root_name)\n",
    "df_test['name_root'] = df_test.name.apply(get_root_name)\n",
    "df_dev['name_root'] = df_dev.name.apply(get_root_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "      <th>name_root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>19</td>\n",
       "      <td>bxr_bdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>23</td>\n",
       "      <td>hsb_ufal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>87</td>\n",
       "      <td>swl_sslc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>153</td>\n",
       "      <td>lt_hse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/home/leo/projects/Datasets/text/UniversalDepe...</td>\n",
       "      <td>319</td>\n",
       "      <td>be_hse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  count name_root\n",
       "51  /home/leo/projects/Datasets/text/UniversalDepe...     19   bxr_bdt\n",
       "37  /home/leo/projects/Datasets/text/UniversalDepe...     23  hsb_ufal\n",
       "33  /home/leo/projects/Datasets/text/UniversalDepe...     87  swl_sslc\n",
       "15  /home/leo/projects/Datasets/text/UniversalDepe...    153    lt_hse\n",
       "20  /home/leo/projects/Datasets/text/UniversalDepe...    319    be_hse"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "smax_train = max([i[1] for i in data_count_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70123"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smax_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the issue is to create a sampling strategy. What should be done I don't know, but I'll create a strategy anyways with my supositions.\n",
    "\n",
    "So I'll do the following:\n",
    "- First I'll merge the language files per language, train and dev datasets will be merged to benefit the smaller langs\n",
    "- The batch size will be the number of languages that I'll be training the network\n",
    "- batches might not (will not) contain the same number of languages, but batches will be saved with the number of languages as reference\n",
    "- for training I'll first send the batches with the least language variability and at the end of each epoch the ones with the most variability (meaning the ones containing more languages)\n",
    "- The number of batches will be defined by .... ???\n",
    "\n",
    "Also for the languages that have more data I'll clean the datasets by filtering the language files according to the rating on the UD-treebank page. I'll start by the languages with more data by order.\n",
    "\n",
    "The datasets that I'm cleaning are the onces from German and Czeck:\n",
    "* Czech-CAC\n",
    "* Czech-CLTT\n",
    "* Czech-PUD\n",
    "\n",
    "For the German datasets I'll avoid merging the dev datasets and the following datasets are not used for the training:\n",
    "* German-GSD\n",
    "* German-PUD\n",
    "* German-LIT\n",
    "\n",
    "For Russian, German and Czech I won't merge the dev sets\n",
    "\n",
    "For the German HDT dataset there are two sets, a and b, dataset b is taken out because this dataset contains a lot of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging by language, also merging train and dev datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.97 s, sys: 27.3 ms, total: 5 s\n",
      "Wall time: 4.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_sentence_len = 1024\n",
    "\n",
    "# the pre-processing of the test data is much simpler, making it per file, not needing to merge and only filtering strings that are longer than the max_sentence data\n",
    "test_lang_dict = {}\n",
    "\n",
    "# filter data that is too big and padding data\n",
    "def filter_pad_data(data, max_len):\n",
    "    dta = [d for d in data if d.shape[1] <=max_sentence_len]\n",
    "    pad_dta = [np.pad(d, [(0,0),(0,1024 - d.shape[1])], mode='constant') for d in dta]\n",
    "    pad_ta = np.stack(pad_dta, axis=0).astype(\"uint16\")\n",
    "    return pad_dta\n",
    "\n",
    "for fname,data in data_test:\n",
    "    test_lang_dict[fname] = filter_pad_data(data, max_sentence_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_lang_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 272 ms, sys: 709 ms, total: 981 ms\n",
      "Wall time: 980 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save all data for testing in vectorized format already\n",
    "\n",
    "for oname, data in test_lang_dict.items():\n",
    "    fname = oname.replace(\".pkl\", \"_test-pad-3x1024_uint16.npy\")\n",
    "    np.save(fname, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang  ru  fname:  ru_taiga-ud-train-charsec_code.pkl\n",
      "lang  ru  fname:  ru_gsd-ud-train-charsec_code.pkl\n",
      "lang  de  fname:  de_hdt-ud-train-a-charsec_code.pkl\n",
      "lang  de  fname:  de_hdt-ud-train-b-charsec_code.pkl\n",
      "skipping:  de_hdt-ud-train-b-charsec_code.pkl\n",
      "lang  cs  fname:  cs_pdt-ud-train-charsec_code.pkl\n",
      "lang  ru  fname:  ru_syntagrus-ud-train-charsec_code.pkl\n",
      "lang  ru  fname:  ru_taiga-ud-dev-charsec_code.pkl\n",
      "skipping:  ru_taiga-ud-dev-charsec_code.pkl\n",
      "lang  cs  fname:  cs_fictree-ud-dev-charsec_code.pkl\n",
      "skipping:  cs_fictree-ud-dev-charsec_code.pkl\n",
      "lang  ru  fname:  ru_gsd-ud-dev-charsec_code.pkl\n",
      "skipping:  ru_gsd-ud-dev-charsec_code.pkl\n",
      "lang  de  fname:  de_hdt-ud-dev-charsec_code.pkl\n",
      "skipping:  de_hdt-ud-dev-charsec_code.pkl\n",
      "lang  cs  fname:  cs_pdt-ud-dev-charsec_code.pkl\n",
      "skipping:  cs_pdt-ud-dev-charsec_code.pkl\n",
      "lang  ru  fname:  ru_syntagrus-ud-dev-charsec_code.pkl\n",
      "skipping:  ru_syntagrus-ud-dev-charsec_code.pkl\n"
     ]
    }
   ],
   "source": [
    "lang_dict = {}\n",
    "\n",
    "for fname,data in data_train + data_dev:\n",
    "    lang = fname.split(\"_\")[0]  # language is as the first 2 or 3 chars of the filename\n",
    "    # avoid merging dev sets for the languages with more data\n",
    "    if lang in [\"de\", \"cs\", \"ru\"]:\n",
    "        print(\"lang \", lang, \" fname: \", fname)\n",
    "        if \"-dev-\" in fname or \"de_hdt-ud-train-b\" in fname:\n",
    "            print(\"skipping: \", fname)\n",
    "            continue\n",
    "    if not lang in lang_dict:\n",
    "        lang_dict[lang] = data\n",
    "    else:\n",
    "        lang_dict[lang] += data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lang_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count_traindev = [(k,len(d)) for k,d in lang_dict.items()]\n",
    "df_traindev = pd.DataFrame(data_count_traindev)\n",
    "df_traindev.columns = [\"name\", \"count\"]\n",
    "df_traindev = df_traindev.sort_values(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bxr</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>hsb</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>swl</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>be</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ga</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>hy</td>\n",
       "      <td>1246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>hu</td>\n",
       "      <td>1351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>af</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mt</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wo</td>\n",
       "      <td>1637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lt</td>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>el</td>\n",
       "      <td>2065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sme</td>\n",
       "      <td>2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gl</td>\n",
       "      <td>3732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sr</td>\n",
       "      <td>3864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>got</td>\n",
       "      <td>4372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tr</td>\n",
       "      <td>4652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>da</td>\n",
       "      <td>4947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>cu</td>\n",
       "      <td>5197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>fa</td>\n",
       "      <td>5397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>he</td>\n",
       "      <td>5725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>uk</td>\n",
       "      <td>6168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eu</td>\n",
       "      <td>7194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ja</td>\n",
       "      <td>7636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hr</td>\n",
       "      <td>7875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sv</td>\n",
       "      <td>8457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sl</td>\n",
       "      <td>9290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sk</td>\n",
       "      <td>9543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bg</td>\n",
       "      <td>10022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lv</td>\n",
       "      <td>11286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ca</td>\n",
       "      <td>14832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>orv</td>\n",
       "      <td>15188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>fro</td>\n",
       "      <td>15751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>nl</td>\n",
       "      <td>19452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>pt</td>\n",
       "      <td>19762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ro</td>\n",
       "      <td>19991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ar</td>\n",
       "      <td>24759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>et</td>\n",
       "      <td>28625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>grc</td>\n",
       "      <td>28646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>en</td>\n",
       "      <td>29097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fi</td>\n",
       "      <td>30437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>it</td>\n",
       "      <td>30681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>es</td>\n",
       "      <td>31546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pl</td>\n",
       "      <td>35506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>la</td>\n",
       "      <td>37395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fr</td>\n",
       "      <td>37533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>38462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ru</td>\n",
       "      <td>54099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>cs</td>\n",
       "      <td>68495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>de</td>\n",
       "      <td>68800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  count\n",
       "39  bxr     19\n",
       "31  hsb     23\n",
       "28  swl    169\n",
       "17   be    384\n",
       "4    ga    566\n",
       "34   hy   1246\n",
       "49   hu   1351\n",
       "26   af   1509\n",
       "3    mt   1556\n",
       "12   wo   1637\n",
       "13   lt   1882\n",
       "48   el   2065\n",
       "41  sme   2257\n",
       "2    gl   3732\n",
       "24   sr   3864\n",
       "45  got   4372\n",
       "20   tr   4652\n",
       "1    da   4947\n",
       "38   cu   5197\n",
       "40   fa   5397\n",
       "37   he   5725\n",
       "19   uk   6168\n",
       "0    eu   7194\n",
       "21   ja   7636\n",
       "15   hr   7875\n",
       "23   sv   8457\n",
       "27   sl   9290\n",
       "18   sk   9543\n",
       "6    bg  10022\n",
       "5    lv  11286\n",
       "25   ca  14832\n",
       "46  orv  15188\n",
       "44  fro  15751\n",
       "36   nl  19452\n",
       "33   pt  19762\n",
       "14   ro  19991\n",
       "47   ar  24759\n",
       "32   et  28625\n",
       "35  grc  28646\n",
       "30   en  29097\n",
       "29   fi  30437\n",
       "11   it  30681\n",
       "10   es  31546\n",
       "16   pl  35506\n",
       "22   la  37395\n",
       "8    fr  37533\n",
       "9    no  38462\n",
       "7    ru  54099\n",
       "43   cs  68495\n",
       "42   de  68800"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_traindev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779078"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_traindev[\"count\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The threshold for the number of batches will be chosen as to maximize the number of complete batches, this will also give the number of languages in each batch set.\n",
    "~~Just because (arbitrary number) I decide that the batches with the least languages will be 10, this might give enough language variability for the training. ~~\n",
    "\n",
    "As there are 50 languages, the batches will contain 50 samples (from REVISITING SMALL BATCH TRAINING FOR DEEP NEURAL NETWORKS https://arxiv.org/pdf/1804.07612.pdf small batches are better)~~, so the batches with the least n# of languages will contain 5 samples per lang, and the ones with 50 languages one sample per batch.~~\n",
    "\n",
    "To complete the batch for the ones that are not with all the languages I intend to randomly choose from the ~~10~~ N languages with the most samples, this is done by randomly shuffling the remaining data from the threshold sampling chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_len = 1024\n",
    "\n",
    "# creating a list to fill the missing data in the batches, data will be then randomly shuffled\n",
    "# I explore here the minimum number of languages that will give me the maximum number of batches.\n",
    "# I'm looking only in the number of samples of the languages, not other point.\n",
    "\n",
    "fi_len = 30437  # with this threshold I only keep up to 17 languages and 17524 batches\n",
    "ar_len = 24759  # with this threshold I only keep up to 14 languages and 20953 batches\n",
    "ro_len = 19991  # with this threshold I only keep up to 15 languages and 19991 batches \n",
    "# is the SWEET SPOT for the max number of batches\n",
    "ca_len = 14832 # with this threshold I only keep up to 20 languages and 14832 batches  and there are 749 extra batches with up to 19 languages\n",
    "threshold_len = ca_len\n",
    "\n",
    "fill_data =[]\n",
    "# create batches, later\n",
    "for lang, data in lang_dict.items():\n",
    "    if len(data)> threshold_len:\n",
    "        dta = [d for d in data[threshold_len:] if d.shape[1] <= max_sentence_len]\n",
    "        fill_data.extend(dta)\n",
    "        \n",
    "# ensure that the data chosen to fill the missing elements is random \n",
    "# (and will statistically be proportional to the number of datapoints of each language)\n",
    "random.shuffle(fill_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352403"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fill_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "batches = []\n",
    "\n",
    "# create batches, later\n",
    "for i in range(threshold_len):  \n",
    "    bid=0\n",
    "    langs=[]\n",
    "    datas=[]\n",
    "    for lang, data in lang_dict.items():\n",
    "        if len(data)> i and data[i].shape[1] <= max_sentence_len:\n",
    "            langs.append(lang)\n",
    "            datas.append(data[i])\n",
    "    while len(datas) < len(lang_dict.keys()):\n",
    "        datas.append(fill_data.pop())\n",
    "    batch = (bid, langs, datas)\n",
    "    batches.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37441"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fill_data)  # there is data still left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_samples_10 = len(fill_data) //50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_samples_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_10_langs = list(chunks(fill_data, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all batches are 50 samples long\n",
    "batch_lens = list(map(lambda x: len(x[2]), batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14832, 50, 50, 749)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_lens), max(batch_lens), min(batch_lens), len(batches_10_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741600"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14832 * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779050"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are then a maximum\n",
    "(14832 + 749) * 50\n",
    "# datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that the data is OK $ 779078  > 779050$ \n",
    "So the number of original samples is bigger than the number of samples on the prepared dataset. This is OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many languages and how many batches with each amount of languages\n",
    "b_stats = {}\n",
    "for bid, blangs, bdatas in batches:\n",
    "    l = len(blangs)\n",
    "    if l in b_stats:\n",
    "        b_stats[l] +=1\n",
    "    else:\n",
    "        b_stats[l] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50: 18,\n",
       " 49: 5,\n",
       " 48: 144,\n",
       " 47: 217,\n",
       " 46: 182,\n",
       " 45: 678,\n",
       " 44: 107,\n",
       " 43: 158,\n",
       " 42: 47,\n",
       " 41: 81,\n",
       " 40: 244,\n",
       " 39: 184,\n",
       " 38: 192,\n",
       " 37: 1465,\n",
       " 36: 142,\n",
       " 35: 507,\n",
       " 34: 281,\n",
       " 33: 295,\n",
       " 32: 249,\n",
       " 31: 201,\n",
       " 30: 328,\n",
       " 29: 443,\n",
       " 28: 1025,\n",
       " 27: 443,\n",
       " 26: 239,\n",
       " 25: 582,\n",
       " 24: 832,\n",
       " 23: 254,\n",
       " 22: 477,\n",
       " 21: 1265,\n",
       " 20: 3547}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to make something for the data shape such as all batches are the same shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I need now to create the list of batches, reverse the order as the training order will be from the least diverse to the most diverse batches up to 50 languages in the last 19 batches (the number of samples the language with least training data has).\n",
    "\n",
    "I take out the last array from the batches_10_langs at it is not complete with 50 samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_data = list(map(lambda x: x[2], batches)) + batches_10_langs[:-1]\n",
    "batches_data.reverse()  # have to train first with the least diverse, and at the end with the most diverse ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches_data) * 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find the maximum lenght of all the data samples, this will be the dimension needed for the numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = []\n",
    "for b in batches_data:\n",
    "    for s in b:\n",
    "        seq_len.append(s.shape[1])\n",
    "\n",
    "min_seq_len, max_seq_len = min(seq_len), max(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1017)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_seq_len, max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many languages and how many batches with each amount of languages\n",
    "len_stats = {}\n",
    "for l in seq_len:\n",
    "    if l in len_stats:\n",
    "        len_stats[l] +=1\n",
    "    else:\n",
    "        len_stats[l] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_stats = SortedDict(sorted(len_stats.items(), key=lambda kv: kv[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SortedDict({1: 85, 2: 500, 3: 608, 4: 1372, 5: 1980, 6: 2047, 7: 2623, 8: 2452, 9: 2700, 10: 2864, 11: 3295, 12: 3374, 13: 4058, 14: 3783, 15: 4669, 16: 4208, 17: 4946, 18: 4523, 19: 5896, 20: 4667, 21: 5325, 22: 4988, 23: 5638, 24: 5325, 25: 5913, 26: 5500, 27: 6093, 28: 5716, 29: 6235, 30: 5605, 31: 6440, 32: 5688, 33: 6369, 34: 5779, 35: 6453, 36: 5937, 37: 6481, 38: 5594, 39: 6213, 40: 5816, 41: 6416, 42: 5673, 43: 6420, 44: 5583, 45: 6149, 46: 5515, 47: 6120, 48: 5444, 49: 5946, 50: 5509, 51: 5850, 52: 5252, 53: 6008, 54: 5469, 55: 5829, 56: 5297, 57: 5752, 58: 5313, 59: 5581, 60: 5279, 61: 5651, 62: 5142, 63: 5393, 64: 5049, 65: 5419, 66: 5016, 67: 5361, 68: 5049, 69: 5264, 70: 4927, 71: 5304, 72: 4869, 73: 5132, 74: 4873, 75: 5118, 76: 4771, 77: 5101, 78: 4787, 79: 4975, 80: 4706, 81: 5003, 82: 4520, 83: 4894, 84: 4550, 85: 4854, 86: 4509, 87: 4747, 88: 4440, 89: 4612, 90: 4360, 91: 4389, 92: 4291, 93: 4397, 94: 4189, 95: 4259, 96: 4130, 97: 4253, 98: 3896, 99: 4220, 100: 3862, 101: 3972, 102: 3976, 103: 4057, 104: 4078, 105: 4020, 106: 3867, 107: 3900, 108: 3551, 109: 3673, 110: 3621, 111: 3670, 112: 3552, 113: 3612, 114: 3582, 115: 3546, 116: 3331, 117: 3462, 118: 3277, 119: 3292, 120: 3345, 121: 3250, 122: 3302, 123: 3329, 124: 3147, 125: 3155, 126: 3065, 127: 3018, 128: 2993, 129: 3074, 130: 2965, 131: 2998, 132: 2874, 133: 2904, 134: 2861, 135: 2931, 136: 2897, 137: 2804, 138: 2782, 139: 2803, 140: 2671, 141: 2561, 142: 2452, 143: 2363, 144: 2339, 145: 2400, 146: 2399, 147: 2357, 148: 2303, 149: 2291, 150: 2209, 151: 2259, 152: 2180, 153: 2167, 154: 2089, 155: 1994, 156: 2010, 157: 1942, 158: 2019, 159: 1968, 160: 1916, 161: 1898, 162: 1899, 163: 1832, 164: 1742, 165: 1817, 166: 1743, 167: 1726, 168: 1676, 169: 1683, 170: 1643, 171: 1673, 172: 1632, 173: 1608, 174: 1549, 175: 1461, 176: 1531, 177: 1503, 178: 1450, 179: 1607, 180: 1439, 181: 1449, 182: 1415, 183: 1379, 184: 1383, 185: 1294, 186: 1313, 187: 1284, 188: 1331, 189: 1160, 190: 1189, 191: 1249, 192: 1173, 193: 1193, 194: 1119, 195: 1151, 196: 1114, 197: 1124, 198: 1108, 199: 1040, 200: 1010, 201: 1007, 202: 972, 203: 1014, 204: 972, 205: 973, 206: 887, 207: 925, 208: 899, 209: 930, 210: 895, 211: 834, 212: 856, 213: 837, 214: 781, 215: 764, 216: 775, 217: 815, 218: 807, 219: 755, 220: 766, 221: 770, 222: 742, 223: 741, 224: 688, 225: 682, 226: 705, 227: 680, 228: 607, 229: 645, 230: 638, 231: 620, 232: 624, 233: 622, 234: 611, 235: 565, 236: 562, 237: 587, 238: 571, 239: 548, 240: 530, 241: 555, 242: 541, 243: 507, 244: 513, 245: 500, 246: 481, 247: 511, 248: 448, 249: 473, 250: 464, 251: 443, 252: 410, 253: 428, 254: 420, 255: 416, 256: 413, 257: 396, 258: 391, 259: 414, 260: 373, 261: 352, 262: 372, 263: 364, 264: 345, 265: 368, 266: 360, 267: 338, 268: 359, 269: 345, 270: 336, 271: 318, 272: 309, 273: 323, 274: 288, 275: 256, 276: 301, 277: 286, 278: 277, 279: 261, 280: 277, 281: 246, 282: 249, 283: 272, 284: 254, 285: 271, 286: 243, 287: 230, 288: 236, 289: 258, 290: 252, 291: 210, 292: 220, 293: 223, 294: 211, 295: 231, 296: 204, 297: 183, 298: 171, 299: 192, 300: 194, 301: 176, 302: 174, 303: 176, 304: 188, 305: 187, 306: 182, 307: 178, 308: 172, 309: 156, 310: 156, 311: 180, 312: 141, 313: 143, 314: 140, 315: 157, 316: 161, 317: 130, 318: 134, 319: 154, 320: 126, 321: 139, 322: 108, 323: 129, 324: 122, 325: 116, 326: 132, 327: 96, 328: 116, 329: 120, 330: 109, 331: 99, 332: 99, 333: 103, 334: 120, 335: 99, 336: 107, 337: 115, 338: 94, 339: 68, 340: 75, 341: 100, 342: 85, 343: 87, 344: 82, 345: 90, 346: 94, 347: 94, 348: 74, 349: 82, 350: 84, 351: 64, 352: 79, 353: 81, 354: 73, 355: 76, 356: 71, 357: 57, 358: 62, 359: 64, 360: 61, 361: 63, 362: 62, 363: 67, 364: 62, 365: 69, 366: 54, 367: 59, 368: 62, 369: 46, 370: 57, 371: 56, 372: 47, 373: 47, 374: 49, 375: 45, 376: 54, 377: 63, 378: 50, 379: 46, 380: 55, 381: 49, 382: 44, 383: 45, 384: 42, 385: 52, 386: 36, 387: 40, 388: 40, 389: 46, 390: 52, 391: 44, 392: 35, 393: 47, 394: 42, 395: 39, 396: 32, 397: 38, 398: 31, 399: 32, 400: 28, 401: 42, 402: 35, 403: 27, 404: 32, 405: 30, 406: 32, 407: 19, 408: 33, 409: 22, 410: 35, 411: 30, 412: 39, 413: 39, 414: 28, 415: 21, 416: 26, 417: 29, 418: 24, 419: 23, 420: 27, 421: 28, 422: 21, 423: 20, 424: 21, 425: 10, 426: 26, 427: 17, 428: 20, 429: 18, 430: 18, 431: 24, 432: 21, 433: 20, 434: 17, 435: 19, 436: 17, 437: 25, 438: 19, 439: 23, 440: 18, 441: 21, 442: 24, 443: 19, 444: 20, 445: 9, 446: 15, 447: 24, 448: 8, 449: 12, 450: 10, 451: 20, 452: 12, 453: 15, 454: 8, 455: 13, 456: 7, 457: 8, 458: 11, 459: 15, 460: 10, 461: 17, 462: 16, 463: 10, 464: 8, 465: 9, 466: 15, 467: 9, 468: 13, 469: 16, 470: 13, 471: 17, 472: 10, 473: 4, 474: 10, 475: 14, 476: 13, 477: 12, 478: 12, 479: 10, 480: 9, 481: 13, 482: 11, 483: 9, 484: 11, 485: 11, 486: 13, 487: 19, 488: 2, 489: 8, 490: 8, 491: 10, 492: 9, 493: 6, 494: 6, 495: 7, 496: 7, 497: 9, 498: 11, 499: 9, 500: 6, 501: 7, 502: 14, 503: 8, 504: 7, 505: 7, 506: 5, 507: 11, 508: 6, 509: 4, 510: 10, 511: 6, 512: 9, 513: 7, 514: 9, 515: 5, 516: 6, 517: 6, 518: 4, 519: 3, 520: 5, 521: 4, 522: 7, 523: 4, 524: 8, 525: 6, 526: 3, 527: 3, 528: 6, 529: 3, 530: 6, 531: 8, 532: 2, 533: 9, 534: 4, 535: 6, 536: 10, 537: 7, 538: 6, 539: 2, 540: 4, 541: 6, 542: 3, 543: 5, 544: 4, 545: 6, 546: 3, 547: 2, 548: 7, 549: 2, 550: 3, 551: 4, 552: 2, 553: 3, 554: 5, 555: 4, 556: 4, 557: 5, 558: 1, 559: 3, 560: 2, 561: 3, 562: 5, 563: 3, 564: 4, 565: 4, 566: 5, 567: 7, 568: 2, 569: 2, 570: 2, 571: 1, 572: 3, 573: 6, 574: 4, 575: 4, 576: 4, 577: 4, 578: 4, 579: 2, 580: 2, 581: 1, 582: 3, 583: 2, 584: 4, 586: 4, 587: 2, 588: 3, 589: 2, 590: 3, 591: 1, 592: 6, 593: 2, 594: 3, 595: 1, 597: 4, 598: 1, 599: 6, 600: 3, 601: 1, 602: 1, 603: 4, 604: 1, 605: 2, 606: 2, 607: 1, 608: 2, 610: 2, 611: 3, 612: 3, 613: 3, 614: 1, 615: 3, 618: 2, 619: 1, 620: 5, 621: 2, 622: 1, 623: 2, 624: 1, 625: 1, 626: 2, 627: 2, 628: 2, 629: 1, 630: 2, 631: 4, 632: 1, 633: 2, 634: 4, 635: 4, 636: 3, 638: 2, 639: 4, 640: 1, 641: 4, 642: 2, 643: 1, 644: 1, 646: 5, 647: 1, 648: 2, 650: 1, 652: 2, 653: 5, 654: 1, 655: 1, 657: 2, 658: 2, 659: 2, 660: 2, 662: 1, 664: 4, 665: 1, 666: 2, 668: 1, 671: 1, 673: 1, 674: 2, 675: 1, 676: 1, 677: 1, 679: 1, 681: 2, 682: 1, 683: 1, 685: 1, 687: 3, 688: 2, 689: 1, 691: 3, 692: 1, 693: 2, 694: 1, 697: 2, 700: 2, 702: 2, 703: 2, 704: 1, 707: 1, 709: 1, 710: 1, 711: 1, 715: 1, 717: 2, 719: 3, 721: 2, 725: 1, 727: 4, 730: 1, 732: 1, 733: 1, 734: 1, 735: 1, 736: 1, 738: 1, 739: 1, 741: 1, 743: 1, 744: 1, 746: 1, 747: 1, 749: 1, 750: 1, 751: 3, 753: 1, 756: 4, 762: 1, 765: 1, 767: 1, 770: 1, 771: 1, 773: 3, 774: 1, 775: 1, 776: 1, 778: 1, 780: 1, 783: 1, 785: 1, 793: 1, 794: 1, 801: 1, 806: 2, 807: 2, 810: 1, 811: 1, 815: 2, 817: 1, 821: 1, 822: 1, 826: 1, 827: 1, 828: 1, 844: 1, 847: 1, 869: 1, 881: 2, 882: 1, 895: 1, 896: 1, 904: 1, 912: 1, 913: 1, 915: 1, 918: 1, 935: 1, 950: 1, 954: 1, 960: 1, 986: 1, 997: 2, 1004: 1, 1008: 1, 1017: 1})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len_stats.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([v for k,v in len_stats.items() if k > 1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4545"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([v for k,v in len_stats.items() if k <= 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data still seems quite bad, there are many samples with lenght that is suspiciously low (85 len 1, 500 len 2, etc) so I should go back to the data generation and will filter out everything that is below a threshold.\n",
    "\n",
    "Also I'll need to manually check the files that contain data that seems bad. But maybe the number of languages (and/or samples) will still be cut down in order to improve data quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will need to filter data by a minimum and maximum length, for this I need to calculate and decide on the (minimum maybe) and maximum size of the input data for the network.\n",
    "\n",
    "Nevertheless, for the moment I'll have then to work on the network to define the input and output shapes.\n",
    "\n",
    "Input will be maximum 1024 char in length, this is to avoid overcomplications and big networks on my setup, but can be changed later.\n",
    "\n",
    "I might leave the sentences with small length (1,2,...) just to have some \"noisy\" input ... ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 s, sys: 2.03 s, total: 28 s\n",
      "Wall time: 28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "padded_data = []\n",
    "for batch in batches_data:\n",
    "    for s in batch:\n",
    "        padded_data.append(np.pad(s, [(0,0),(0,1024 - s.shape[1])], mode='constant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data_np = np.stack(padded_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data_np.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce precision (everything is below the maximum utf-8 encoding for 2 segments index < 2^11)\n",
    "np_data = all_train_data_np.astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint16')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779000, 3, 1024)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = \"/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4\"\n",
    "# train_fname = os.path.join(base_dir, \"traindev_np_batches_779000x3x1024_int32.npy\")\n",
    "# np.save(train_fname, all_train_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file is 4.8GB on disk ... can't fit in my GPU and also have the models there, nice I do have \n",
    "train_fname = os.path.join(base_dir, \"traindev_np_batches_779000x3x1024_uint16.npy\")\n",
    "np.save(train_fname, np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779000, 3, 1024)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 65,  32, 118, ...,   0,   0,   0],\n",
       "       [  5,  17,   7, ...,   0,   0,   0],\n",
       "       [126,   0, 194, ...,   0,   0,   0]], dtype=uint16)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data[-1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 280)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np_data[0,:,:]), np.count_nonzero(np_data[-1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
