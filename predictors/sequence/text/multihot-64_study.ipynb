{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multihot study fitting in 64 bits\n",
    "\n",
    "This study tries to cut the number of embedding dimensions and will continue from the points done in multihot_study_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to cut down from the embedding dimension of 324  to something much more manageable.\n",
    "\n",
    "So I want to go UTF8ed (utf-8 embedding dimension) no more than 64 bits, why? just because\n",
    "\n",
    "The low limit of the embedding would be 32 bits (the maximum lenght of an utf-8 code)\n",
    "\n",
    "$ 32 <= UTF8ed <= 64 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this I want to basically do the following: ${N\\choose k}$\n",
    "\n",
    "Where $ 32 <= N <= 64$\n",
    "and $ k $ should be minimized to augment the sparcity of the vector as much as possible\n",
    "\n",
    "Also I would like to add some verification or checking elements that should be also more important, for example, the first 4 elements should indicate which UTF-8 segment is being used. This implies  $ 32 <= N <= 60$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value $k$ should be around the $k^{th}$ root of the product of the first $k$ parts of $N!$\n",
    "\n",
    "So I will try some values for k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a first experiment I would like to see how many \n",
    "\n",
    "# the number of items that need to be included in the coding scheme:\n",
    "ncodes = 1112064  # number of valid codes in UTF-8 per Wikipedia page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 31, 30, 29]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(32,32-4,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1,4+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=45,k=5\n",
      "N=46,k=5\n",
      "N=47,k=5\n",
      "N=48,k=5\n",
      "N=49,k=5\n",
      "N=50,k=5\n",
      "N=51,k=5\n",
      "N=52,k=5\n",
      "N=53,k=5\n",
      "N=54,k=5\n",
      "N=55,k=5\n",
      "N=56,k=5\n",
      "N=57,k=5\n",
      "N=58,k=5\n",
      "N=59,k=5\n",
      "N=60,k=5\n",
      "N=61,k=5\n",
      "N=62,k=5\n",
      "N=63,k=5\n"
     ]
    }
   ],
   "source": [
    "#find the minimum N for which the condition is filled\n",
    "for N in range(32,64):\n",
    "    for k in [4,5]:\n",
    "        v = np.prod(list(range(N,N-k,-1))) / np.prod(list(range(1,k+1)))\n",
    "        if v > ncodes:\n",
    "            print(\"ncodes={}; N={},k={}\".format(v N,k))\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so the values are $ N >= 45 ; k >=5 $\n",
    "\n",
    "Which means that for a code of dim 64 I can use a one-hot for the first 4 elements such as it indicates the utf-8 plane segment  and tehre are still 15 elements to signal some other things (such as a positional embedding or an error correction code for example).\n",
    "\n",
    "So I decide to create a code of dimension $ N=49 $ and leave the rest of the space for dimensional embedding or other thing (64 would be great for grouped convolution features and 49 is only divisible by 7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these 49 elements, the only available values will be $0$ and $1$, the first 4 elements will be selected according to the plane segment used in UTF-8, and the rest should indicate all the selection (this adds redundancy but also makes things more clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 4),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (3, 4)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combinations(list(range(5)), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, basically I have to do something like the following:\n",
    "\n",
    "- generate all combinations of ${45\\choose 5}$\n",
    "- assing to each an index \n",
    "- convert all that to numpy and vectors of size 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_combinations(N,k):\n",
    "    ret = combinations(list(range(N)),k)  #iterator\n",
    "    return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combs = get_all_combinations(45,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(list(all_combs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1221759, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 5],\n",
       "       [0, 1, 2, 3, 6],\n",
       "       [0, 1, 2, 3, 7],\n",
       "       [0, 1, 2, 3, 8]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = np.zeros([indices.shape[0], 45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1221759, 45)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy.put works with indices as if the array is flattened so I have to work on that\n",
    "lin_indices = np.array(list(range(embeds.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_indices = lin_indices.reshape([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1221759, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0],\n",
       "       [ 1],\n",
       "       [ 2],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 5],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [11],\n",
       "       [12],\n",
       "       [13],\n",
       "       [14],\n",
       "       [15],\n",
       "       [16],\n",
       "       [17],\n",
       "       [18],\n",
       "       [19]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_indices[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_indices =  (lin_indices*45)+indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3,   4],\n",
       "       [ 45,  46,  47,  48,  50],\n",
       "       [ 90,  91,  92,  93,  96],\n",
       "       [135, 136, 137, 138, 142],\n",
       "       [180, 181, 182, 183, 188],\n",
       "       [225, 226, 227, 228, 234],\n",
       "       [270, 271, 272, 273, 280],\n",
       "       [315, 316, 317, 318, 326],\n",
       "       [360, 361, 362, 363, 372],\n",
       "       [405, 406, 407, 408, 418]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds.put(flat_indices,[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This covers a complete codebook, now the issue might be the distance between two elements of the code. In this case the distance is quite small, so I can add some extra dimensions that increments the distance between vectors...\n",
    "Maybe what I can do is actually use the next 15 dimensions (to fill up to 64 dimensions) ... so something might come up of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After thinking about several methods, specially on Fowraed Error Correction Codes like TurboCodes, LDPC and ReedSolomon. Other error detection codes (that use parity codes) are not necessarilly useful as the parity will always be the same in the codebook by construction (which is another nice thing). There is another thing here, is that many codes (like golay or hamming) have fixed size for the messages which do not match the needs in the codes here.\n",
    "\n",
    "So basically what needs to be done is augment the distance between two elements, which can be done easily. \n",
    "\n",
    "In this case I can do that with an easy trick that will augment distance between the points, maybe do several one-hot like the one used in the previous codebook I worked on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = [3,5,7,11,13,17,19,23]\n",
    "arr = [5,7,11,13,17,19,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37182145, 95)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(arr), np.sum(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue with this is that the dimensionality grows more than I fixed I wanted to work on.\n",
    "\n",
    "So I can use the same technique but with the 15 elements I have left as max dimension that I fixed (just because I wanted to)\n",
    "\n",
    "Note that all these decisions on dimensionality are completely arbitrary, adding constraints just for the sake of cutting down the number of operations and trainable parameters.\n",
    "\n",
    "The idea of having a fixed codebook is to get free of it later.\n",
    "\n",
    "So for this extra code of 15 elements will be created in a way that all pairs are co-primes (this increases the distance between vectors on the cycles), the easiest way of selecting co-primes is selecting prime numbers, also there is a nice thing in the sequence $[3,5,7]$ that they sum 15 which is exactly the same as the allowed space I gave myself to build that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyes = np.eye(3), np.eye(5), np.eye(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eyes[0].repeat(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(eyes[0],(3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep3, rep5, rep7 = int(np.ceil(embeds.shape[0]/3.)), int(np.ceil(embeds.shape[0]/5.)), int(np.ceil(embeds.shape[0]/7.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[407253, 244352, 174537]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps = [rep3,rep5,rep7]\n",
    "reps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now I build the codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = []\n",
    "for e,r in zip(eyes, reps):\n",
    "    t = np.tile(e, [r,1])[:embeds.shape[0],:]\n",
    "    tiles.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1221759, 3), (1221759, 5), (1221759, 7)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.shape for t in tiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "code15 = np.concatenate(tiles,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1221759, 15)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds45 = np.concatenate([embeds,code15],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1221759, 60)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds45.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds45bool = np.array(embeds45, dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to compute the distances between vectors, just to know about them .. but the dimensionality of the vector makes it big and out of memory errors appear, so I'll do splits to try to get it right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = np.array_split(embeds45bool, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False, False,  True, False, False, False, False,  True,\n",
       "        False, False, False, False, False, False],\n",
       "       [ True,  True,  True,  True, False,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False,  True, False, False,  True, False, False, False, False,\n",
       "         True, False, False, False, False, False]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist,pdist, hamming\n",
    "# from scipy.spatial import distance\n",
    "dd = cdist(embeds45bool,splits[0][:2], metric='hamming')\n",
    "# pp = pdist(embeds45bool[:10,:],splits[0][:2])\n",
    "hh = hamming(embeds45bool[0], splits[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1222, 60)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False, False,  True, False, False, False, False,  True,\n",
       "        False, False, False, False, False, False]),\n",
       " array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds45bool[0],embeds45[0],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1221759, 2), ())"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.shape, hh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13333333, 0.13333333, 0.13333333, ..., 0.23333333, 0.26666667,\n",
       "       0.26666667])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf[ddf>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03333333333333333"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(ddf[ddf>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next experiment should not be run lightly as it is heavy and time consuming (one run takes about 138 seconds wall time, so about 140s I estimate about 39 hours, or about 2 days of runtime in my computer, I can not parallelize more due to memory issues which I only have 64GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# isplits = splits[:5]\n",
    "# # # from scipy.spatial.distance import cdist\n",
    "# # # # cdist(XA, XB, metric='euclidean', p=2, V=None, VI=None, w=None)\n",
    "# # # maxd, mind, \n",
    "# diststats = []\n",
    "# for s in isplits: \n",
    "#     fdist = cdist(embeds45bool,s, metric='hamming').flat\n",
    "#     nzfdist = fdist[fdist>0]  # eliminate from the elements the zero distances (distance to itself)\n",
    "#     # save stat values\n",
    "#     diststats.append( (np.min(nzfdist), np.max(nzfdist), np.median(nzfdist), np.std(nzfdist) ))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diststats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5, 12. , 10.5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0.03333333333333333 , 0.26666666666666666 , 0.23333333333333334]) * 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# splits2 = np.array_split(embeds45, 1000)\n",
    "# isplits = splits2[:5]\n",
    "# # # from scipy.spatial.distance import cdist\n",
    "# # # # cdist(XA, XB, metric='euclidean', p=2, V=None, VI=None, w=None)\n",
    "# # # maxd, mind, \n",
    "# diststats2 = []\n",
    "# for s in isplits: \n",
    "#     fdist = cdist(embeds45,s, metric='hamming').flat\n",
    "#     nzfdist = fdist[fdist>0]  # eliminate from the elements the zero distances (distance to itself)\n",
    "#     # save stat values\n",
    "#     diststats2.append( (np.min(nzfdist), np.max(nzfdist), np.median(nzfdist), np.std(nzfdist) ))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diststats2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll get to do the segment coding this makes an extra 4 elements that encode each segment and the special tokens\n",
    "\n",
    "It will be a one hot encoding and all ones when  is a special token and I can use the **utf-8 private area**\n",
    "\n",
    "From the previous study the indices for the codes are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices for the segments:  0 128 2176 65664 2097280\n"
     ]
    }
   ],
   "source": [
    "print(\"indices for the segments: \", 0, 128, (128 + 2**5 * 2**6), (128 + 2**4 * (2**6)**2), (128 + 2**3 * (2**6)**3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what I need are a few elements at some point to use them as private values.\n",
    "\n",
    "In the case of utf-8 there are non used values taht I can use for this purpose, or I can add some extra values at the beginning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the segment indicator vector will be  shape (embeds.shape[0], 4)\n",
    "segind = np.zeros((embeds.shape[0], 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1221759, 4)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segind.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use the last 4 codes as special codes, these will be set for the following elements:\n",
    "* \\<error>  $last$\n",
    "* \\<start> $last-1$\n",
    "* \\<stop> $last-2$\n",
    "* \\<unknown> $last-3$\n",
    "* \\<null> $last-4$\n",
    "\n",
    "\n",
    "Other elements might be needed, but as the encoding is much bigger than the complete utf-8 space I'll be able to add them later if the need arrives.\n",
    "\n",
    "\n",
    "Special codes have the segment indicator part set to *1111*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "segind[-5:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segind[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is where the pre-computed indices are of use\n",
    "# 0 128 2176 65664 2097280\n",
    "segind[:128] = np.array([0,0,0,1])\n",
    "segind[128:2176] = np.array([0,0,1,0])\n",
    "segind[2176:65664] = np.array([0,1,0,0])\n",
    "# segind[65664:] = np.array([1,0,0,0])\n",
    "segind[65664:-113854] = np.array([1,0,0,0])  # where 113855 is the number of special codes that fit in this coding but I leave one for margin\n",
    "segind[-6:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segind[120:130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segind[2170:2180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segind[65660:65670]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segind[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can create the complete codebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds64 = np.concatenate([embeds45,segind],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1221759, 64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds64.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have all the codes, this should be enough for many things. Nevertheless even if this is an encoding that can capture everything, the decoding part as well as the learning might prove problematic. \n",
    "One-hot is quite nice for learning and decoding while this encoding will need some other techniques for decoding and measuring loss (cosine similarity for example?, using faiss might be an option)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another way of encoding this, try to maximize the distance between elements in the *SAME* utf-8 code segment, this could be more beneficial as most of the text in one text or language should (mostly) be in the same segment while (maybe) having a few words or codes from the other ones (exceptions would be the punctuation and emoticons codes), but for the moment I'll just create my codes as is and be done with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utf8_encoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of codes =  1107904\n",
      "number of code_exceptions =  790656\n"
     ]
    }
   ],
   "source": [
    "tables = create_tables(segments=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, char2idx, idx2char = tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1107904, 1107904)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we check the number of codes generated is\n",
    "len(char2idx), len(idx2char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is less than: 1221759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113855"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1221759 - 1107904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what I want to do now is to save the coding but for that I need to add the special characters, \n",
    "# <err> (error) 𝑙𝑎𝑠𝑡 = 1221758\n",
    "# <start> 𝑙𝑎𝑠𝑡−1 = 1221757\n",
    "# <stop>  𝑙𝑎𝑠𝑡−2 = 1221756\n",
    "# <unk> (unknown) 𝑙𝑎𝑠𝑡−3 = 1221755\n",
    "# <null> 𝑙𝑎𝑠𝑡−4 = 1221754\n",
    "\n",
    "# char2idx[\"<err>\"] = 1221758\n",
    "# char2idx[\"<start>\"] = 1221757\n",
    "# char2idx[\"<stop>\"] = 1221756\n",
    "# char2idx[\"<unk>\"] = 1221755\n",
    "# char2idx[\"<null>\"] = 1221754\n",
    "\n",
    "# idx2char[1221758] = \"<err>\"\n",
    "# idx2char[1221757] = \"<start>\"\n",
    "# idx2char[1221756] = \"<stop>\"\n",
    "# idx2char[1221755] = \"<unk>\"\n",
    "# idx2char[1221754] = \"<null>\"\n",
    "\n",
    "# eslen = len(embeds64)\n",
    "# idx2char[\"<err>\"] = eslen-1\n",
    "# idx2char[\"<start>\"] = eslen-2\n",
    "# idx2char[\"<stop>\"] = eslen-3\n",
    "# idx2char[\"<unk>\"] = eslen-4\n",
    "# idx2char[\"<null>\"] = eslen-5\n",
    "\n",
    "# idx2char[eslen-1] = \"<err>\"\n",
    "# idx2char[eslen-2] = \"<start>\"\n",
    "# idx2char[eslen-3] = \"<stop>\"\n",
    "# idx2char[eslen-4] = \"<unk>\"\n",
    "# idx2char[eslen-5] = \"<null>\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds64bool = np.array(embeds64, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(char2idx.items())[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(idx2char.items())[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(embeds64[[0,120,240,360,480,600,720,840,960,1080,1200,1320]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now SAVE all the codes\n",
    "# save_obj(char2idx, \"multihot64-char2idx\")\n",
    "# save_obj(idx2char, \"multihot64-idx2char\")\n",
    "# save_obj(embeds64, \"multihot64-embeds\")\n",
    "# save_obj(embeds64bool, \"multihot64-embeds-bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 280K\n",
      "drwxr-xr-x 5 leo leo 4,0K sept. 27 14:22 \u001b[0m\u001b[01;34madaptive-span\u001b[0m/\n",
      "-rw-r--r-- 1 leo leo  42K oct.   3 17:57 ecc_study_simple.ipynb\n",
      "-rw-rw-r-- 1 leo leo 7,9K sept. 21 21:16 ilustrated_transformer.py\n",
      "-rw-r--r-- 1 leo leo    0 juil. 30 11:41 __init__.py\n",
      "drwxrwxr-x 4 leo leo 4,0K oct.  31 16:37 \u001b[01;34mlangmodels\u001b[0m/\n",
      "-rw-r--r-- 1 leo leo  42K oct.  31 16:46 multihot-64_study.ipynb\n",
      "-rw-r--r-- 1 leo leo 5,1K oct.  31 16:46 multihot_faiss-test.ipynb\n",
      "-rw-r--r-- 1 leo leo  49K oct.  30 19:31 multihot-small_study.ipynb\n",
      "-rw-r--r-- 1 leo leo  39K sept. 10 22:11 multihot_study_simple.ipynb\n",
      "-rw-r--r-- 1 leo leo 2,8K sept. 20 02:50 nextchar.py\n",
      "-rw-rw-r-- 1 leo leo 1,8K sept. 21 21:58 position_coding.py\n",
      "drwxr-xr-x 2 leo leo 4,0K oct.   4 18:11 \u001b[01;34m__pycache__\u001b[0m/\n",
      "-rw-r--r-- 1 leo leo  13K oct.   3 15:35 tcn.py\n",
      "drwxr-xr-x 2 leo leo 4,0K oct.  30 19:06 \u001b[01;34mutf8-codes\u001b[0m/\n",
      "-rw-r--r-- 1 leo leo 9,5K oct.   3 16:34 utf8_encoder.py\n",
      "-rw-rw-r-- 1 leo leo    0 sept. 10 22:06 utf8_multihot.py\n",
      "-rw-r--r-- 1 leo leo  17K sept.  9 18:25 UTF8_test.ipynb\n",
      "-rw-r--r-- 1 leo leo  11K juil. 30 11:41 utf8vae.py\n"
     ]
    }
   ],
   "source": [
    "ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is a bit big, so I'll cut out the part that is NOT used and leave just a few places for special codes, the rest, forget about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminate the values that we'll not use and keep the most distanced objects for special use\n",
    "embeds64short = np.concatenate([embeds64[:-113855], embeds64[-6:]], axis=0)\n",
    "# char2idxshort = np.concatenate([char2idx[:-113854], char2idx[-6:]], axis=0)\n",
    "# idx2charshort = np.concatenate([idx2char[:-113854], idx2char[-6:]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1107910, 64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds64short.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "eslen = len(embeds64short)\n",
    "char2idx[\"<err>\"] = eslen-1\n",
    "char2idx[\"<start>\"] = eslen-2\n",
    "char2idx[\"<stop>\"] = eslen-3\n",
    "char2idx[\"<unk>\"] = eslen-4\n",
    "char2idx[\"<null>\"] = eslen-5\n",
    "\n",
    "idx2char[eslen-1] = \"<err>\"\n",
    "idx2char[eslen-2] = \"<start>\"\n",
    "idx2char[eslen-3] = \"<stop>\"\n",
    "idx2char[eslen-4] = \"<unk>\"\n",
    "idx2char[eslen-5] = \"<null>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds64short = np.array(embeds64short, dtype='float32')\n",
    "embeds64shortbool = np.array(embeds64short, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del idx2char[1221758]\n",
    "# del idx2char[1221757]\n",
    "# del idx2char[1221756]\n",
    "# del idx2char[1221755]\n",
    "# del idx2char[1221754]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(char2idx)\n",
    "# del(idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds64short.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1107909, 1107909, (1107910, 64))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char2idx), len(idx2char), embeds64short.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I do some verification of the elements to be sure that all goes OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "aidx = set(range(embeds64short.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cidx = set(char2idx.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxc = set(idx2char.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107909"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idxc.intersection(cidx))  # intersection OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(set(), set())"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxc.difference(cidx), cidx.difference(idxc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This set should have 1 non used value (a special token space), this is by construction to get some space in case I need it and not having to change the codebook, just add it to the dictionary assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(set(), {1107904})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxc.difference(aidx), aidx.difference(idxc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds64short[[1107904]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now SAVE all the codes\n",
    "save_obj(char2idx, \"multihot64short-char2idx\")\n",
    "save_obj(idx2char, \"multihot64short-idx2char\")\n",
    "save_obj(embeds64short, \"multihot64short-embeds\")\n",
    "save_obj(embeds64shortbool, \"multihot64short-embeds-bool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking this change only, the complete numpy pickled embedding codebook changes from:\n",
    "* 625540774 bytes multihot64-embeds.pkl to\n",
    "* 567250086 bytes multihot64short-embeds.pkl\n",
    "\n",
    "so, about 55MBs difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
