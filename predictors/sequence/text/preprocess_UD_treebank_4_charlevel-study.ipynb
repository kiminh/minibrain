{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Dependencies Treebank Pre-Processing\n",
    "\n",
    "This notebook explores the preprocessing of the language conllu files to use them in character level neural networks.\n",
    "\n",
    "The languages and files to use will be filtered in order to avoid languages that use characters of utf-8 that are represented with 3 and 4 segmetns, as the tests are done only with the first 2 segments (this is for prerformance reasons and I consider that this is enough to show that the methodology works).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from sortedcontainers import SortedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import conllu\n",
    "import pyconll\n",
    "import pyconll.util\n",
    "import ntpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/8384737/extract-file-name-from-path-no-matter-what-the-os-path-format\n",
    "def path_leaf(path):\n",
    "    head, tail = ntpath.split(path)\n",
    "    return tail or ntpath.basename(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files_recurse(rootdir):\n",
    "    allfiles = []\n",
    "    for root, directories, filenames in os.walk(rootdir):\n",
    "        for filename in filenames: \n",
    "            allfiles.append(os.path.join(root,filename) )\n",
    "    return allfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conllu(fname):\n",
    "    f = open(fname,\"r\")\n",
    "    cnl = conllu.parse(f.read())\n",
    "    return path_leaf(fname), cnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfiles = get_all_files_recurse(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conllufiles = [f for f in allfiles if f.endswith(\".conllu\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conllufiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of languages that won't be used:\n",
    "# this is because I'll be using only the first 2 segments of UTF-8, so the idea is that \n",
    "## Maybe blacklist \n",
    "# \"Hebrew\",\n",
    "maybe_blacklist = [\"Kurmanji\", \"Urdu\", \"Indonesian\", \"Coptic-Scriptorium\", \"Kazakh\", \"Marathi\", \"Tamil\", \"Thai\", \"Warlpiri\"]\n",
    "lang_tokens_blacklist = [\"Hindi\", \"Chinese\", \"Korean\", \"Tagalog\", \"Vietnamese\", \"Telugu\", \"Uyghur\", \"Cantonese\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter out the languages that I won't be training on \n",
    "\n",
    "mainly due to the encoding I'm using I don't encode anything that is above 2 segments up to U+07FF in UTF-8, this is for resources reasons in my local machine.\n",
    "\n",
    "for more extensive and maybe future networks, I'll use 3 segments (up to U+FFFF), a complete encoding should use all 4 utf-8 segments up to U+10FFFF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = maybe_blacklist + lang_tokens_blacklist\n",
    "\n",
    "prefiltered_conllu = []\n",
    "for f in conllufiles:\n",
    "    todel = list(filter(lambda bl: bl in f, blacklist))\n",
    "#     print(f, todel)\n",
    "    if len(todel)==0:\n",
    "        prefiltered_conllu.append(f)\n",
    "#     else:\n",
    "#         print(\"todel>0\", todel)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prefiltered_conllu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conllu_train = [f for f in prefiltered_conllu if \"-train\" in f]\n",
    "conllu_test = [f for f in prefiltered_conllu if \"-test\" in f]\n",
    "conllu_dev = [f for f in prefiltered_conllu if \"-dev\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 120, 77)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conllu_train), len(conllu_test), len(conllu_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Basque-BDT/eu_bdt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Danish-DDT/da_ddt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Galician-TreeGal/gl_treegal-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Maltese-MUDT/mt_mudt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Irish-IDT/ga_idt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Galician-CTG/gl_ctg-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Latvian-LVTB/lv_lvtb-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Bulgarian-BTB/bg_btb-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Russian-Taiga/ru_taiga-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_French-Spoken/fr_spoken-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Norwegian-Nynorsk/no_nynorsk-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Czech-CLTT/cs_cltt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Spanish-GSD/es_gsd-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Italian-VIT/it_vit-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Italian-ParTUT/it_partut-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Wolof-WTB/wo_wtb-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Lithuanian-HSE/lt_hse-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Romanian-RRT/ro_rrt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Croatian-SET/hr_set-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Polish-LFG/pl_lfg-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_French-Sequoia/fr_sequoia-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Belarusian-HSE/be_hse-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Slovak-SNK/sk_snk-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Ukrainian-IU/uk_iu-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Turkish-IMST/tr_imst-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Czech-FicTree/cs_fictree-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Japanese-GSD/ja_gsd-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Latin-PROIEL/la_proiel-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Swedish-Talbanken/sv_talbanken-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_French-GSD/fr_gsd-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Serbian-SET/sr_set-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Catalan-AnCora/ca_ancora-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Czech-CAC/cs_cac-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Afrikaans-AfriBooms/af_afribooms-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Norwegian-Bokmaal/no_bokmaal-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Slovenian-SST/sl_sst-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Swedish_Sign_Language-SSLC/swl_sslc-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Japanese-BCCWJ/ja_bccwj-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Italian-PoSTWITA/it_postwita-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Finnish-FTB/fi_ftb-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_English-ESL/en_esl-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Upper_Sorbian-UFAL/hsb_ufal-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_English-LinES/en_lines-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Estonian-EDT/et_edt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Portuguese-GSD/pt_gsd-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Armenian-ArmTDP/hy_armtdp-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Ancient_Greek-Perseus/grc_perseus-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Swedish-LinES/sv_lines-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Portuguese-Bosque/pt_bosque-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Dutch-LassySmall/nl_lassysmall-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Hebrew-HTB/he_htb-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Old_Church_Slavonic-PROIEL/cu_proiel-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Finnish-TDT/fi_tdt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Slovenian-SSJ/sl_ssj-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_German-GSD/de_gsd-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Latin-Perseus/la_perseus-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Buryat-BDT/bxr_bdt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Persian-Seraji/fa_seraji-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Romanian-Nonstandard/ro_nonstandard-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Russian-GSD/ru_gsd-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_English-EWT/en_ewt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Polish-PDB/pl_pdb-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_North_Sami-Giella/sme_giella-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Norwegian-NynorskLIA/no_nynorsklia-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_French-ParTUT/fr_partut-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_German-HDT/de_hdt-ud-train-b.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_German-HDT/de_hdt-ud-train-a.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_English-GUM/en_gum-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Czech-PDT/cs_pdt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Old_French-SRCMF/fro_srcmf-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Gothic-PROIEL/got_proiel-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Old_Russian-TOROT/orv_torot-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Arabic-PADT/ar_padt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Estonian-EWT/et_ewt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Italian-ISDT/it_isdt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Ancient_Greek-PROIEL/grc_proiel-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Greek-GDT/el_gdt-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Latin-ITTB/la_ittb-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_English-ParTUT/en_partut-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Hungarian-Szeged/hu_szeged-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Lithuanian-ALKSNIS/lt_alksnis-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Arabic-NYUAD/ar_nyuad-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Russian-SynTagRus/ru_syntagrus-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Spanish-AnCora/es_ancora-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_French-FTB/fr_ftb-ud-train.conllu',\n",
       " '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Dutch-Alpino/nl_alpino-ud-train.conllu']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conllu_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all are files\n",
    "# ff = [os.path.isfile(f) for f in cleanfnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields according to conllu parser lib\n",
    "#fields = ['id', 'form', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc']\n",
    "# fields = ['upostag', 'deprel', 'feats']\n",
    "# fields = ['upostag', 'deprel']  # these are the only fields that I will take into account for training\n",
    "fields = ['upostag']  # first I'll start only with UPOS as is the smallest and simplest one to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upos (and the other fields) is extracted from the analysis of all the files in the ud-treebank dataset v2.4,\n",
    "# the same analysis can be done for v2.5 that came up on Nov 15th 2019.\n",
    "upos = {'ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', \n",
    "        'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', '_'}\n",
    "\n",
    "upos = sorted(list(upos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# deprel analysis of ud-treebank v2.4 on all the language files\n",
    "deprel={'_', 'acl', 'acl:adv', 'acl:appos', 'acl:cleft', 'acl:focus', 'acl:inf', 'acl:part', 'acl:poss', 'acl:relcl', 'advcl', 'advcl:appos', 'advcl:arg', 'advcl:cleft', 'advcl:cond', 'advcl:coverb', 'advcl:periph', 'advcl:relcl', 'advcl:sp', 'advcl:svc', 'advcl:tcl', 'advmod', 'advmod:appos', 'advmod:arg', 'advmod:cc', 'advmod:det', 'advmod:df', 'advmod:discourse', 'advmod:emph', 'advmod:locy', 'advmod:mode', 'advmod:neg', 'advmod:obl', 'advmod:periph', 'advmod:que', 'advmod:sentcon', 'advmod:tfrom', 'advmod:tlocy', 'advmod:tmod', 'advmod:to', 'advmod:tto', 'amod', 'amod:advmod', 'amod:att', 'amod:attlvc', 'amod:flat', 'amod:mode', 'amod:obl', 'appos', 'appos:conj', 'appos:nmod', 'aux', 'aux:aglt', 'aux:caus', 'aux:clitic', 'aux:cnd', 'aux:imp', 'aux:mood', 'aux:neg', 'aux:part', 'aux:pass', 'aux:poss', 'aux:q', 'case', 'case:acc', 'case:aspect', 'case:circ', 'case:dec', 'case:det', 'case:gen', 'case:loc', 'case:pred', 'case:pref', 'case:suff', 'case:voc', 'cc', 'cc:nc', 'cc:preconj', 'ccomp', 'ccomp:cleft', 'ccomp:obj', 'ccomp:obl', 'ccomp:pmod', 'ccomp:pred', 'clf', 'compound', 'compound:a', 'compound:affix', 'compound:coll', 'compound:conjv', 'compound:dir', 'compound:ext', 'compound:lvc', 'compound:n', 'compound:nn', 'compound:plur', 'compound:preverb', 'compound:prt', 'compound:quant', 'compound:redup', 'compound:smixut', 'compound:svc', 'compound:v', 'compound:vo', 'compound:vv', 'conj', 'conj:appos', 'conj:coord', 'conj:dicto', 'conj:extend', 'conj:redup', 'conj:svc', 'cop', 'cop:expl', 'cop:locat', 'cop:own', 'csubj', 'csubj:cleft', 'csubj:cop', 'csubj:pass', 'csubj:quasi', 'dep', 'dep:alt', 'dep:iobj', 'dep:obj', 'dep:prt', 'det', 'det:def', 'det:numgov', 'det:nummod', 'det:poss', 'det:predet', 'det:rel', 'discourse', 'discourse:emo', 'discourse:filler', 'discourse:intj', 'discourse:q', 'discourse:sp', 'dislocated', 'dislocated:cleft', 'expl', 'expl:impers', 'expl:pass', 'expl:poss', 'expl:pv', 'fixed', 'fixed:name', 'flat', 'flat:abs', 'flat:foreign', 'flat:name', 'flat:range', 'flat:repeat', 'flat:sibl', 'flat:title', 'flat:vv', 'goeswith', 'iobj', 'iobj:agent', 'iobj:appl', 'iobj:caus', 'list', 'mark', 'mark:adv', 'mark:advb', 'mark:advmod', 'mark:comp', 'mark:obj', 'mark:obl', 'mark:prt', 'mark:q', 'mark:rel', 'mark:relcl', 'nmod', 'nmod:abl', 'nmod:advmod', 'nmod:agent', 'nmod:appos', 'nmod:arg', 'nmod:att', 'nmod:attlvc', 'nmod:cau', 'nmod:clas', 'nmod:cmp', 'nmod:comp', 'nmod:dat', 'nmod:flat', 'nmod:gen', 'nmod:gmod', 'nmod:gobj', 'nmod:gsubj', 'nmod:ins', 'nmod:npmod', 'nmod:obl', 'nmod:obllvc', 'nmod:own', 'nmod:part', 'nmod:pmod', 'nmod:poss', 'nmod:pred', 'nmod:ref', 'nmod:tmod', 'nsubj', 'nsubj:advmod', 'nsubj:appos', 'nsubj:caus', 'nsubj:cop', 'nsubj:expl', 'nsubj:lvc', 'nsubj:nc', 'nsubj:obj', 'nsubj:own', 'nsubj:pass', 'nsubj:periph', 'nsubj:quasi', 'nummod', 'nummod:entity', 'nummod:gov', 'obj', 'obj:advmod', 'obj:advneg', 'obj:agent', 'obj:appl', 'obj:cau', 'obj:caus', 'obj:lvc', 'obj:obl', 'obj:periph', 'obl', 'obl:advmod', 'obl:agent', 'obl:appl', 'obl:arg', 'obl:cau', 'obl:cmpr', 'obl:comp', 'obl:lmod', 'obl:loc', 'obl:mod', 'obl:npmod', 'obl:own', 'obl:patient', 'obl:periph', 'obl:poss', 'obl:prep', 'obl:sentcon', 'obl:tmod', 'obl:x', 'orphan', 'parataxis', 'parataxis:appos', 'parataxis:conj', 'parataxis:deletion', 'parataxis:discourse', 'parataxis:dislocated', 'parataxis:hashtag', 'parataxis:insert', 'parataxis:newsent', 'parataxis:nsubj', 'parataxis:obj', 'parataxis:parenth', 'parataxis:rel', 'parataxis:rep', 'parataxis:restart', 'punct', 'reparandum', 'root', 'vocative', 'vocative:cl', 'vocative:mention', 'xcomp', 'xcomp:adj', 'xcomp:ds', 'xcomp:obj', 'xcomp:pred', 'xcomp:sp', 'xcomp:subj'}\n",
    "deprel=sorted(list(deprel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 278)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(upos), len(deprel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "UPOS = {'ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON',\n",
    "        'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', '_'}\n",
    "UPOS_LIST = sorted(list(UPOS))\n",
    "UPOS_IDX2CHAR = SortedDict(enumerate(UPOS_LIST))\n",
    "UPOS_CHAR2IDX = SortedDict(zip(UPOS_LIST, range(len(UPOS_LIST))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SortedDict({'ADJ': 0, 'ADP': 1, 'ADV': 2, 'AUX': 3, 'CCONJ': 4, 'DET': 5, 'INTJ': 6, 'NOUN': 7, 'NUM': 8, 'PART': 9, 'PRON': 10, 'PROPN': 11, 'PUNCT': 12, 'SCONJ': 13, 'SYM': 14, 'VERB': 15, 'X': 16, '_': 17})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UPOS_CHAR2IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SortedDict({0: 'ADJ', 1: 'ADP', 2: 'ADV', 3: 'AUX', 4: 'CCONJ', 5: 'DET', 6: 'INTJ', 7: 'NOUN', 8: 'NUM', 9: 'PART', 10: 'PRON', 11: 'PROPN', 12: 'PUNCT', 13: 'SCONJ', 14: 'SYM', 15: 'VERB', 16: 'X', 17: '_'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UPOS_IDX2CHAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprel analysis of ud-treebank v2.4 on all the language files\n",
    "DEPREL = {'_', 'acl', 'acl:adv', 'acl:appos', 'acl:cleft', 'acl:focus', 'acl:inf', 'acl:part', 'acl:poss', 'acl:relcl', 'advcl', 'advcl:appos', 'advcl:arg', 'advcl:cleft', 'advcl:cond', 'advcl:coverb', 'advcl:periph', 'advcl:relcl', 'advcl:sp', 'advcl:svc', 'advcl:tcl', 'advmod', 'advmod:appos', 'advmod:arg', 'advmod:cc', 'advmod:det', 'advmod:df', 'advmod:discourse', 'advmod:emph', 'advmod:locy', 'advmod:mode', 'advmod:neg', 'advmod:obl', 'advmod:periph', 'advmod:que', 'advmod:sentcon', 'advmod:tfrom', 'advmod:tlocy', 'advmod:tmod', 'advmod:to', 'advmod:tto', 'amod', 'amod:advmod', 'amod:att', 'amod:attlvc', 'amod:flat', 'amod:mode', 'amod:obl', 'appos', 'appos:conj', 'appos:nmod', 'aux', 'aux:aglt', 'aux:caus', 'aux:clitic', 'aux:cnd', 'aux:imp', 'aux:mood', 'aux:neg', 'aux:part', 'aux:pass', 'aux:poss', 'aux:q', 'case', 'case:acc', 'case:aspect', 'case:circ', 'case:dec', 'case:det', 'case:gen', 'case:loc', 'case:pred', 'case:pref', 'case:suff', 'case:voc', 'cc', 'cc:nc', 'cc:preconj', 'ccomp', 'ccomp:cleft', 'ccomp:obj', 'ccomp:obl', 'ccomp:pmod', 'ccomp:pred', 'clf', 'compound', 'compound:a', 'compound:affix', 'compound:coll', 'compound:conjv', 'compound:dir', 'compound:ext', 'compound:lvc', 'compound:n', 'compound:nn', 'compound:plur', 'compound:preverb', 'compound:prt', 'compound:quant', 'compound:redup', 'compound:smixut', 'compound:svc', 'compound:v', 'compound:vo', 'compound:vv', 'conj', 'conj:appos', 'conj:coord', 'conj:dicto', 'conj:extend', 'conj:redup', 'conj:svc', 'cop', 'cop:expl', 'cop:locat', 'cop:own', 'csubj', 'csubj:cleft', 'csubj:cop', 'csubj:pass', 'csubj:quasi', 'dep', 'dep:alt', 'dep:iobj', 'dep:obj', 'dep:prt', 'det', 'det:def', 'det:numgov', 'det:nummod', 'det:poss', 'det:predet', 'det:rel', 'discourse', 'discourse:emo', 'discourse:filler', 'discourse:intj', 'discourse:q', 'discourse:sp', 'dislocated', 'dislocated:cleft', 'expl', 'expl:impers', 'expl:pass', 'expl:poss', 'expl:pv', 'fixed', 'fixed:name', 'flat', 'flat:abs', 'flat:foreign', 'flat:name', 'flat:range', 'flat:repeat', 'flat:sibl', 'flat:title', 'flat:vv', 'goeswith', 'iobj', 'iobj:agent', 'iobj:appl', 'iobj:caus', 'list', 'mark', 'mark:adv', 'mark:advb', 'mark:advmod', 'mark:comp', 'mark:obj', 'mark:obl', 'mark:prt', 'mark:q', 'mark:rel', 'mark:relcl', 'nmod', 'nmod:abl', 'nmod:advmod', 'nmod:agent', 'nmod:appos', 'nmod:arg', 'nmod:att', 'nmod:attlvc', 'nmod:cau', 'nmod:clas', 'nmod:cmp', 'nmod:comp', 'nmod:dat', 'nmod:flat', 'nmod:gen', 'nmod:gmod', 'nmod:gobj', 'nmod:gsubj', 'nmod:ins', 'nmod:npmod', 'nmod:obl', 'nmod:obllvc', 'nmod:own', 'nmod:part', 'nmod:pmod', 'nmod:poss', 'nmod:pred', 'nmod:ref', 'nmod:tmod', 'nsubj', 'nsubj:advmod', 'nsubj:appos', 'nsubj:caus', 'nsubj:cop', 'nsubj:expl', 'nsubj:lvc', 'nsubj:nc', 'nsubj:obj', 'nsubj:own', 'nsubj:pass', 'nsubj:periph', 'nsubj:quasi', 'nummod', 'nummod:entity', 'nummod:gov', 'obj', 'obj:advmod', 'obj:advneg', 'obj:agent', 'obj:appl', 'obj:cau', 'obj:caus', 'obj:lvc', 'obj:obl', 'obj:periph', 'obl', 'obl:advmod', 'obl:agent', 'obl:appl', 'obl:arg', 'obl:cau', 'obl:cmpr', 'obl:comp', 'obl:lmod', 'obl:loc', 'obl:mod', 'obl:npmod', 'obl:own', 'obl:patient', 'obl:periph', 'obl:poss', 'obl:prep', 'obl:sentcon', 'obl:tmod', 'obl:x', 'orphan', 'parataxis', 'parataxis:appos', 'parataxis:conj', 'parataxis:deletion', 'parataxis:discourse', 'parataxis:dislocated', 'parataxis:hashtag', 'parataxis:insert', 'parataxis:newsent', 'parataxis:nsubj', 'parataxis:obj', 'parataxis:parenth', 'parataxis:rel', 'parataxis:rep', 'parataxis:restart', 'punct', 'reparandum', 'root', 'vocative', 'vocative:cl', 'vocative:mention', 'xcomp', 'xcomp:adj', 'xcomp:ds', 'xcomp:obj', 'xcomp:pred', 'xcomp:sp', 'xcomp:subj'}\n",
    "DEPREL_LIST = sorted(list(DEPREL))\n",
    "DEPREL_IDX2CHAR = SortedDict(enumerate(DEPREL_LIST))\n",
    "DEPREL_CHAR2IDX = SortedDict(zip(DEPREL_LIST, range(len(DEPREL_LIST))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually doing one processing so I understand how it is and if the process goes OK.\n",
    "\n",
    "es_test = '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_Spanish-AnCora/es_ancora-ud-train.conllu'\n",
    "fr_test = '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_French-ParTUT/fr_partut-ud-train.conllu',\n",
    "en_test = '/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/UD_English-EWT/en_ewt-ud-train.conllu',\n",
    "\n",
    "# should later verify that things are OK in every processed file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.63 s, sys: 220 ms, total: 6.85 s\n",
      "Wall time: 6.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "es_leaf, es_cnl = get_conllu(es_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "escnl0 = es_cnl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.16 s, sys: 212 ms, total: 4.38 s\n",
      "Wall time: 4.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# conllu library seems to basic for the usage I need, now I'll try pyconll\n",
    "es_pcnl = pyconll.load_from_file(es_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess0 = es_pcnl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14305"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( es_pcnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ess0._ids_to_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "est0 = ess0._tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El presidente del órgano regulador de las Telecomunicaciones se mostró partidario de completar esta liberalización de las telecomunicaciones con otras medidas que incentiven la competencia como puede ser abrir el acceso a la información de los clientes de Telefónica a otros operadores.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ess0.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U1')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(ess0.text)).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_txt = np.array(list(ess0.text))\n",
    "l_tags = np.empty_like(l_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 286)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack([l_txt, l_tags]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(ess0.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in es_pcnl:\n",
    "#     print(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est0.form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ess0.text[0:].find(est0.form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DET'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est0.upos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' presidente del órgano regulador de las Telecomunicaciones se mostró partidario de completar esta liberalización de las telecomunicaciones con otras medidas que incentiven la competencia como puede ser abrir el acceso a la información de los clientes de Telefónica a otros operadores.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ess0.text[0+0+2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2charlevel(sequence, upos=True, deprel=False):\n",
    "    \"\"\"\n",
    "    :param sequence: conllu (pyconll) sequence\n",
    "    :return: a numpy array of chars where the first column is the text (char by char) and the \n",
    "    remaining columns are the tags assigned upos and deprel (in that order)\n",
    "    \"\"\"\n",
    "    # convert text to list\n",
    "    txt = sequence.text\n",
    "    l_txt = np.array(list(txt))\n",
    "#     l_tags = np.empty_like(l_txt)\n",
    "#     l_tags_upos = np.empty(l_txt.shape, dtype=\"U5\")  # 5 chars is the max lenght of the upos type\n",
    "    l_tags_upos = np.full(l_txt.shape, fill_value=\"_\", dtype=\"U5\")  # 5 chars is the max lenght of the upos type\n",
    "    l_tags_deprel = None\n",
    "    if deprel:\n",
    "#         l_tags_deprel = np.empty(l_txt.shape, dtype=\"U20\")  # 5 chars is the max lenght of the deprel type in the analysis\n",
    "        l_tags_deprel = np.full(l_txt.shape, fill_value=\"_\", dtype=\"U20\")\n",
    "    # for each token, go in the string \n",
    "    index = 0\n",
    "    for t in sequence._tokens:\n",
    "        # find token indices in the remaining of the sequence (this is to do a good tagging)\n",
    "        tidx = txt[index:].find(t.form)\n",
    "        tlen = len(t.form)\n",
    "        idx_start = index + tidx\n",
    "        idx_end = idx_start + tlen\n",
    "        # set the flags for each char\n",
    "        l_tags_upos[idx_start:idx_end] = t.upos\n",
    "        if deprel:\n",
    "            l_tags_deprel[idx_start:idx_end] = t.deprel\n",
    "        # set index to the new absolute text position\n",
    "        index = idx_end\n",
    "    if deprel:\n",
    "        ret = np.stack([l_txt, l_tags_upos, l_tags_deprel])\n",
    "    else:\n",
    "        ret = np.stack([l_txt, l_tags_upos])\n",
    "    return ret\n",
    "#     return l_txt, l_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 242 µs, sys: 15 µs, total: 257 µs\n",
      "Wall time: 188 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['E', 'DET', 'det'],\n",
       "       ['l', 'DET', 'det'],\n",
       "       [' ', '_', '_'],\n",
       "       ['p', 'NOUN', 'nsubj'],\n",
       "       ['r', 'NOUN', 'nsubj'],\n",
       "       ['e', 'NOUN', 'nsubj'],\n",
       "       ['s', 'NOUN', 'nsubj'],\n",
       "       ['i', 'NOUN', 'nsubj'],\n",
       "       ['d', 'NOUN', 'nsubj'],\n",
       "       ['e', 'NOUN', 'nsubj'],\n",
       "       ['n', 'NOUN', 'nsubj'],\n",
       "       ['t', 'NOUN', 'nsubj'],\n",
       "       ['e', 'NOUN', 'nsubj'],\n",
       "       [' ', '_', '_'],\n",
       "       ['d', 'ADP', 'case'],\n",
       "       ['e', 'ADP', 'case'],\n",
       "       ['l', 'ADP', 'case'],\n",
       "       [' ', '_', '_'],\n",
       "       ['ó', 'NOUN', 'nmod'],\n",
       "       ['r', 'NOUN', 'nmod'],\n",
       "       ['g', 'NOUN', 'nmod'],\n",
       "       ['a', 'NOUN', 'nmod'],\n",
       "       ['n', 'NOUN', 'nmod'],\n",
       "       ['o', 'NOUN', 'nmod'],\n",
       "       [' ', '_', '_'],\n",
       "       ['r', 'ADJ', 'amod'],\n",
       "       ['e', 'ADJ', 'amod'],\n",
       "       ['g', 'ADJ', 'amod'],\n",
       "       ['u', 'ADJ', 'amod'],\n",
       "       ['l', 'ADJ', 'amod'],\n",
       "       ['a', 'ADJ', 'amod'],\n",
       "       ['d', 'ADJ', 'amod'],\n",
       "       ['o', 'ADJ', 'amod'],\n",
       "       ['r', 'ADJ', 'amod'],\n",
       "       [' ', '_', '_'],\n",
       "       ['d', 'ADP', 'case'],\n",
       "       ['e', 'ADP', 'case'],\n",
       "       [' ', '_', '_'],\n",
       "       ['l', 'DET', 'det'],\n",
       "       ['a', 'DET', 'det'],\n",
       "       ['s', 'DET', 'det'],\n",
       "       [' ', '_', '_'],\n",
       "       ['T', 'PROPN', 'nmod'],\n",
       "       ['e', 'PROPN', 'nmod'],\n",
       "       ['l', 'PROPN', 'nmod'],\n",
       "       ['e', 'PROPN', 'nmod'],\n",
       "       ['c', 'PROPN', 'nmod'],\n",
       "       ['o', 'PROPN', 'nmod'],\n",
       "       ['m', 'PROPN', 'nmod'],\n",
       "       ['u', 'PROPN', 'nmod'],\n",
       "       ['n', 'PROPN', 'nmod'],\n",
       "       ['i', 'PROPN', 'nmod'],\n",
       "       ['c', 'PROPN', 'nmod'],\n",
       "       ['a', 'PROPN', 'nmod'],\n",
       "       ['c', 'PROPN', 'nmod'],\n",
       "       ['i', 'PROPN', 'nmod'],\n",
       "       ['o', 'PROPN', 'nmod'],\n",
       "       ['n', 'PROPN', 'nmod'],\n",
       "       ['e', 'PROPN', 'nmod'],\n",
       "       ['s', 'PROPN', 'nmod'],\n",
       "       [' ', '_', '_'],\n",
       "       ['s', 'PRON', 'obj'],\n",
       "       ['e', 'PRON', 'obj'],\n",
       "       [' ', '_', '_'],\n",
       "       ['m', 'VERB', 'root'],\n",
       "       ['o', 'VERB', 'root'],\n",
       "       ['s', 'VERB', 'root'],\n",
       "       ['t', 'VERB', 'root'],\n",
       "       ['r', 'VERB', 'root'],\n",
       "       ['ó', 'VERB', 'root'],\n",
       "       [' ', '_', '_'],\n",
       "       ['p', 'ADJ', 'obj'],\n",
       "       ['a', 'ADJ', 'obj'],\n",
       "       ['r', 'ADJ', 'obj'],\n",
       "       ['t', 'ADJ', 'obj'],\n",
       "       ['i', 'ADJ', 'obj'],\n",
       "       ['d', 'ADJ', 'obj'],\n",
       "       ['a', 'ADJ', 'obj'],\n",
       "       ['r', 'ADJ', 'obj'],\n",
       "       ['i', 'ADJ', 'obj'],\n",
       "       ['o', 'ADJ', 'obj'],\n",
       "       [' ', '_', '_'],\n",
       "       ['d', 'ADP', 'mark'],\n",
       "       ['e', 'ADP', 'mark'],\n",
       "       [' ', '_', '_'],\n",
       "       ['c', 'VERB', 'acl'],\n",
       "       ['o', 'VERB', 'acl'],\n",
       "       ['m', 'VERB', 'acl'],\n",
       "       ['p', 'VERB', 'acl'],\n",
       "       ['l', 'VERB', 'acl'],\n",
       "       ['e', 'VERB', 'acl'],\n",
       "       ['t', 'VERB', 'acl'],\n",
       "       ['a', 'VERB', 'acl'],\n",
       "       ['r', 'VERB', 'acl'],\n",
       "       [' ', '_', '_'],\n",
       "       ['e', 'DET', 'det'],\n",
       "       ['s', 'DET', 'det'],\n",
       "       ['t', 'DET', 'det'],\n",
       "       ['a', 'DET', 'det'],\n",
       "       [' ', '_', '_'],\n",
       "       ['l', 'NOUN', 'obj'],\n",
       "       ['i', 'NOUN', 'obj'],\n",
       "       ['b', 'NOUN', 'obj'],\n",
       "       ['e', 'NOUN', 'obj'],\n",
       "       ['r', 'NOUN', 'obj'],\n",
       "       ['a', 'NOUN', 'obj'],\n",
       "       ['l', 'NOUN', 'obj'],\n",
       "       ['i', 'NOUN', 'obj'],\n",
       "       ['z', 'NOUN', 'obj'],\n",
       "       ['a', 'NOUN', 'obj'],\n",
       "       ['c', 'NOUN', 'obj'],\n",
       "       ['i', 'NOUN', 'obj'],\n",
       "       ['ó', 'NOUN', 'obj'],\n",
       "       ['n', 'NOUN', 'obj'],\n",
       "       [' ', '_', '_'],\n",
       "       ['d', 'ADP', 'case'],\n",
       "       ['e', 'ADP', 'case'],\n",
       "       [' ', '_', '_'],\n",
       "       ['l', 'DET', 'det'],\n",
       "       ['a', 'DET', 'det'],\n",
       "       ['s', 'DET', 'det'],\n",
       "       [' ', '_', '_'],\n",
       "       ['t', 'NOUN', 'nmod'],\n",
       "       ['e', 'NOUN', 'nmod'],\n",
       "       ['l', 'NOUN', 'nmod'],\n",
       "       ['e', 'NOUN', 'nmod'],\n",
       "       ['c', 'NOUN', 'nmod'],\n",
       "       ['o', 'NOUN', 'nmod'],\n",
       "       ['m', 'NOUN', 'nmod'],\n",
       "       ['u', 'NOUN', 'nmod'],\n",
       "       ['n', 'NOUN', 'nmod'],\n",
       "       ['i', 'NOUN', 'nmod'],\n",
       "       ['c', 'NOUN', 'nmod'],\n",
       "       ['a', 'NOUN', 'nmod'],\n",
       "       ['c', 'NOUN', 'nmod'],\n",
       "       ['i', 'NOUN', 'nmod'],\n",
       "       ['o', 'NOUN', 'nmod'],\n",
       "       ['n', 'NOUN', 'nmod'],\n",
       "       ['e', 'NOUN', 'nmod'],\n",
       "       ['s', 'NOUN', 'nmod'],\n",
       "       [' ', '_', '_'],\n",
       "       ['c', 'ADP', 'case'],\n",
       "       ['o', 'ADP', 'case'],\n",
       "       ['n', 'ADP', 'case'],\n",
       "       [' ', '_', '_'],\n",
       "       ['o', 'DET', 'det'],\n",
       "       ['t', 'DET', 'det'],\n",
       "       ['r', 'DET', 'det'],\n",
       "       ['a', 'DET', 'det'],\n",
       "       ['s', 'DET', 'det'],\n",
       "       [' ', '_', '_'],\n",
       "       ['m', 'NOUN', 'obl'],\n",
       "       ['e', 'NOUN', 'obl'],\n",
       "       ['d', 'NOUN', 'obl'],\n",
       "       ['i', 'NOUN', 'obl'],\n",
       "       ['d', 'NOUN', 'obl'],\n",
       "       ['a', 'NOUN', 'obl'],\n",
       "       ['s', 'NOUN', 'obl'],\n",
       "       [' ', '_', '_'],\n",
       "       ['q', 'PRON', 'nsubj'],\n",
       "       ['u', 'PRON', 'nsubj'],\n",
       "       ['e', 'PRON', 'nsubj'],\n",
       "       [' ', '_', '_'],\n",
       "       ['i', 'VERB', 'acl'],\n",
       "       ['n', 'VERB', 'acl'],\n",
       "       ['c', 'VERB', 'acl'],\n",
       "       ['e', 'VERB', 'acl'],\n",
       "       ['n', 'VERB', 'acl'],\n",
       "       ['t', 'VERB', 'acl'],\n",
       "       ['i', 'VERB', 'acl'],\n",
       "       ['v', 'VERB', 'acl'],\n",
       "       ['e', 'VERB', 'acl'],\n",
       "       ['n', 'VERB', 'acl'],\n",
       "       [' ', '_', '_'],\n",
       "       ['l', 'DET', 'det'],\n",
       "       ['a', 'DET', 'det'],\n",
       "       [' ', '_', '_'],\n",
       "       ['c', 'NOUN', 'obj'],\n",
       "       ['o', 'NOUN', 'obj'],\n",
       "       ['m', 'NOUN', 'obj'],\n",
       "       ['p', 'NOUN', 'obj'],\n",
       "       ['e', 'NOUN', 'obj'],\n",
       "       ['t', 'NOUN', 'obj'],\n",
       "       ['e', 'NOUN', 'obj'],\n",
       "       ['n', 'NOUN', 'obj'],\n",
       "       ['c', 'NOUN', 'obj'],\n",
       "       ['i', 'NOUN', 'obj'],\n",
       "       ['a', 'NOUN', 'obj'],\n",
       "       [' ', '_', '_'],\n",
       "       ['c', 'SCONJ', 'mark'],\n",
       "       ['o', 'SCONJ', 'mark'],\n",
       "       ['m', 'SCONJ', 'mark'],\n",
       "       ['o', 'SCONJ', 'mark'],\n",
       "       [' ', '_', '_'],\n",
       "       ['p', 'NOUN', 'fixed'],\n",
       "       ['u', 'NOUN', 'fixed'],\n",
       "       ['e', 'NOUN', 'fixed'],\n",
       "       ['d', 'NOUN', 'fixed'],\n",
       "       ['e', 'NOUN', 'fixed'],\n",
       "       [' ', '_', '_'],\n",
       "       ['s', 'NOUN', 'fixed'],\n",
       "       ['e', 'NOUN', 'fixed'],\n",
       "       ['r', 'NOUN', 'fixed'],\n",
       "       [' ', '_', '_'],\n",
       "       ['a', 'VERB', 'acl'],\n",
       "       ['b', 'VERB', 'acl'],\n",
       "       ['r', 'VERB', 'acl'],\n",
       "       ['i', 'VERB', 'acl'],\n",
       "       ['r', 'VERB', 'acl'],\n",
       "       [' ', '_', '_'],\n",
       "       ['e', 'DET', 'det'],\n",
       "       ['l', 'DET', 'det'],\n",
       "       [' ', '_', '_'],\n",
       "       ['a', 'NOUN', 'obj'],\n",
       "       ['c', 'NOUN', 'obj'],\n",
       "       ['c', 'NOUN', 'obj'],\n",
       "       ['e', 'NOUN', 'obj'],\n",
       "       ['s', 'NOUN', 'obj'],\n",
       "       ['o', 'NOUN', 'obj'],\n",
       "       [' ', '_', '_'],\n",
       "       ['a', 'ADP', 'case'],\n",
       "       [' ', '_', '_'],\n",
       "       ['l', 'DET', 'det'],\n",
       "       ['a', 'DET', 'det'],\n",
       "       [' ', '_', '_'],\n",
       "       ['i', 'NOUN', 'nmod'],\n",
       "       ['n', 'NOUN', 'nmod'],\n",
       "       ['f', 'NOUN', 'nmod'],\n",
       "       ['o', 'NOUN', 'nmod'],\n",
       "       ['r', 'NOUN', 'nmod'],\n",
       "       ['m', 'NOUN', 'nmod'],\n",
       "       ['a', 'NOUN', 'nmod'],\n",
       "       ['c', 'NOUN', 'nmod'],\n",
       "       ['i', 'NOUN', 'nmod'],\n",
       "       ['ó', 'NOUN', 'nmod'],\n",
       "       ['n', 'NOUN', 'nmod'],\n",
       "       [' ', '_', '_'],\n",
       "       ['d', 'ADP', 'case'],\n",
       "       ['e', 'ADP', 'case'],\n",
       "       [' ', '_', '_'],\n",
       "       ['l', 'DET', 'det'],\n",
       "       ['o', 'DET', 'det'],\n",
       "       ['s', 'DET', 'det'],\n",
       "       [' ', '_', '_'],\n",
       "       ['c', 'NOUN', 'nmod'],\n",
       "       ['l', 'NOUN', 'nmod'],\n",
       "       ['i', 'NOUN', 'nmod'],\n",
       "       ['e', 'NOUN', 'nmod'],\n",
       "       ['n', 'NOUN', 'nmod'],\n",
       "       ['t', 'NOUN', 'nmod'],\n",
       "       ['e', 'NOUN', 'nmod'],\n",
       "       ['s', 'NOUN', 'nmod'],\n",
       "       [' ', '_', '_'],\n",
       "       ['d', 'ADP', 'case'],\n",
       "       ['e', 'ADP', 'case'],\n",
       "       [' ', '_', '_'],\n",
       "       ['T', 'PROPN', 'nmod'],\n",
       "       ['e', 'PROPN', 'nmod'],\n",
       "       ['l', 'PROPN', 'nmod'],\n",
       "       ['e', 'PROPN', 'nmod'],\n",
       "       ['f', 'PROPN', 'nmod'],\n",
       "       ['ó', 'PROPN', 'nmod'],\n",
       "       ['n', 'PROPN', 'nmod'],\n",
       "       ['i', 'PROPN', 'nmod'],\n",
       "       ['c', 'PROPN', 'nmod'],\n",
       "       ['a', 'PROPN', 'nmod'],\n",
       "       [' ', '_', '_'],\n",
       "       ['a', 'ADP', 'case'],\n",
       "       [' ', '_', '_'],\n",
       "       ['o', 'DET', 'det'],\n",
       "       ['t', 'DET', 'det'],\n",
       "       ['r', 'DET', 'det'],\n",
       "       ['o', 'DET', 'det'],\n",
       "       ['s', 'DET', 'det'],\n",
       "       [' ', '_', '_'],\n",
       "       ['o', 'NOUN', 'obj'],\n",
       "       ['p', 'NOUN', 'obj'],\n",
       "       ['e', 'NOUN', 'obj'],\n",
       "       ['r', 'NOUN', 'obj'],\n",
       "       ['a', 'NOUN', 'obj'],\n",
       "       ['d', 'NOUN', 'obj'],\n",
       "       ['o', 'NOUN', 'obj'],\n",
       "       ['r', 'NOUN', 'obj'],\n",
       "       ['e', 'NOUN', 'obj'],\n",
       "       ['s', 'NOUN', 'obj'],\n",
       "       ['.', 'PUNCT', 'punct']], dtype='<U20')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "seq2charlevel(ess0, deprel=True).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charseq2int(charseq, char2int_codebook, upos2int, deprel2int):\n",
    "    \"\"\"\n",
    "\n",
    "    :param charseq: character sequence in a numpy matrix form where shape = (2,N) or (3,N)\n",
    "            charseq[0] is the character sequence\n",
    "            charseq[1] is the upos tag\n",
    "            charseq[2] is the deprel tag\n",
    "    :param char2int_codebook: dictionary codebook encoding the chars to int indices\n",
    "    :param upos2int: dictionary encoding the upos tags to int\n",
    "    :param deprel2int: dictionary encoding the deprel tags to int\n",
    "    :return: an output matrix of type int of the same dimensions as the input with the index coding for each row\n",
    "    \"\"\"\n",
    "    assert 2 <= charseq.shape[0] <= 3\n",
    "    ret = np.empty(shape=charseq.shape, dtype=np.int32)\n",
    "    ret[0, :] = np.vectorize(char2int_codebook.get)(charseq[0])\n",
    "    ret[1, :] = np.vectorize(upos2int.get)(charseq[1], upos2int[\"_\"])\n",
    "    if charseq.shape[0] == 3:\n",
    "        ret[2, :] = np.vectorize(deprel2int.get)(charseq[2], deprel2int[\"_\"])\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I test the ideas here, I need to load the encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utf8_encoder import *\n",
    "utf8codebook = np.load(\"utf8-codes/utf8_code_matrix_2seg.npy\")\n",
    "idx2char = load_obj(\"utf8-codes/num2txt_2seg.pkl\")\n",
    "char2idx = load_obj(\"utf8-codes/txt2num_2seg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "charseq = seq2charlevel(ess0, deprel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = np.zeros(shape=charseq.shape, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret[0, :] = np.vectorize(char2idx.get)(charseq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret[1, :] = np.vectorize(UPOS_CHAR2IDX.get)(charseq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret[2, :] = np.vectorize(DEPREL_CHAR2IDX.get)(charseq[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([126, 126,   0, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203,\n",
       "         0,  63,  63,  63,   0, 174, 174, 174, 174, 174, 174,   0,  41,\n",
       "        41,  41,  41,  41,  41,  41,  41,  41,   0,  63,  63,   0, 126,\n",
       "       126, 126,   0, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174,\n",
       "       174, 174, 174, 174, 174, 174, 174, 174,   0, 219, 219,   0, 267,\n",
       "       267, 267, 267, 267, 267,   0, 219, 219, 219, 219, 219, 219, 219,\n",
       "       219, 219, 219,   0, 163, 163,   0,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   0, 126, 126, 126, 126,   0, 219, 219, 219, 219,\n",
       "       219, 219, 219, 219, 219, 219, 219, 219, 219, 219,   0,  63,  63,\n",
       "         0, 126, 126, 126,   0, 174, 174, 174, 174, 174, 174, 174, 174,\n",
       "       174, 174, 174, 174, 174, 174, 174, 174, 174, 174,   0,  63,  63,\n",
       "        63,   0, 126, 126, 126, 126, 126,   0, 229, 229, 229, 229, 229,\n",
       "       229, 229,   0, 203, 203, 203,   0,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   0, 126, 126,   0, 219, 219, 219, 219, 219,\n",
       "       219, 219, 219, 219, 219, 219,   0, 163, 163, 163, 163,   0, 146,\n",
       "       146, 146, 146, 146,   0, 146, 146, 146,   0,   1,   1,   1,   1,\n",
       "         1,   0, 126, 126,   0, 219, 219, 219, 219, 219, 219,   0,  63,\n",
       "         0, 126, 126,   0, 174, 174, 174, 174, 174, 174, 174, 174, 174,\n",
       "       174, 174,   0,  63,  63,   0, 126, 126, 126,   0, 174, 174, 174,\n",
       "       174, 174, 174, 174, 174,   0,  63,  63,   0, 174, 174, 174, 174,\n",
       "       174, 174, 174, 174, 174, 174,   0,  63,   0, 126, 126, 126, 126,\n",
       "       126,   0, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 265],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_charseq = charseq2int(charseq, char2idx, UPOS_CHAR2IDX, DEPREL_CHAR2IDX)\n",
    "# ind_charseq = charseq2int(charseq, char2idx)  #, UPOS_CHAR2IDX, DEPREL_CHAR2IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(DEPREL_CHAR2IDX.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advmod:df'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEPREL_IDX2CHAR[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEPREL_CHAR2IDX[\"nsubj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([['E', 'l', ' ', 'p', 'r', 'e', 's', 'i', 'd', 'e', 'n', 't', 'e',\n",
       "         ' ', 'd', 'e', 'l', ' ', 'ó', 'r'],\n",
       "        ['DET', 'DET', '_', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN',\n",
       "         'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', '_', 'ADP', 'ADP', 'ADP',\n",
       "         '_', 'NOUN', 'NOUN'],\n",
       "        ['det', 'det', '_', 'nsubj', 'nsubj', 'nsubj', 'nsubj', 'nsubj',\n",
       "         'nsubj', 'nsubj', 'nsubj', 'nsubj', 'nsubj', '_', 'case', 'case',\n",
       "         'case', '_', 'nmod', 'nmod']], dtype='<U20'),\n",
       " array([[ 69, 108,  32, 112, 114, 101, 115, 105, 100, 101, 110, 116, 101,\n",
       "          32, 100, 101, 108,  32, 243, 114],\n",
       "        [  5,   5,  17,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          17,   1,   1,   1,  17,   7,   7],\n",
       "        [126, 126,   0, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203,\n",
       "           0,  63,  63,  63,   0, 174, 174]], dtype=int32))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charseq[:,:20], ind_charseq[:,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 69, 108,  32, 112, 114, 101, 115, 105, 100, 101, 110, 116, 101,\n",
       "         32, 100, 101, 108,  32, 243, 114, 103,  97, 110, 111,  32, 114,\n",
       "        101, 103, 117, 108,  97, 100, 111, 114,  32, 100, 101,  32, 108,\n",
       "         97, 115,  32,  84, 101, 108, 101,  99, 111, 109, 117, 110, 105,\n",
       "         99,  97,  99, 105, 111, 110, 101, 115,  32, 115, 101,  32, 109,\n",
       "        111, 115, 116, 114, 243,  32, 112,  97, 114, 116, 105, 100,  97,\n",
       "        114, 105, 111,  32, 100, 101,  32,  99, 111, 109, 112, 108, 101,\n",
       "        116,  97, 114,  32, 101, 115, 116,  97,  32, 108, 105,  98, 101,\n",
       "        114,  97, 108, 105, 122,  97,  99, 105, 243, 110,  32, 100, 101,\n",
       "         32, 108,  97, 115,  32, 116, 101, 108, 101,  99, 111, 109, 117,\n",
       "        110, 105,  99,  97,  99, 105, 111, 110, 101, 115,  32,  99, 111,\n",
       "        110,  32, 111, 116, 114,  97, 115,  32, 109, 101, 100, 105, 100,\n",
       "         97, 115,  32, 113, 117, 101,  32, 105, 110,  99, 101, 110, 116,\n",
       "        105, 118, 101, 110,  32, 108,  97,  32,  99, 111, 109, 112, 101,\n",
       "        116, 101, 110,  99, 105,  97,  32,  99, 111, 109, 111,  32, 112,\n",
       "        117, 101, 100, 101,  32, 115, 101, 114,  32,  97,  98, 114, 105,\n",
       "        114,  32, 101, 108,  32,  97,  99,  99, 101, 115, 111,  32,  97,\n",
       "         32, 108,  97,  32, 105, 110, 102, 111, 114, 109,  97,  99, 105,\n",
       "        243, 110,  32, 100, 101,  32, 108, 111, 115,  32,  99, 108, 105,\n",
       "        101, 110, 116, 101, 115,  32, 100, 101,  32,  84, 101, 108, 101,\n",
       "        102, 243, 110, 105,  99,  97,  32,  97,  32, 111, 116, 114, 111,\n",
       "        115,  32, 111, 112, 101, 114,  97, 100, 111, 114, 101, 115,  46],\n",
       "       [  5,   5,  17,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "         17,   1,   1,   1,  17,   7,   7,   7,   7,   7,   7,  17,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,  17,   1,   1,  17,   5,\n",
       "          5,   5,  17,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,\n",
       "         11,  11,  11,  11,  11,  11,  11,  11,  17,  10,  10,  17,  15,\n",
       "         15,  15,  15,  15,  15,  17,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  17,   1,   1,  17,  15,  15,  15,  15,  15,  15,\n",
       "         15,  15,  15,  17,   5,   5,   5,   5,  17,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,  17,   1,   1,\n",
       "         17,   5,   5,   5,  17,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,   7,   7,   7,   7,  17,   1,   1,\n",
       "          1,  17,   5,   5,   5,   5,   5,  17,   7,   7,   7,   7,   7,\n",
       "          7,   7,  17,  10,  10,  10,  17,  15,  15,  15,  15,  15,  15,\n",
       "         15,  15,  15,  15,  17,   5,   5,  17,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,   7,  17,  13,  13,  13,  13,  17,   7,\n",
       "          7,   7,   7,   7,  17,   7,   7,   7,  17,  15,  15,  15,  15,\n",
       "         15,  17,   5,   5,  17,   7,   7,   7,   7,   7,   7,  17,   1,\n",
       "         17,   5,   5,  17,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,  17,   1,   1,  17,   5,   5,   5,  17,   7,   7,   7,\n",
       "          7,   7,   7,   7,   7,  17,   1,   1,  17,  11,  11,  11,  11,\n",
       "         11,  11,  11,  11,  11,  11,  17,   1,  17,   5,   5,   5,   5,\n",
       "          5,  17,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,  12],\n",
       "       [126, 126,   0, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203,\n",
       "          0,  63,  63,  63,   0, 174, 174, 174, 174, 174, 174,   0,  41,\n",
       "         41,  41,  41,  41,  41,  41,  41,  41,   0,  63,  63,   0, 126,\n",
       "        126, 126,   0, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174,\n",
       "        174, 174, 174, 174, 174, 174, 174, 174,   0, 219, 219,   0, 267,\n",
       "        267, 267, 267, 267, 267,   0, 219, 219, 219, 219, 219, 219, 219,\n",
       "        219, 219, 219,   0, 163, 163,   0,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   0, 126, 126, 126, 126,   0, 219, 219, 219, 219,\n",
       "        219, 219, 219, 219, 219, 219, 219, 219, 219, 219,   0,  63,  63,\n",
       "          0, 126, 126, 126,   0, 174, 174, 174, 174, 174, 174, 174, 174,\n",
       "        174, 174, 174, 174, 174, 174, 174, 174, 174, 174,   0,  63,  63,\n",
       "         63,   0, 126, 126, 126, 126, 126,   0, 229, 229, 229, 229, 229,\n",
       "        229, 229,   0, 203, 203, 203,   0,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   0, 126, 126,   0, 219, 219, 219, 219, 219,\n",
       "        219, 219, 219, 219, 219, 219,   0, 163, 163, 163, 163,   0, 146,\n",
       "        146, 146, 146, 146,   0, 146, 146, 146,   0,   1,   1,   1,   1,\n",
       "          1,   0, 126, 126,   0, 219, 219, 219, 219, 219, 219,   0,  63,\n",
       "          0, 126, 126,   0, 174, 174, 174, 174, 174, 174, 174, 174, 174,\n",
       "        174, 174,   0,  63,  63,   0, 126, 126, 126,   0, 174, 174, 174,\n",
       "        174, 174, 174, 174, 174,   0,  63,  63,   0, 174, 174, 174, 174,\n",
       "        174, 174, 174, 174, 174, 174,   0,  63,   0, 126, 126, 126, 126,\n",
       "        126,   0, 219, 219, 219, 219, 219, 219, 219, 219, 219, 219, 265]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_charseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243, 17, 267)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check max values to see if there is something weird\n",
    "max(ind_charseq[0]),max(ind_charseq[1]), max(ind_charseq[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 108 ms, total: 1.11 s\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_charseq = []\n",
    "# es_pcnl = pyconll.load_from_file(es_test)\n",
    "for seq in es_pcnl:\n",
    "    charseq = seq2charlevel(seq, deprel=True)\n",
    "#     ind_charseq = charseq2int(charseq, char2idx, UPOS_CHAR2IDX, DEPREL_CHAR2IDX)\n",
    "    list_charseq.append(charseq)\n",
    "#     list_ind_charseq.append(ind_charseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14305"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_charseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.43 s, sys: 2.74 ms, total: 1.43 s\n",
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_ind_charseq = []\n",
    "count = 0\n",
    "for charseq in list_charseq:\n",
    "    count+=1\n",
    "    ind_charseq = charseq2int(charseq, char2idx, UPOS_CHAR2IDX, DEPREL_CHAR2IDX)\n",
    "    list_ind_charseq.append(ind_charseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14305"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_ind_charseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmodels.utils.preprocess_conllu import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have a 'write' attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/projects/minibrain/predictors/sequence/text/langmodels/utils/preprocess_conllu.py\u001b[0m in \u001b[0;36mprocess_all\u001b[0;34m(flist, utf8_char2int_codebook, return_data, save_processed)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mfout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msave_processed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mfout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.conllu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-charsec_code.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_conllu_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutf8_char2int_codebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUPOS_CHAR2IDX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEPREL_CHAR2IDX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/minibrain/predictors/sequence/text/langmodels/utils/preprocess_conllu.py\u001b[0m in \u001b[0;36mprocess_conllu_file\u001b[0;34m(fname, char2int_codebook, upos2int, deprel2int, deprel, save_to)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconll2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar2int_codebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupos2int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeprel2int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeprel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have a 'write' attribute"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# len(conllu_train), len(conllu_test), len(conllu_dev)\n",
    "train_data = process_all(conllu_train, char2idx, return_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_data = process_all(conllu_test, char2idx, return_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dev_data = process_all(conllu_dev, char2idx, return_data=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
