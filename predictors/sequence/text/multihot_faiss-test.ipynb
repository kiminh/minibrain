{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS for UTF-8 Multihot Decoding\n",
    "\n",
    "This notebook intends to learn how to use faiss and check if it is usefull to handle the decoding (cosine similarity ?) of embedding vectors into code indices of the codebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n",
      "Loading faiss.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "import faiss\n",
    "from utf8_encoder import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-computed utf-8 codes and codebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from langmodels.utf8codec import *\n",
    "from langmodels import utf8codec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utf8codebook = load_obj(\"utf8-codes/multihot64short-embeds\")\n",
    "# idx2char = load_obj(\"utf8-codes/multihot64short-idx2char\")\n",
    "# char2idx = load_obj(\"utf8-codes/multihot64short-char2idx\")\n",
    "\n",
    "# utf8codebook = load_obj(\"utf8-codes/utf8_code_matrix_2seg.npy\")\n",
    "utf8codebook = np.load(\"utf8-codes/utf8_code_matrix_2seg.npy\").astype(\"float32\")\n",
    "idx2char = load_obj(\"utf8-codes/num2txt_2seg.pkl\")\n",
    "char2idx = load_obj(\"utf8-codes/txt2num_2seg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_matrix, txt2code, code2txt, txt2num, num2txt = utf8codec._load_codebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utf8codebook.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d=64\n",
    "d=324\n",
    "indexl2 = faiss.IndexFlatL2(d)\n",
    "# faiss.index_factory()  # <- this function for index creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the documentation, maybe will be faster for decoding to use an IVF (Inverse Vector File) index type\n",
    "\n",
    "Also it might be good to have it in CPU as the GPU operations might not be needed for training or testing, the decoding can be done just when needed to create a text reconstruction for user visualization. Taking into account that I have much more RAM tahn GPU-RAM (a factor of 8) this would be a nice thing.\n",
    "\n",
    "IVF indices need training\n",
    "\n",
    "Product Quantization (PQ) could be used and might be good, this is because the input are binary elements, and the outputs of the network are float32. If quantized, the most important decimals of the vector output might be good enough to recognize similarity (just an idea, I don't know if this will be true).\n",
    "\n",
    "Might need *OPQ rotation* and|or *RemapDimensionsTransform* (from documentation) to improve the PQ coding (transformations can be trained) and *rq = faiss.IndexRefineFlat(q)* to refine ranking once pre-ranked\n",
    "\n",
    "From documentation:\n",
    "\n",
    "    \"The IVFFlat is often the fastest option, so the PQ variants are useful if memory is limited.\"\n",
    "\n",
    "\n",
    "\n",
    "The other nice thing of this is that we can compute the closest K nearest neighbours, which can give several benefits for decoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could try to do iterative decoding, several passes for the same input, each giving a result, this result passing it again, and again, this might lead to some nice surprises (estabilizing the result when there are doubts or different options??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1984, 324)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utf8codebook.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexl2.add(utf8codebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what I do is encode all the codebook and decode it with the overfit-pre-trained Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "utf8embedd = torch.load(\"trained_models/utf8Autoencoder_embedding_2segments.pth\")\n",
    "utf8decod = torch.load(\"trained_models/utf8Autoencoder_decoder_2segments.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I get the dataset and the codes for each elements to test and check all the codes and see the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "utf8embedd = utf8embedd.to(device)\n",
    "utf8decod = utf8decod.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utf8embedd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utf8decod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data to encode and decode\n",
    "chars, idxs = list(char2idx.keys()), list(char2idx.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(zip(chars,idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.stack(idxs)\n",
    "tindices = torch.from_numpy(indices).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(indices)[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968,\n",
       "        1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980,\n",
       "        1981, 1982, 1983,    2,    3,   15], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tindices[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1987])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tindices = tindices.unsqueeze(0)\n",
    "tindices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_multihot, enc32 = utf8embedd(tindices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = utf8decod(enc32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdec = dec > 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False,  ..., False, False, False],\n",
       "         [ True, False, False,  ..., False, False, False],\n",
       "         [ True, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [ True, False, False,  ..., False, False, False],\n",
       "         [ True, False, False,  ..., False, False, False],\n",
       "         [ True, False, False,  ..., False, False, False]]], device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = bdec.squeeze() == enc_multihot.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1987, 324])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "npdec = dec.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npdec.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=2\n",
    "D,I = indexl2.search(npdec[0], k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1987, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "I0 = I[:,0] \n",
    "errvals = np.roll(I0,1) - I0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errs = [i for i in errvals if abs(i) != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(len(idx2char.keys())):\n",
    "    o = idx2char[i]\n",
    "    d = idx2char[I0[i]]\n",
    "    if o != d:\n",
    "        res.append((i,o,d))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, '\\x04', 'E'),\n",
       " (11, '\\x0b', '\\x0e'),\n",
       " (22, '\\x16', 'x'),\n",
       " (32, ' ', '+'),\n",
       " (38, '&', 'z'),\n",
       " (48, '0', 'z'),\n",
       " (50, '2', 'x'),\n",
       " (65, 'A', 'x'),\n",
       " (67, 'C', 'U'),\n",
       " (70, 'F', '+'),\n",
       " (81, 'Q', '+'),\n",
       " (82, 'R', 'x'),\n",
       " (98, 'b', 'E'),\n",
       " (100, 'd', '+'),\n",
       " (121, 'y', 'z'),\n",
       " (165, '¥', '\\x86'),\n",
       " (171, '«', '\\x86'),\n",
       " (180, '´', '\\x86'),\n",
       " (229, 'å', 'î'),\n",
       " (235, 'ë', 'î'),\n",
       " (244, 'ô', 'î'),\n",
       " (293, 'ĥ', 'ċ'),\n",
       " (299, 'ī', 'ċ'),\n",
       " (308, 'Ĵ', 'ċ'),\n",
       " (357, 'ť', 'Œ'),\n",
       " (363, 'ū', 'Œ'),\n",
       " (372, 'Ŵ', 'ł'),\n",
       " (421, 'ƥ', 'Ɓ'),\n",
       " (427, 'ƫ', 'Ɓ'),\n",
       " (436, 'ƴ', 'Ɓ'),\n",
       " (485, 'ǥ', 'ǋ'),\n",
       " (491, 'ǫ', 'ǋ'),\n",
       " (500, 'Ǵ', 'ǋ'),\n",
       " (549, 'ȥ', 'ȋ'),\n",
       " (555, 'ȫ', 'ȋ'),\n",
       " (564, 'ȴ', 'ȋ'),\n",
       " (613, 'ɥ', 'ɂ'),\n",
       " (619, 'ɫ', 'ɂ'),\n",
       " (628, 'ɴ', 'ɂ'),\n",
       " (677, 'ʥ', 'ʋ'),\n",
       " (683, 'ʫ', 'ʋ'),\n",
       " (692, 'ʴ', 'ʋ'),\n",
       " (741, '˥', '˕'),\n",
       " (747, '˫', '˕'),\n",
       " (756, '˴', '˕'),\n",
       " (805, '̥', '́'),\n",
       " (811, '̫', '́'),\n",
       " (820, '̴', '́'),\n",
       " (869, 'ͥ', '\\u0379'),\n",
       " (875, 'ͫ', '\\u0379'),\n",
       " (884, 'ʹ', '\\u0379'),\n",
       " (933, 'Υ', '\\u038b'),\n",
       " (939, 'Ϋ', '\\u038b'),\n",
       " (948, 'δ', '\\u038b'),\n",
       " (997, 'ϥ', 'ϋ'),\n",
       " (1003, 'ϫ', 'ϋ'),\n",
       " (1012, 'ϴ', 'ϋ'),\n",
       " (1061, 'Х', 'Ћ'),\n",
       " (1067, 'Ы', 'Ћ'),\n",
       " (1076, 'д', 'Ћ'),\n",
       " (1125, 'ѥ', 'Ѻ'),\n",
       " (1131, 'ѫ', 'ѳ'),\n",
       " (1140, 'Ѵ', 'ѻ'),\n",
       " (1189, 'ҥ', 'ҋ'),\n",
       " (1195, 'ҫ', 'ҋ'),\n",
       " (1204, 'Ҵ', 'ҋ'),\n",
       " (1253, 'ӥ', 'Ӌ'),\n",
       " (1259, 'ӫ', 'Ӌ'),\n",
       " (1268, 'Ӵ', 'Ӌ'),\n",
       " (1317, 'ԥ', 'Ԣ'),\n",
       " (1323, 'ԫ', 'Ԣ'),\n",
       " (1332, 'Դ', 'Ԣ'),\n",
       " (1381, 'ե', 'Ջ'),\n",
       " (1387, 'ի', 'Ջ'),\n",
       " (1396, 'մ', 'Ջ'),\n",
       " (1445, '֥', '\\u058b'),\n",
       " (1451, '֫', '\\u058b'),\n",
       " (1460, 'ִ', '\\u058b'),\n",
       " (1509, 'ץ', 'ׁ'),\n",
       " (1515, '\\u05eb', 'ׁ'),\n",
       " (1524, '״', 'ׂ'),\n",
       " (1573, 'إ', '\\u0602'),\n",
       " (1579, 'ث', 'ئ'),\n",
       " (1588, 'ش', 'س'),\n",
       " (1637, '٥', 'ً'),\n",
       " (1643, '٫', 'ً'),\n",
       " (1652, 'ٴ', 'ً'),\n",
       " (1701, 'ڥ', 'ڼ'),\n",
       " (1707, 'ګ', 'ڼ'),\n",
       " (1716, 'ڴ', 'ڼ'),\n",
       " (1765, 'ۥ', 'ۂ'),\n",
       " (1771, '۫', 'ۂ'),\n",
       " (1780, '۴', 'ۂ'),\n",
       " (1829, 'ܥ', '܇'),\n",
       " (1835, 'ܫ', 'ܶ'),\n",
       " (1844, 'ܴ', 'ܾ'),\n",
       " (1893, 'ݥ', '݁'),\n",
       " (1899, 'ݫ', '݁'),\n",
       " (1908, 'ݴ', '݁'),\n",
       " (1957, 'ޥ', 'ދ'),\n",
       " (1963, 'ޫ', 'ދ'),\n",
       " (1972, '\\u07b4', 'ދ')]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 102 errors in the decoding on the first choice, anything more than zero is a problem so I have to go back and try to train a new encoder with maybe more dimensions to see what happens.\n",
    "\n",
    "Anywais I stil have to find a way to make a ZERO error on the overfitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0, 61],\n",
       "        [ 1, 84],\n",
       "        [ 2, 33],\n",
       "        ...,\n",
       "        [ 2, 33],\n",
       "        [ 3, 49],\n",
       "        [15, 20]]), array([[0.01641178, 2.0125747 ],\n",
       "        [0.01641798, 2.0115097 ],\n",
       "        [0.01641083, 2.0119002 ],\n",
       "        ...,\n",
       "        [0.01641083, 2.0119002 ],\n",
       "        [0.01641297, 2.0119598 ],\n",
       "        [0.01641273, 2.0115497 ]], dtype=float32))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I,D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5728, device='cuda:0'),\n",
       " tensor(102, device='cuda:0'),\n",
       " tensor(5830., device='cuda:0'),\n",
       " 5824.0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(bdec), torch.sum(~cmp), torch.sum(enc_multihot), np.sum(utf8codebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the $ sum  cmp== 102 $  in the comparison and the different sum in the codebook and the enc_multihot seem to show some mismatch, which I have to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1987, 324])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1987, 324])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_multihot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1987, 324]),\n",
       " torch.Size([1, 1987, 32]),\n",
       " torch.Size([1, 1987, 324]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_multihot.shape, enc32.shape, dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what I should do is create several indices and test the decoding in all of those\n",
    "# for performance to see which one is better in precision, memory usage and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the GPU\n",
    "res = faiss.StandardGpuResources()  # use a single GPU\n",
    "gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, indexl2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpu_index_flat.ntotal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index seems quite big here\n",
    "Mem usage of the GPU is 3028 MiB with the index in GPU\n",
    "\n",
    "Mem usage of the GPU without the index: 1573MiB\n",
    "\n",
    "So total memory usage of the index is: 1455 MiB for the IndexFlatL2 on the entire utf8 codebook coded in vectors of dim 64 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1455"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3028 - 1573"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
