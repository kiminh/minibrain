{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Tests for Part Of Speech tagging\n",
    "\n",
    "This notebook is dedicated to start working with the PoS dataset already pre-processed and the column networks that I'm creating.\n",
    "\n",
    "The network will be constructed from small parts, each will be trained on top of the previous one, adding a new column and decoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/leo/venv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Loading faiss with AVX2 support.\n",
      "Loading faiss.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from langmodels.models import *\n",
    "import langmodels.utf8codec as utf8codec\n",
    "from langmodels.utils.tools import *\n",
    "from langmodels.utils.preprocess_conllu import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the embeddings first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the codebook and all the dictionaries mapping the data\n",
    "# utf8codes, txt2code, code2txt, txt2num, num2txt = utf8codec._load_codebook()\n",
    "utf8codes = np.load(\"./utf8-codes/utf8_codebook_overfit_matrix_2seg_dim64.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utf8codes = utf8codes.reshape(1987,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Conv1DPoS(utf8codes)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1949540"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the original network 11266152 parameters, I have cut the number of features and dimensions to make it smaller\n",
    "\n",
    "for nlayers = 5 of dim 5 is 6912424 and 6846888 trainable\n",
    "\n",
    "for the following Conv1DPartOfSpeech the number of parameters is: 2161960 where 2096424 are trainable\n",
    "\n",
    "    nchannels_in=[64, 128, 256, 512, 256],\n",
    "    nchannels_out=[128, 256, 512, 256, 96],\n",
    "    kernels=[3, 3, 3, 3, 3],\n",
    "    nlayers=[6, 6, 4, 4, 3],\n",
    "    groups=[1, 4, 8, 4, 1],\n",
    "    \n",
    "And LinearUposDeprelDecoder params are:\n",
    "\n",
    "    lin_in_dim=96, \n",
    "    lin_hidd_dim=768,\n",
    "    upos_dim=18, \n",
    "    deprel_dim=278,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1884004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets are the one that are heavy, so I'll just load them and check what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = \"/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/traindev_np_batches_779000x3x1024_uint16.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.load(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779000, 3, 1024)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint16')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta_train_txt = data_train[:,0,:]\n",
    "dta_train_upos = data_train[:,1,:]\n",
    "dta_train_deprel = data_train[:,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.from_numpy(dta_train_txt[:50].astype(\"int64\")).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txtcode, positions, latent, dec = net(x)\n",
    "# last_latent = latent[-1]\n",
    "# upos, deprel = dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txtcode.shape, positions.shape, last_latent.shape, upos.shape, #  deprel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = torch.cat([upos,deprel], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upos and deprel data are given by indices, this keeps memory as low as possible, but they need to be encoded\n",
    "upos_eye = torch.eye(len(UPOS))\n",
    "deprel_eye = torch.eye(len(DEPREL))\n",
    "with torch.no_grad():\n",
    "    upos_emb = nn.Embedding(*upos_eye.shape)\n",
    "    upos_emb.weight.data.copy_(upos_eye)\n",
    "    upos_emb = upos_emb.to(device)\n",
    "\n",
    "    deprel_emb = nn.Embedding(*deprel_eye.shape)\n",
    "    deprel_emb.weight.data.copy_(deprel_eye)\n",
    "    deprel_emb.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "def chunks(data, n, dim=0):\n",
    "    \"\"\"Yield successive n-sized chunks from data by the dimension dim\"\"\"\n",
    "    for i in range(0, data.shape[dim], n):\n",
    "        yield data_train[i:i + n,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(upos, deprel, target_upos, target_deprel):\n",
    "\n",
    "    # TODO check a more sofisticated loss function, for the moment only the sum to see if it runs\n",
    "    # the issue is that upos is easier than deprel (18 vs 278 classes)\n",
    "#     upos_loss = F.mse_loss(upos, target_upos)\n",
    "#     deprel_loss = F.mse_loss(deprel, target_deprel)\n",
    "    # issue with the size of target and tensors for cross_entropy ... I don't understand\n",
    "#     upos_loss = F.cross_entropy(upos, target_upos)\n",
    "#     deprel_loss = F.cross_entropy(deprel, target_deprel)\n",
    "#     print(upos.shape, target_upos.shape, deprel.shape, target_deprel.shape)\n",
    "    upos_loss = F.nll_loss(upos, target_upos)\n",
    "    deprel_loss = F.nll_loss(deprel, target_deprel)\n",
    "#     upos_loss = F.kl_div(upos, target_upos)\n",
    "#     deprel_loss = F.kl_div(deprel, target_deprel)\n",
    "    loss = upos_loss + deprel_loss\n",
    "#     loss = F.kl_div(torch.cat([upos, deprel], dim=-1).contiguous(), torch.cat([target_upos, target_deprel], dim=-1).contiguous())\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indata = torch.from_numpy(data_train[-2:,0,:].astype(\"int64\")).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# testing tensorboard add_graph to see if the network graph is drawn correctly ;)\n",
    "# indata = torch.from_numpy(data_train[-2:,0,:].astype(\"int64\")).to(device)\n",
    "# writer.add_graph(net, indata)\n",
    "# Kernel dies when I do this ... so ... :O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_function, batches, epoch, ndatapoints, device, log_interval=100):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "#     batch_loss = []\n",
    "    batch_idx = 1\n",
    "    for b_data in batches:\n",
    "        torch.cuda.empty_cache()  # make sure the cache is emptied to begin the nexxt batch\n",
    "        b_train = torch.from_numpy(b_data[:,0,:].astype(\"int64\")).squeeze().to(device).long()\n",
    "        b_upos = torch.from_numpy(b_data[:,1,:].astype(\"int64\")).squeeze().to(device).long()\n",
    "#         b_deprel = torch.from_numpy(b_data[:,2,:].astype(\"int64\")).squeeze().to(device).long()\n",
    "#         tensor_data = torch.from_numpy(bdata).to(device).long()  #.double()  #.float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        txtcode, positions, latent, dec = model(b_train)\n",
    "        last_latent = latent[-1]\n",
    "        upos, deprel = dec\n",
    "#         print(emb.shape,emb.dtype, res.shape, res.dtype)\n",
    "#         print(upos.shape, b_upos.shape)\n",
    "#         loss = loss_function(upos, deprel, upos_emb(b_upos), deprel_emb(b_deprel))\n",
    "#         loss = loss_function(upos, deprel, b_upos, b_deprel)\n",
    "        # Untill I make it work, work only with the UPOS PoS as it will be faster MUCH faster\n",
    "#         loss = F.kl_div(upos, upos_emb(b_upos), reduction=\"batchmean\")\n",
    "        loss = F.nll_loss(upos.view([-1,18]),b_upos.view([-1]))\n",
    "#         loss = F.cross_entropy(upos.view([-1,18]),b_upos.view([-1]))\n",
    "#         loss = F.cross_entropy(upos,b_upos)\n",
    "#         loss = F.mse_loss(upos, upos_emb(b_upos))\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.data.item()  # [0]\n",
    "        writer.add_scalar(\"Loss/train\", loss.data.item(), global_step=epoch*batch_idx)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Timestamp {} Train Epoch: {} [{}/{} ]\\tLoss: {:.6f}'.format(\n",
    "                datetime.now(),\n",
    "                epoch, batch_idx , (ndatapoints//len(b_data)),\n",
    "                loss.data.item() / b_data.shape[0]))\n",
    "#             batch_loss.append(loss)\n",
    "        batch_idx += 1\n",
    "        del(b_train)\n",
    "        del(b_upos)\n",
    "#         del(b_deprel)\n",
    "        torch.cuda.empty_cache()\n",
    "    writer.add_scalar(\"EpochLoss/train\", train_loss / batch_idx, epoch)\n",
    "    print('====> Timestamp {} Epoch: {} Average loss: {:.8f}'.format(datetime.now(), epoch, train_loss / ndatapoints))\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load testing data ALL the training data\n",
    "base_dir = \"/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4\"\n",
    "# get all file paths for testing\n",
    "all_fnames = get_all_files_recurse(base_dir)\n",
    "fnames = [f for f in all_fnames if \"test-charse\" in f and f.endswith(\".npy\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all test files \n",
    "test_data = []\n",
    "for f in fnames:\n",
    "    data = np.load(f)\n",
    "    lang_name = path_leaf(f).split(\"-ud\")[0]\n",
    "    test_data.append((lang_name, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loss_function, test_data, epoch, device, max_data=100):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for lang, d in test_data:\n",
    "        torch.cuda.empty_cache()  # make sure the cache is emptied to begin the nexxt batch\n",
    "        b_test = torch.from_numpy(d[:max_data,0,:].astype(\"int64\")).squeeze().to(device).long()\n",
    "        b_upos = torch.from_numpy(d[:max_data,1,:].astype(\"int64\")).squeeze().to(device).long()\n",
    "#         b_deprel = torch.from_numpy(d[:,2,:].astype(\"int64\")).squeeze().to(device).long()\n",
    "        _, _, _, dec = model(b_test)\n",
    "#         last_latent = latent[-1]\n",
    "        upos, _ = dec\n",
    "        loss = loss_function(upos.view([-1,18]),b_upos.view([-1]))\n",
    "#         loss =  loss_function(res, tensor_data).data.item()  # [0]\n",
    "        test_loss += loss.data.item()\n",
    "        writer.add_scalar(\"LangLoss/test/\"+lang, loss.data.item(), global_step=epoch)\n",
    "        del(b_test)\n",
    "        del(b_upos)\n",
    "        torch.cuda.empty_cache()\n",
    "    test_loss /= len(test_data)  # although this is not faire as different languages give different results\n",
    "    writer.add_scalar(\"EpochLangLoss/test/\", test_loss, global_step=epoch)\n",
    "    print('epoch: {}====> Test set loss: {:.8f}'.format(epoch, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload model from saved state:\n",
    "# net.network.load_model(\"./trained_models/conv1dcol\", \"conv1dcol_kl-div+1000batches-mse-loss_epoch-3_001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-6, weight_decay=0, amsgrad=False )\n",
    "# optimizer = torch.optim.AdamW(model.parameters())\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((779000, 3, 1024), 15580)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_train.shape[0]//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 10000\n",
    "batch_size = 50\n",
    "# data = data_train[-1000*batch_size:,:,:]  # just for the trials, use the last 1000 batches only\n",
    "data = data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(779000, 3, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = chunks(data, epoch_size, dim=0)\n",
    "# batches = chunks(data, batch_size, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# epoch_count = 0\n",
    "# test(model, loss_function, test_data, epoch_count, device, max_data=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp 2019-11-27 18:32:16.779965 Train Epoch: 1 [10/200 ]\tLoss: 0.053510\n",
      "Timestamp 2019-11-27 18:32:19.232719 Train Epoch: 1 [20/200 ]\tLoss: 0.033693\n",
      "Timestamp 2019-11-27 18:32:21.648737 Train Epoch: 1 [30/200 ]\tLoss: 0.016544\n",
      "Timestamp 2019-11-27 18:32:24.090981 Train Epoch: 1 [40/200 ]\tLoss: 0.009193\n",
      "Timestamp 2019-11-27 18:32:26.545630 Train Epoch: 1 [50/200 ]\tLoss: 0.006553\n",
      "Timestamp 2019-11-27 18:32:28.921684 Train Epoch: 1 [60/200 ]\tLoss: 0.006662\n",
      "Timestamp 2019-11-27 18:32:31.285176 Train Epoch: 1 [70/200 ]\tLoss: 0.006000\n",
      "Timestamp 2019-11-27 18:32:33.650147 Train Epoch: 1 [80/200 ]\tLoss: 0.005756\n",
      "Timestamp 2019-11-27 18:32:36.014267 Train Epoch: 1 [90/200 ]\tLoss: 0.005029\n",
      "Timestamp 2019-11-27 18:32:38.388077 Train Epoch: 1 [100/200 ]\tLoss: 0.005981\n",
      "Timestamp 2019-11-27 18:32:40.753877 Train Epoch: 1 [110/200 ]\tLoss: 0.004569\n",
      "Timestamp 2019-11-27 18:32:43.120740 Train Epoch: 1 [120/200 ]\tLoss: 0.004130\n",
      "Timestamp 2019-11-27 18:32:45.476898 Train Epoch: 1 [130/200 ]\tLoss: 0.005601\n",
      "Timestamp 2019-11-27 18:32:47.839648 Train Epoch: 1 [140/200 ]\tLoss: 0.003964\n",
      "Timestamp 2019-11-27 18:32:50.206956 Train Epoch: 1 [150/200 ]\tLoss: 0.005221\n",
      "Timestamp 2019-11-27 18:32:52.580589 Train Epoch: 1 [160/200 ]\tLoss: 0.005093\n",
      "Timestamp 2019-11-27 18:32:54.941417 Train Epoch: 1 [170/200 ]\tLoss: 0.004314\n",
      "Timestamp 2019-11-27 18:32:57.304943 Train Epoch: 1 [180/200 ]\tLoss: 0.004115\n",
      "Timestamp 2019-11-27 18:32:59.666694 Train Epoch: 1 [190/200 ]\tLoss: 0.004339\n",
      "Timestamp 2019-11-27 18:33:02.026431 Train Epoch: 1 [200/200 ]\tLoss: 0.004875\n",
      "====> Timestamp 2019-11-27 18:33:02.069258 Epoch: 1 Average loss: 0.01065826\n",
      "epoch: 1====> Test set loss: 0.20863459\n",
      "Timestamp 2019-11-27 18:33:15.719249 Train Epoch: 2 [10/200 ]\tLoss: 0.003686\n",
      "Timestamp 2019-11-27 18:33:18.076477 Train Epoch: 2 [20/200 ]\tLoss: 0.003865\n",
      "Timestamp 2019-11-27 18:33:20.437281 Train Epoch: 2 [30/200 ]\tLoss: 0.004199\n",
      "Timestamp 2019-11-27 18:33:22.822702 Train Epoch: 2 [40/200 ]\tLoss: 0.004409\n",
      "Timestamp 2019-11-27 18:33:25.173747 Train Epoch: 2 [50/200 ]\tLoss: 0.003993\n",
      "Timestamp 2019-11-27 18:33:27.534750 Train Epoch: 2 [60/200 ]\tLoss: 0.004705\n",
      "Timestamp 2019-11-27 18:33:29.895199 Train Epoch: 2 [70/200 ]\tLoss: 0.004284\n",
      "Timestamp 2019-11-27 18:33:32.260125 Train Epoch: 2 [80/200 ]\tLoss: 0.004333\n",
      "Timestamp 2019-11-27 18:33:34.623535 Train Epoch: 2 [90/200 ]\tLoss: 0.003926\n",
      "Timestamp 2019-11-27 18:33:36.978890 Train Epoch: 2 [100/200 ]\tLoss: 0.004712\n",
      "Timestamp 2019-11-27 18:33:39.342122 Train Epoch: 2 [110/200 ]\tLoss: 0.003795\n",
      "Timestamp 2019-11-27 18:33:41.695279 Train Epoch: 2 [120/200 ]\tLoss: 0.003615\n",
      "Timestamp 2019-11-27 18:33:44.048910 Train Epoch: 2 [130/200 ]\tLoss: 0.004841\n",
      "Timestamp 2019-11-27 18:33:46.406692 Train Epoch: 2 [140/200 ]\tLoss: 0.003722\n",
      "Timestamp 2019-11-27 18:33:48.777878 Train Epoch: 2 [150/200 ]\tLoss: 0.004874\n",
      "Timestamp 2019-11-27 18:33:51.135019 Train Epoch: 2 [160/200 ]\tLoss: 0.004763\n",
      "Timestamp 2019-11-27 18:33:53.524983 Train Epoch: 2 [170/200 ]\tLoss: 0.004180\n",
      "Timestamp 2019-11-27 18:33:55.883457 Train Epoch: 2 [180/200 ]\tLoss: 0.003897\n",
      "Timestamp 2019-11-27 18:33:58.243925 Train Epoch: 2 [190/200 ]\tLoss: 0.004233\n",
      "Timestamp 2019-11-27 18:34:00.610588 Train Epoch: 2 [200/200 ]\tLoss: 0.004770\n",
      "====> Timestamp 2019-11-27 18:34:00.656106 Epoch: 2 Average loss: 0.00429803\n",
      "epoch: 2====> Test set loss: 0.20155731\n",
      "Timestamp 2019-11-27 18:34:14.328544 Train Epoch: 3 [10/200 ]\tLoss: 0.003563\n",
      "Timestamp 2019-11-27 18:34:16.708726 Train Epoch: 3 [20/200 ]\tLoss: 0.003746\n",
      "Timestamp 2019-11-27 18:34:19.077769 Train Epoch: 3 [30/200 ]\tLoss: 0.004079\n",
      "Timestamp 2019-11-27 18:34:21.452691 Train Epoch: 3 [40/200 ]\tLoss: 0.004244\n",
      "Timestamp 2019-11-27 18:34:23.838379 Train Epoch: 3 [50/200 ]\tLoss: 0.003812\n",
      "Timestamp 2019-11-27 18:34:26.205925 Train Epoch: 3 [60/200 ]\tLoss: 0.004440\n",
      "Timestamp 2019-11-27 18:34:28.573252 Train Epoch: 3 [70/200 ]\tLoss: 0.003990\n",
      "Timestamp 2019-11-27 18:34:30.947004 Train Epoch: 3 [80/200 ]\tLoss: 0.004006\n",
      "Timestamp 2019-11-27 18:34:33.319513 Train Epoch: 3 [90/200 ]\tLoss: 0.003566\n",
      "Timestamp 2019-11-27 18:34:35.690888 Train Epoch: 3 [100/200 ]\tLoss: 0.004343\n",
      "Timestamp 2019-11-27 18:34:38.059332 Train Epoch: 3 [110/200 ]\tLoss: 0.003505\n",
      "Timestamp 2019-11-27 18:34:40.433933 Train Epoch: 3 [120/200 ]\tLoss: 0.003212\n",
      "Timestamp 2019-11-27 18:34:42.804904 Train Epoch: 3 [130/200 ]\tLoss: 0.004267\n",
      "Timestamp 2019-11-27 18:34:45.164051 Train Epoch: 3 [140/200 ]\tLoss: 0.003269\n",
      "Timestamp 2019-11-27 18:34:47.515646 Train Epoch: 3 [150/200 ]\tLoss: 0.004069\n",
      "Timestamp 2019-11-27 18:34:49.882082 Train Epoch: 3 [160/200 ]\tLoss: 0.004114\n",
      "Timestamp 2019-11-27 18:34:52.264704 Train Epoch: 3 [170/200 ]\tLoss: 0.003466\n",
      "Timestamp 2019-11-27 18:34:54.636431 Train Epoch: 3 [180/200 ]\tLoss: 0.003398\n",
      "Timestamp 2019-11-27 18:34:56.993375 Train Epoch: 3 [190/200 ]\tLoss: 0.003475\n",
      "Timestamp 2019-11-27 18:34:59.362844 Train Epoch: 3 [200/200 ]\tLoss: 0.003898\n",
      "====> Timestamp 2019-11-27 18:34:59.405750 Epoch: 3 Average loss: 0.00389922\n",
      "epoch: 3====> Test set loss: 0.17863206\n",
      "Timestamp 2019-11-27 18:35:13.245248 Train Epoch: 4 [10/200 ]\tLoss: 0.002789\n",
      "Timestamp 2019-11-27 18:35:15.625621 Train Epoch: 4 [20/200 ]\tLoss: 0.003030\n",
      "Timestamp 2019-11-27 18:35:17.989281 Train Epoch: 4 [30/200 ]\tLoss: 0.003243\n",
      "Timestamp 2019-11-27 18:35:20.359343 Train Epoch: 4 [40/200 ]\tLoss: 0.003542\n",
      "Timestamp 2019-11-27 18:35:22.762896 Train Epoch: 4 [50/200 ]\tLoss: 0.003180\n",
      "Timestamp 2019-11-27 18:35:25.136526 Train Epoch: 4 [60/200 ]\tLoss: 0.003633\n",
      "Timestamp 2019-11-27 18:35:27.509479 Train Epoch: 4 [70/200 ]\tLoss: 0.003649\n",
      "Timestamp 2019-11-27 18:35:29.873558 Train Epoch: 4 [80/200 ]\tLoss: 0.003387\n",
      "Timestamp 2019-11-27 18:35:32.239228 Train Epoch: 4 [90/200 ]\tLoss: 0.002976\n",
      "Timestamp 2019-11-27 18:35:34.601017 Train Epoch: 4 [100/200 ]\tLoss: 0.003733\n",
      "Timestamp 2019-11-27 18:35:36.961774 Train Epoch: 4 [110/200 ]\tLoss: 0.002965\n",
      "Timestamp 2019-11-27 18:35:39.328746 Train Epoch: 4 [120/200 ]\tLoss: 0.002784\n",
      "Timestamp 2019-11-27 18:35:41.692898 Train Epoch: 4 [130/200 ]\tLoss: 0.003754\n",
      "Timestamp 2019-11-27 18:35:44.055719 Train Epoch: 4 [140/200 ]\tLoss: 0.002916\n",
      "Timestamp 2019-11-27 18:35:46.414920 Train Epoch: 4 [150/200 ]\tLoss: 0.003646\n",
      "Timestamp 2019-11-27 18:35:48.768757 Train Epoch: 4 [160/200 ]\tLoss: 0.003789\n",
      "Timestamp 2019-11-27 18:35:51.131501 Train Epoch: 4 [170/200 ]\tLoss: 0.003179\n",
      "Timestamp 2019-11-27 18:35:53.518535 Train Epoch: 4 [180/200 ]\tLoss: 0.003172\n",
      "Timestamp 2019-11-27 18:35:55.880350 Train Epoch: 4 [190/200 ]\tLoss: 0.003276\n",
      "Timestamp 2019-11-27 18:35:58.242108 Train Epoch: 4 [200/200 ]\tLoss: 0.003623\n",
      "====> Timestamp 2019-11-27 18:35:58.285438 Epoch: 4 Average loss: 0.00338801\n",
      "epoch: 4====> Test set loss: 0.16787767\n",
      "Timestamp 2019-11-27 18:36:12.050584 Train Epoch: 5 [10/200 ]\tLoss: 0.002604\n",
      "Timestamp 2019-11-27 18:36:14.408617 Train Epoch: 5 [20/200 ]\tLoss: 0.002840\n",
      "Timestamp 2019-11-27 18:36:16.767940 Train Epoch: 5 [30/200 ]\tLoss: 0.003034\n",
      "Timestamp 2019-11-27 18:36:19.134555 Train Epoch: 5 [40/200 ]\tLoss: 0.003408\n",
      "Timestamp 2019-11-27 18:36:21.514754 Train Epoch: 5 [50/200 ]\tLoss: 0.003035\n",
      "Timestamp 2019-11-27 18:36:23.904190 Train Epoch: 5 [60/200 ]\tLoss: 0.003449\n",
      "Timestamp 2019-11-27 18:36:26.268632 Train Epoch: 5 [70/200 ]\tLoss: 0.003480\n",
      "Timestamp 2019-11-27 18:36:28.635052 Train Epoch: 5 [80/200 ]\tLoss: 0.003240\n",
      "Timestamp 2019-11-27 18:36:31.004883 Train Epoch: 5 [90/200 ]\tLoss: 0.002844\n",
      "Timestamp 2019-11-27 18:36:33.381690 Train Epoch: 5 [100/200 ]\tLoss: 0.003573\n",
      "Timestamp 2019-11-27 18:36:35.754177 Train Epoch: 5 [110/200 ]\tLoss: 0.002832\n",
      "Timestamp 2019-11-27 18:36:38.123838 Train Epoch: 5 [120/200 ]\tLoss: 0.002645\n",
      "Timestamp 2019-11-27 18:36:40.498718 Train Epoch: 5 [130/200 ]\tLoss: 0.003619\n",
      "Timestamp 2019-11-27 18:36:42.872860 Train Epoch: 5 [140/200 ]\tLoss: 0.002813\n",
      "Timestamp 2019-11-27 18:36:45.241321 Train Epoch: 5 [150/200 ]\tLoss: 0.003504\n",
      "Timestamp 2019-11-27 18:36:47.607851 Train Epoch: 5 [160/200 ]\tLoss: 0.003673\n",
      "Timestamp 2019-11-27 18:36:49.990006 Train Epoch: 5 [170/200 ]\tLoss: 0.003065\n",
      "Timestamp 2019-11-27 18:36:52.377532 Train Epoch: 5 [180/200 ]\tLoss: 0.003070\n",
      "Timestamp 2019-11-27 18:36:54.752957 Train Epoch: 5 [190/200 ]\tLoss: 0.003171\n",
      "Timestamp 2019-11-27 18:36:57.140347 Train Epoch: 5 [200/200 ]\tLoss: 0.003508\n",
      "====> Timestamp 2019-11-27 18:36:57.184727 Epoch: 5 Average loss: 0.00323924\n",
      "epoch: 5====> Test set loss: 0.16464169\n",
      "Timestamp 2019-11-27 18:37:10.886304 Train Epoch: 6 [10/200 ]\tLoss: 0.002549\n",
      "Timestamp 2019-11-27 18:37:13.253560 Train Epoch: 6 [20/200 ]\tLoss: 0.002749\n",
      "Timestamp 2019-11-27 18:37:15.618385 Train Epoch: 6 [30/200 ]\tLoss: 0.002943\n",
      "Timestamp 2019-11-27 18:37:17.990843 Train Epoch: 6 [40/200 ]\tLoss: 0.003333\n",
      "Timestamp 2019-11-27 18:37:20.358433 Train Epoch: 6 [50/200 ]\tLoss: 0.002968\n",
      "Timestamp 2019-11-27 18:37:22.747388 Train Epoch: 6 [60/200 ]\tLoss: 0.003354\n",
      "Timestamp 2019-11-27 18:37:25.112093 Train Epoch: 6 [70/200 ]\tLoss: 0.003385\n",
      "Timestamp 2019-11-27 18:37:27.475845 Train Epoch: 6 [80/200 ]\tLoss: 0.003140\n",
      "Timestamp 2019-11-27 18:37:29.851189 Train Epoch: 6 [90/200 ]\tLoss: 0.002780\n",
      "Timestamp 2019-11-27 18:37:32.218928 Train Epoch: 6 [100/200 ]\tLoss: 0.003501\n",
      "Timestamp 2019-11-27 18:37:34.590104 Train Epoch: 6 [110/200 ]\tLoss: 0.002768\n",
      "Timestamp 2019-11-27 18:37:36.957811 Train Epoch: 6 [120/200 ]\tLoss: 0.002575\n",
      "Timestamp 2019-11-27 18:37:39.324549 Train Epoch: 6 [130/200 ]\tLoss: 0.003544\n",
      "Timestamp 2019-11-27 18:37:41.694275 Train Epoch: 6 [140/200 ]\tLoss: 0.002751\n",
      "Timestamp 2019-11-27 18:37:44.067174 Train Epoch: 6 [150/200 ]\tLoss: 0.003432\n",
      "Timestamp 2019-11-27 18:37:46.429387 Train Epoch: 6 [160/200 ]\tLoss: 0.003590\n",
      "Timestamp 2019-11-27 18:37:48.794522 Train Epoch: 6 [170/200 ]\tLoss: 0.003001\n",
      "Timestamp 2019-11-27 18:37:51.158796 Train Epoch: 6 [180/200 ]\tLoss: 0.003011\n",
      "Timestamp 2019-11-27 18:37:53.545938 Train Epoch: 6 [190/200 ]\tLoss: 0.003098\n",
      "Timestamp 2019-11-27 18:37:55.911415 Train Epoch: 6 [200/200 ]\tLoss: 0.003440\n",
      "====> Timestamp 2019-11-27 18:37:55.953957 Epoch: 6 Average loss: 0.00316108\n",
      "epoch: 6====> Test set loss: 0.16293709\n",
      "Timestamp 2019-11-27 18:38:09.774846 Train Epoch: 7 [10/200 ]\tLoss: 0.002498\n",
      "Timestamp 2019-11-27 18:38:12.148420 Train Epoch: 7 [20/200 ]\tLoss: 0.002698\n",
      "Timestamp 2019-11-27 18:38:14.528158 Train Epoch: 7 [30/200 ]\tLoss: 0.002893\n",
      "Timestamp 2019-11-27 18:38:16.896042 Train Epoch: 7 [40/200 ]\tLoss: 0.003281\n",
      "Timestamp 2019-11-27 18:38:19.265340 Train Epoch: 7 [50/200 ]\tLoss: 0.002906\n",
      "Timestamp 2019-11-27 18:38:21.629755 Train Epoch: 7 [60/200 ]\tLoss: 0.003282\n",
      "Timestamp 2019-11-27 18:38:23.998544 Train Epoch: 7 [70/200 ]\tLoss: 0.003328\n",
      "Timestamp 2019-11-27 18:38:26.373825 Train Epoch: 7 [80/200 ]\tLoss: 0.003068\n",
      "Timestamp 2019-11-27 18:38:28.723341 Train Epoch: 7 [90/200 ]\tLoss: 0.002722\n",
      "Timestamp 2019-11-27 18:38:31.087050 Train Epoch: 7 [100/200 ]\tLoss: 0.003439\n",
      "Timestamp 2019-11-27 18:38:33.439725 Train Epoch: 7 [110/200 ]\tLoss: 0.002696\n",
      "Timestamp 2019-11-27 18:38:35.797601 Train Epoch: 7 [120/200 ]\tLoss: 0.002522\n",
      "Timestamp 2019-11-27 18:38:38.164181 Train Epoch: 7 [130/200 ]\tLoss: 0.003483\n",
      "Timestamp 2019-11-27 18:38:40.530921 Train Epoch: 7 [140/200 ]\tLoss: 0.002717\n",
      "Timestamp 2019-11-27 18:38:42.898366 Train Epoch: 7 [150/200 ]\tLoss: 0.003353\n",
      "Timestamp 2019-11-27 18:38:45.248925 Train Epoch: 7 [160/200 ]\tLoss: 0.003502\n",
      "Timestamp 2019-11-27 18:38:47.612728 Train Epoch: 7 [170/200 ]\tLoss: 0.002933\n",
      "Timestamp 2019-11-27 18:38:49.976609 Train Epoch: 7 [180/200 ]\tLoss: 0.002939\n",
      "Timestamp 2019-11-27 18:38:52.366408 Train Epoch: 7 [190/200 ]\tLoss: 0.003043\n",
      "Timestamp 2019-11-27 18:38:54.741732 Train Epoch: 7 [200/200 ]\tLoss: 0.003382\n",
      "====> Timestamp 2019-11-27 18:38:54.786064 Epoch: 7 Average loss: 0.00309954\n",
      "epoch: 7====> Test set loss: 0.16167026\n",
      "Timestamp 2019-11-27 18:39:08.414184 Train Epoch: 8 [10/200 ]\tLoss: 0.002447\n",
      "Timestamp 2019-11-27 18:39:10.792388 Train Epoch: 8 [20/200 ]\tLoss: 0.002642\n",
      "Timestamp 2019-11-27 18:39:13.158362 Train Epoch: 8 [30/200 ]\tLoss: 0.002838\n",
      "Timestamp 2019-11-27 18:39:15.530388 Train Epoch: 8 [40/200 ]\tLoss: 0.003222\n",
      "Timestamp 2019-11-27 18:39:17.898394 Train Epoch: 8 [50/200 ]\tLoss: 0.002858\n",
      "Timestamp 2019-11-27 18:39:20.273356 Train Epoch: 8 [60/200 ]\tLoss: 0.003233\n",
      "Timestamp 2019-11-27 18:39:22.665551 Train Epoch: 8 [70/200 ]\tLoss: 0.003253\n",
      "Timestamp 2019-11-27 18:39:25.032119 Train Epoch: 8 [80/200 ]\tLoss: 0.002999\n",
      "Timestamp 2019-11-27 18:39:27.414874 Train Epoch: 8 [90/200 ]\tLoss: 0.002675\n",
      "Timestamp 2019-11-27 18:39:29.793871 Train Epoch: 8 [100/200 ]\tLoss: 0.003384\n",
      "Timestamp 2019-11-27 18:39:32.157294 Train Epoch: 8 [110/200 ]\tLoss: 0.002645\n",
      "Timestamp 2019-11-27 18:39:34.528914 Train Epoch: 8 [120/200 ]\tLoss: 0.002471\n",
      "Timestamp 2019-11-27 18:39:36.901626 Train Epoch: 8 [130/200 ]\tLoss: 0.003427\n",
      "Timestamp 2019-11-27 18:39:39.274475 Train Epoch: 8 [140/200 ]\tLoss: 0.002678\n",
      "Timestamp 2019-11-27 18:39:41.642916 Train Epoch: 8 [150/200 ]\tLoss: 0.003324\n",
      "Timestamp 2019-11-27 18:39:44.008133 Train Epoch: 8 [160/200 ]\tLoss: 0.003453\n",
      "Timestamp 2019-11-27 18:39:46.372808 Train Epoch: 8 [170/200 ]\tLoss: 0.002876\n",
      "Timestamp 2019-11-27 18:39:48.744431 Train Epoch: 8 [180/200 ]\tLoss: 0.002897\n",
      "Timestamp 2019-11-27 18:39:51.117084 Train Epoch: 8 [190/200 ]\tLoss: 0.002988\n",
      "Timestamp 2019-11-27 18:39:53.502403 Train Epoch: 8 [200/200 ]\tLoss: 0.003334\n",
      "====> Timestamp 2019-11-27 18:39:53.545617 Epoch: 8 Average loss: 0.00304647\n",
      "epoch: 8====> Test set loss: 0.16093587\n",
      "Timestamp 2019-11-27 18:40:07.333977 Train Epoch: 9 [10/200 ]\tLoss: 0.002388\n",
      "Timestamp 2019-11-27 18:40:09.711901 Train Epoch: 9 [20/200 ]\tLoss: 0.002604\n",
      "Timestamp 2019-11-27 18:40:12.082189 Train Epoch: 9 [30/200 ]\tLoss: 0.002797\n",
      "Timestamp 2019-11-27 18:40:14.450135 Train Epoch: 9 [40/200 ]\tLoss: 0.003179\n",
      "Timestamp 2019-11-27 18:40:16.830364 Train Epoch: 9 [50/200 ]\tLoss: 0.002819\n",
      "Timestamp 2019-11-27 18:40:19.204958 Train Epoch: 9 [60/200 ]\tLoss: 0.003174\n",
      "Timestamp 2019-11-27 18:40:21.579317 Train Epoch: 9 [70/200 ]\tLoss: 0.003174\n",
      "Timestamp 2019-11-27 18:40:23.977141 Train Epoch: 9 [80/200 ]\tLoss: 0.002944\n",
      "Timestamp 2019-11-27 18:40:26.340498 Train Epoch: 9 [90/200 ]\tLoss: 0.002636\n",
      "Timestamp 2019-11-27 18:40:28.714935 Train Epoch: 9 [100/200 ]\tLoss: 0.003345\n",
      "Timestamp 2019-11-27 18:40:31.086987 Train Epoch: 9 [110/200 ]\tLoss: 0.002598\n",
      "Timestamp 2019-11-27 18:40:33.454804 Train Epoch: 9 [120/200 ]\tLoss: 0.002427\n",
      "Timestamp 2019-11-27 18:40:35.826416 Train Epoch: 9 [130/200 ]\tLoss: 0.003379\n",
      "Timestamp 2019-11-27 18:40:38.196060 Train Epoch: 9 [140/200 ]\tLoss: 0.002623\n",
      "Timestamp 2019-11-27 18:40:40.574557 Train Epoch: 9 [150/200 ]\tLoss: 0.003275\n",
      "Timestamp 2019-11-27 18:40:42.955299 Train Epoch: 9 [160/200 ]\tLoss: 0.003419\n",
      "Timestamp 2019-11-27 18:40:45.324699 Train Epoch: 9 [170/200 ]\tLoss: 0.002847\n",
      "Timestamp 2019-11-27 18:40:47.690120 Train Epoch: 9 [180/200 ]\tLoss: 0.002845\n",
      "Timestamp 2019-11-27 18:40:50.055650 Train Epoch: 9 [190/200 ]\tLoss: 0.002946\n",
      "Timestamp 2019-11-27 18:40:52.453918 Train Epoch: 9 [200/200 ]\tLoss: 0.003295\n",
      "====> Timestamp 2019-11-27 18:40:52.497078 Epoch: 9 Average loss: 0.00299899\n",
      "epoch: 9====> Test set loss: 0.16009202\n",
      "Timestamp 2019-11-27 18:41:06.341917 Train Epoch: 10 [10/200 ]\tLoss: 0.002354\n",
      "Timestamp 2019-11-27 18:41:08.702292 Train Epoch: 10 [20/200 ]\tLoss: 0.002586\n",
      "Timestamp 2019-11-27 18:41:11.070285 Train Epoch: 10 [30/200 ]\tLoss: 0.002763\n",
      "Timestamp 2019-11-27 18:41:13.438579 Train Epoch: 10 [40/200 ]\tLoss: 0.003139\n",
      "Timestamp 2019-11-27 18:41:15.797415 Train Epoch: 10 [50/200 ]\tLoss: 0.002772\n",
      "Timestamp 2019-11-27 18:41:18.149646 Train Epoch: 10 [60/200 ]\tLoss: 0.003125\n",
      "Timestamp 2019-11-27 18:41:20.519841 Train Epoch: 10 [70/200 ]\tLoss: 0.003101\n",
      "Timestamp 2019-11-27 18:41:22.906368 Train Epoch: 10 [80/200 ]\tLoss: 0.002885\n",
      "Timestamp 2019-11-27 18:41:25.273894 Train Epoch: 10 [90/200 ]\tLoss: 0.002613\n",
      "Timestamp 2019-11-27 18:41:27.641271 Train Epoch: 10 [100/200 ]\tLoss: 0.003301\n",
      "Timestamp 2019-11-27 18:41:30.011546 Train Epoch: 10 [110/200 ]\tLoss: 0.002573\n",
      "Timestamp 2019-11-27 18:41:32.370689 Train Epoch: 10 [120/200 ]\tLoss: 0.002385\n",
      "Timestamp 2019-11-27 18:41:34.742377 Train Epoch: 10 [130/200 ]\tLoss: 0.003334\n",
      "Timestamp 2019-11-27 18:41:37.104044 Train Epoch: 10 [140/200 ]\tLoss: 0.002574\n",
      "Timestamp 2019-11-27 18:41:39.460755 Train Epoch: 10 [150/200 ]\tLoss: 0.003205\n",
      "Timestamp 2019-11-27 18:41:41.817637 Train Epoch: 10 [160/200 ]\tLoss: 0.003358\n",
      "Timestamp 2019-11-27 18:41:44.183953 Train Epoch: 10 [170/200 ]\tLoss: 0.002821\n",
      "Timestamp 2019-11-27 18:41:46.538365 Train Epoch: 10 [180/200 ]\tLoss: 0.002807\n",
      "Timestamp 2019-11-27 18:41:48.901546 Train Epoch: 10 [190/200 ]\tLoss: 0.002912\n",
      "Timestamp 2019-11-27 18:41:51.265393 Train Epoch: 10 [200/200 ]\tLoss: 0.003253\n",
      "====> Timestamp 2019-11-27 18:41:51.308412 Epoch: 10 Average loss: 0.00295071\n",
      "epoch: 10====> Test set loss: 0.15930864\n",
      "Timestamp 2019-11-27 18:42:05.109184 Train Epoch: 11 [10/200 ]\tLoss: 0.002322\n",
      "Timestamp 2019-11-27 18:42:07.474123 Train Epoch: 11 [20/200 ]\tLoss: 0.002572\n",
      "Timestamp 2019-11-27 18:42:09.852911 Train Epoch: 11 [30/200 ]\tLoss: 0.002724\n",
      "Timestamp 2019-11-27 18:42:12.228505 Train Epoch: 11 [40/200 ]\tLoss: 0.003109\n",
      "Timestamp 2019-11-27 18:42:14.606425 Train Epoch: 11 [50/200 ]\tLoss: 0.002713\n",
      "Timestamp 2019-11-27 18:42:16.976903 Train Epoch: 11 [60/200 ]\tLoss: 0.003064\n",
      "Timestamp 2019-11-27 18:42:19.357332 Train Epoch: 11 [70/200 ]\tLoss: 0.003057\n",
      "Timestamp 2019-11-27 18:42:21.726993 Train Epoch: 11 [80/200 ]\tLoss: 0.002834\n",
      "Timestamp 2019-11-27 18:42:24.117999 Train Epoch: 11 [90/200 ]\tLoss: 0.002590\n",
      "Timestamp 2019-11-27 18:42:26.489236 Train Epoch: 11 [100/200 ]\tLoss: 0.003246\n",
      "Timestamp 2019-11-27 18:42:28.857672 Train Epoch: 11 [110/200 ]\tLoss: 0.002522\n",
      "Timestamp 2019-11-27 18:42:31.231845 Train Epoch: 11 [120/200 ]\tLoss: 0.002350\n",
      "Timestamp 2019-11-27 18:42:33.604769 Train Epoch: 11 [130/200 ]\tLoss: 0.003274\n",
      "Timestamp 2019-11-27 18:42:35.981568 Train Epoch: 11 [140/200 ]\tLoss: 0.002538\n",
      "Timestamp 2019-11-27 18:42:38.351513 Train Epoch: 11 [150/200 ]\tLoss: 0.003162\n",
      "Timestamp 2019-11-27 18:42:40.729552 Train Epoch: 11 [160/200 ]\tLoss: 0.003282\n",
      "Timestamp 2019-11-27 18:42:43.106974 Train Epoch: 11 [170/200 ]\tLoss: 0.002787\n",
      "Timestamp 2019-11-27 18:42:45.477646 Train Epoch: 11 [180/200 ]\tLoss: 0.002738\n",
      "Timestamp 2019-11-27 18:42:47.853203 Train Epoch: 11 [190/200 ]\tLoss: 0.002871\n",
      "Timestamp 2019-11-27 18:42:50.231781 Train Epoch: 11 [200/200 ]\tLoss: 0.003219\n",
      "====> Timestamp 2019-11-27 18:42:50.276670 Epoch: 11 Average loss: 0.00290242\n",
      "epoch: 11====> Test set loss: 0.15852177\n",
      "Timestamp 2019-11-27 18:43:04.123791 Train Epoch: 12 [10/200 ]\tLoss: 0.002278\n",
      "Timestamp 2019-11-27 18:43:06.496083 Train Epoch: 12 [20/200 ]\tLoss: 0.002540\n",
      "Timestamp 2019-11-27 18:43:08.865683 Train Epoch: 12 [30/200 ]\tLoss: 0.002694\n",
      "Timestamp 2019-11-27 18:43:11.247154 Train Epoch: 12 [40/200 ]\tLoss: 0.003084\n",
      "Timestamp 2019-11-27 18:43:13.611493 Train Epoch: 12 [50/200 ]\tLoss: 0.002654\n",
      "Timestamp 2019-11-27 18:43:15.975673 Train Epoch: 12 [60/200 ]\tLoss: 0.003003\n",
      "Timestamp 2019-11-27 18:43:18.349248 Train Epoch: 12 [70/200 ]\tLoss: 0.002987\n",
      "Timestamp 2019-11-27 18:43:20.716174 Train Epoch: 12 [80/200 ]\tLoss: 0.002780\n",
      "Timestamp 2019-11-27 18:43:23.105760 Train Epoch: 12 [90/200 ]\tLoss: 0.002573\n",
      "Timestamp 2019-11-27 18:43:25.468353 Train Epoch: 12 [100/200 ]\tLoss: 0.003173\n",
      "Timestamp 2019-11-27 18:43:27.843986 Train Epoch: 12 [110/200 ]\tLoss: 0.002475\n",
      "Timestamp 2019-11-27 18:43:30.211882 Train Epoch: 12 [120/200 ]\tLoss: 0.002296\n",
      "Timestamp 2019-11-27 18:43:32.578816 Train Epoch: 12 [130/200 ]\tLoss: 0.003210\n",
      "Timestamp 2019-11-27 18:43:34.944139 Train Epoch: 12 [140/200 ]\tLoss: 0.002487\n",
      "Timestamp 2019-11-27 18:43:37.306967 Train Epoch: 12 [150/200 ]\tLoss: 0.003117\n",
      "Timestamp 2019-11-27 18:43:39.678587 Train Epoch: 12 [160/200 ]\tLoss: 0.003221\n",
      "Timestamp 2019-11-27 18:43:42.044910 Train Epoch: 12 [170/200 ]\tLoss: 0.002736\n",
      "Timestamp 2019-11-27 18:43:44.411995 Train Epoch: 12 [180/200 ]\tLoss: 0.002661\n",
      "Timestamp 2019-11-27 18:43:46.780937 Train Epoch: 12 [190/200 ]\tLoss: 0.002846\n",
      "Timestamp 2019-11-27 18:43:49.147059 Train Epoch: 12 [200/200 ]\tLoss: 0.003160\n",
      "====> Timestamp 2019-11-27 18:43:49.190922 Epoch: 12 Average loss: 0.00284774\n",
      "epoch: 12====> Test set loss: 0.15748511\n",
      "Timestamp 2019-11-27 18:44:02.958479 Train Epoch: 13 [10/200 ]\tLoss: 0.002207\n",
      "Timestamp 2019-11-27 18:44:05.324858 Train Epoch: 13 [20/200 ]\tLoss: 0.002452\n",
      "Timestamp 2019-11-27 18:44:07.695865 Train Epoch: 13 [30/200 ]\tLoss: 0.002655\n",
      "Timestamp 2019-11-27 18:44:10.083555 Train Epoch: 13 [40/200 ]\tLoss: 0.003047\n",
      "Timestamp 2019-11-27 18:44:12.454693 Train Epoch: 13 [50/200 ]\tLoss: 0.002594\n",
      "Timestamp 2019-11-27 18:44:14.828029 Train Epoch: 13 [60/200 ]\tLoss: 0.002944\n",
      "Timestamp 2019-11-27 18:44:17.196590 Train Epoch: 13 [70/200 ]\tLoss: 0.002943\n",
      "Timestamp 2019-11-27 18:44:19.563267 Train Epoch: 13 [80/200 ]\tLoss: 0.002731\n",
      "Timestamp 2019-11-27 18:44:21.946331 Train Epoch: 13 [90/200 ]\tLoss: 0.002557\n",
      "Timestamp 2019-11-27 18:44:24.319948 Train Epoch: 13 [100/200 ]\tLoss: 0.003070\n",
      "Timestamp 2019-11-27 18:44:26.680735 Train Epoch: 13 [110/200 ]\tLoss: 0.002415\n",
      "Timestamp 2019-11-27 18:44:29.053928 Train Epoch: 13 [120/200 ]\tLoss: 0.002236\n",
      "Timestamp 2019-11-27 18:44:31.435861 Train Epoch: 13 [130/200 ]\tLoss: 0.003170\n",
      "Timestamp 2019-11-27 18:44:33.802588 Train Epoch: 13 [140/200 ]\tLoss: 0.002431\n",
      "Timestamp 2019-11-27 18:44:36.170016 Train Epoch: 13 [150/200 ]\tLoss: 0.003052\n",
      "Timestamp 2019-11-27 18:44:38.538082 Train Epoch: 13 [160/200 ]\tLoss: 0.003167\n",
      "Timestamp 2019-11-27 18:44:40.913370 Train Epoch: 13 [170/200 ]\tLoss: 0.002676\n",
      "Timestamp 2019-11-27 18:44:43.281150 Train Epoch: 13 [180/200 ]\tLoss: 0.002589\n",
      "Timestamp 2019-11-27 18:44:45.659761 Train Epoch: 13 [190/200 ]\tLoss: 0.002804\n",
      "Timestamp 2019-11-27 18:44:48.027235 Train Epoch: 13 [200/200 ]\tLoss: 0.003096\n",
      "====> Timestamp 2019-11-27 18:44:48.073150 Epoch: 13 Average loss: 0.00278247\n",
      "epoch: 13====> Test set loss: 0.15617440\n",
      "Timestamp 2019-11-27 18:45:01.773350 Train Epoch: 14 [10/200 ]\tLoss: 0.002141\n",
      "Timestamp 2019-11-27 18:45:04.137280 Train Epoch: 14 [20/200 ]\tLoss: 0.002393\n",
      "Timestamp 2019-11-27 18:45:06.513999 Train Epoch: 14 [30/200 ]\tLoss: 0.002632\n",
      "Timestamp 2019-11-27 18:45:08.880038 Train Epoch: 14 [40/200 ]\tLoss: 0.002965\n",
      "Timestamp 2019-11-27 18:45:11.251376 Train Epoch: 14 [50/200 ]\tLoss: 0.002531\n",
      "Timestamp 2019-11-27 18:45:13.620197 Train Epoch: 14 [60/200 ]\tLoss: 0.002862\n",
      "Timestamp 2019-11-27 18:45:15.992607 Train Epoch: 14 [70/200 ]\tLoss: 0.002868\n",
      "Timestamp 2019-11-27 18:45:18.370614 Train Epoch: 14 [80/200 ]\tLoss: 0.002684\n",
      "Timestamp 2019-11-27 18:45:20.743987 Train Epoch: 14 [90/200 ]\tLoss: 0.002539\n",
      "Timestamp 2019-11-27 18:45:23.140338 Train Epoch: 14 [100/200 ]\tLoss: 0.002976\n",
      "Timestamp 2019-11-27 18:45:25.517152 Train Epoch: 14 [110/200 ]\tLoss: 0.002356\n",
      "Timestamp 2019-11-27 18:45:27.876123 Train Epoch: 14 [120/200 ]\tLoss: 0.002179\n",
      "Timestamp 2019-11-27 18:45:30.258171 Train Epoch: 14 [130/200 ]\tLoss: 0.003081\n",
      "Timestamp 2019-11-27 18:45:32.634483 Train Epoch: 14 [140/200 ]\tLoss: 0.002389\n",
      "Timestamp 2019-11-27 18:45:35.003587 Train Epoch: 14 [150/200 ]\tLoss: 0.002992\n",
      "Timestamp 2019-11-27 18:45:37.365825 Train Epoch: 14 [160/200 ]\tLoss: 0.003116\n",
      "Timestamp 2019-11-27 18:45:39.736954 Train Epoch: 14 [170/200 ]\tLoss: 0.002638\n",
      "Timestamp 2019-11-27 18:45:42.108321 Train Epoch: 14 [180/200 ]\tLoss: 0.002534\n",
      "Timestamp 2019-11-27 18:45:44.484782 Train Epoch: 14 [190/200 ]\tLoss: 0.002763\n",
      "Timestamp 2019-11-27 18:45:46.850231 Train Epoch: 14 [200/200 ]\tLoss: 0.003028\n",
      "====> Timestamp 2019-11-27 18:45:46.894108 Epoch: 14 Average loss: 0.00271310\n",
      "epoch: 14====> Test set loss: 0.15472674\n",
      "Timestamp 2019-11-27 18:46:00.655156 Train Epoch: 15 [10/200 ]\tLoss: 0.002115\n",
      "Timestamp 2019-11-27 18:46:03.024460 Train Epoch: 15 [20/200 ]\tLoss: 0.002339\n",
      "Timestamp 2019-11-27 18:46:05.399124 Train Epoch: 15 [30/200 ]\tLoss: 0.002577\n",
      "Timestamp 2019-11-27 18:46:07.767813 Train Epoch: 15 [40/200 ]\tLoss: 0.002911\n",
      "Timestamp 2019-11-27 18:46:10.153785 Train Epoch: 15 [50/200 ]\tLoss: 0.002482\n",
      "Timestamp 2019-11-27 18:46:12.518143 Train Epoch: 15 [60/200 ]\tLoss: 0.002781\n",
      "Timestamp 2019-11-27 18:46:14.891240 Train Epoch: 15 [70/200 ]\tLoss: 0.002813\n",
      "Timestamp 2019-11-27 18:46:17.266943 Train Epoch: 15 [80/200 ]\tLoss: 0.002644\n",
      "Timestamp 2019-11-27 18:46:19.633839 Train Epoch: 15 [90/200 ]\tLoss: 0.002501\n",
      "Timestamp 2019-11-27 18:46:22.027252 Train Epoch: 15 [100/200 ]\tLoss: 0.002908\n",
      "Timestamp 2019-11-27 18:46:24.387438 Train Epoch: 15 [110/200 ]\tLoss: 0.002299\n",
      "Timestamp 2019-11-27 18:46:26.755788 Train Epoch: 15 [120/200 ]\tLoss: 0.002118\n",
      "Timestamp 2019-11-27 18:46:29.120892 Train Epoch: 15 [130/200 ]\tLoss: 0.002995\n",
      "Timestamp 2019-11-27 18:46:31.487625 Train Epoch: 15 [140/200 ]\tLoss: 0.002335\n",
      "Timestamp 2019-11-27 18:46:33.846448 Train Epoch: 15 [150/200 ]\tLoss: 0.002933\n",
      "Timestamp 2019-11-27 18:46:36.214425 Train Epoch: 15 [160/200 ]\tLoss: 0.003060\n",
      "Timestamp 2019-11-27 18:46:38.570935 Train Epoch: 15 [170/200 ]\tLoss: 0.002591\n",
      "Timestamp 2019-11-27 18:46:40.942801 Train Epoch: 15 [180/200 ]\tLoss: 0.002476\n",
      "Timestamp 2019-11-27 18:46:43.307461 Train Epoch: 15 [190/200 ]\tLoss: 0.002702\n",
      "Timestamp 2019-11-27 18:46:45.677417 Train Epoch: 15 [200/200 ]\tLoss: 0.002951\n",
      "====> Timestamp 2019-11-27 18:46:45.720165 Epoch: 15 Average loss: 0.00265132\n",
      "epoch: 15====> Test set loss: 0.15352374\n",
      "Timestamp 2019-11-27 18:46:59.542051 Train Epoch: 16 [10/200 ]\tLoss: 0.002086\n",
      "Timestamp 2019-11-27 18:47:01.921997 Train Epoch: 16 [20/200 ]\tLoss: 0.002294\n",
      "Timestamp 2019-11-27 18:47:04.294244 Train Epoch: 16 [30/200 ]\tLoss: 0.002514\n",
      "Timestamp 2019-11-27 18:47:06.661113 Train Epoch: 16 [40/200 ]\tLoss: 0.002878\n",
      "Timestamp 2019-11-27 18:47:09.026638 Train Epoch: 16 [50/200 ]\tLoss: 0.002435\n",
      "Timestamp 2019-11-27 18:47:11.397322 Train Epoch: 16 [60/200 ]\tLoss: 0.002743\n",
      "Timestamp 2019-11-27 18:47:13.764229 Train Epoch: 16 [70/200 ]\tLoss: 0.002750\n",
      "Timestamp 2019-11-27 18:47:16.123477 Train Epoch: 16 [80/200 ]\tLoss: 0.002590\n",
      "Timestamp 2019-11-27 18:47:18.496000 Train Epoch: 16 [90/200 ]\tLoss: 0.002411\n",
      "Timestamp 2019-11-27 18:47:20.872321 Train Epoch: 16 [100/200 ]\tLoss: 0.002844\n",
      "Timestamp 2019-11-27 18:47:23.267547 Train Epoch: 16 [110/200 ]\tLoss: 0.002254\n",
      "Timestamp 2019-11-27 18:47:25.630667 Train Epoch: 16 [120/200 ]\tLoss: 0.002086\n",
      "Timestamp 2019-11-27 18:47:27.994303 Train Epoch: 16 [130/200 ]\tLoss: 0.002946\n",
      "Timestamp 2019-11-27 18:47:30.449848 Train Epoch: 16 [140/200 ]\tLoss: 0.002300\n",
      "Timestamp 2019-11-27 18:47:32.885747 Train Epoch: 16 [150/200 ]\tLoss: 0.002874\n",
      "Timestamp 2019-11-27 18:47:35.289349 Train Epoch: 16 [160/200 ]\tLoss: 0.003017\n",
      "Timestamp 2019-11-27 18:47:37.669673 Train Epoch: 16 [170/200 ]\tLoss: 0.002560\n",
      "Timestamp 2019-11-27 18:47:39.984939 Train Epoch: 16 [180/200 ]\tLoss: 0.002427\n",
      "Timestamp 2019-11-27 18:47:42.288753 Train Epoch: 16 [190/200 ]\tLoss: 0.002653\n",
      "Timestamp 2019-11-27 18:47:44.587262 Train Epoch: 16 [200/200 ]\tLoss: 0.002922\n",
      "====> Timestamp 2019-11-27 18:47:44.635661 Epoch: 16 Average loss: 0.00259990\n",
      "epoch: 16====> Test set loss: 0.15272277\n",
      "Timestamp 2019-11-27 18:47:58.069369 Train Epoch: 17 [10/200 ]\tLoss: 0.002049\n",
      "Timestamp 2019-11-27 18:48:00.384060 Train Epoch: 17 [20/200 ]\tLoss: 0.002251\n",
      "Timestamp 2019-11-27 18:48:02.692961 Train Epoch: 17 [30/200 ]\tLoss: 0.002476\n",
      "Timestamp 2019-11-27 18:48:05.004100 Train Epoch: 17 [40/200 ]\tLoss: 0.002834\n",
      "Timestamp 2019-11-27 18:48:07.318359 Train Epoch: 17 [50/200 ]\tLoss: 0.002382\n",
      "Timestamp 2019-11-27 18:48:09.624043 Train Epoch: 17 [60/200 ]\tLoss: 0.002709\n",
      "Timestamp 2019-11-27 18:48:11.943475 Train Epoch: 17 [70/200 ]\tLoss: 0.002701\n",
      "Timestamp 2019-11-27 18:48:14.248628 Train Epoch: 17 [80/200 ]\tLoss: 0.002559\n",
      "Timestamp 2019-11-27 18:48:16.553170 Train Epoch: 17 [90/200 ]\tLoss: 0.002361\n",
      "Timestamp 2019-11-27 18:48:18.864153 Train Epoch: 17 [100/200 ]\tLoss: 0.002769\n",
      "Timestamp 2019-11-27 18:48:21.179224 Train Epoch: 17 [110/200 ]\tLoss: 0.002187\n",
      "Timestamp 2019-11-27 18:48:23.507187 Train Epoch: 17 [120/200 ]\tLoss: 0.002032\n",
      "Timestamp 2019-11-27 18:48:25.822385 Train Epoch: 17 [130/200 ]\tLoss: 0.002872\n",
      "Timestamp 2019-11-27 18:48:28.134793 Train Epoch: 17 [140/200 ]\tLoss: 0.002249\n",
      "Timestamp 2019-11-27 18:48:30.448741 Train Epoch: 17 [150/200 ]\tLoss: 0.002843\n",
      "Timestamp 2019-11-27 18:48:32.757762 Train Epoch: 17 [160/200 ]\tLoss: 0.002968\n",
      "Timestamp 2019-11-27 18:48:35.066166 Train Epoch: 17 [170/200 ]\tLoss: 0.002521\n",
      "Timestamp 2019-11-27 18:48:37.377601 Train Epoch: 17 [180/200 ]\tLoss: 0.002373\n",
      "Timestamp 2019-11-27 18:48:39.688471 Train Epoch: 17 [190/200 ]\tLoss: 0.002604\n",
      "Timestamp 2019-11-27 18:48:41.993299 Train Epoch: 17 [200/200 ]\tLoss: 0.002855\n",
      "====> Timestamp 2019-11-27 18:48:42.037227 Epoch: 17 Average loss: 0.00255035\n",
      "epoch: 17====> Test set loss: 0.15223847\n",
      "Timestamp 2019-11-27 18:48:55.468674 Train Epoch: 18 [10/200 ]\tLoss: 0.002014\n",
      "Timestamp 2019-11-27 18:48:57.764364 Train Epoch: 18 [20/200 ]\tLoss: 0.002210\n",
      "Timestamp 2019-11-27 18:49:00.069862 Train Epoch: 18 [30/200 ]\tLoss: 0.002432\n",
      "Timestamp 2019-11-27 18:49:02.368978 Train Epoch: 18 [40/200 ]\tLoss: 0.002798\n",
      "Timestamp 2019-11-27 18:49:04.668182 Train Epoch: 18 [50/200 ]\tLoss: 0.002375\n",
      "Timestamp 2019-11-27 18:49:06.963919 Train Epoch: 18 [60/200 ]\tLoss: 0.002660\n",
      "Timestamp 2019-11-27 18:49:09.265414 Train Epoch: 18 [70/200 ]\tLoss: 0.002666\n",
      "Timestamp 2019-11-27 18:49:11.572252 Train Epoch: 18 [80/200 ]\tLoss: 0.002515\n",
      "Timestamp 2019-11-27 18:49:13.868677 Train Epoch: 18 [90/200 ]\tLoss: 0.002328\n",
      "Timestamp 2019-11-27 18:49:16.167261 Train Epoch: 18 [100/200 ]\tLoss: 0.002694\n",
      "Timestamp 2019-11-27 18:49:18.462585 Train Epoch: 18 [110/200 ]\tLoss: 0.002145\n",
      "Timestamp 2019-11-27 18:49:20.764672 Train Epoch: 18 [120/200 ]\tLoss: 0.002001\n",
      "Timestamp 2019-11-27 18:49:23.089202 Train Epoch: 18 [130/200 ]\tLoss: 0.002833\n",
      "Timestamp 2019-11-27 18:49:25.391657 Train Epoch: 18 [140/200 ]\tLoss: 0.002229\n",
      "Timestamp 2019-11-27 18:49:27.695635 Train Epoch: 18 [150/200 ]\tLoss: 0.002784\n",
      "Timestamp 2019-11-27 18:49:29.992817 Train Epoch: 18 [160/200 ]\tLoss: 0.002917\n",
      "Timestamp 2019-11-27 18:49:32.295875 Train Epoch: 18 [170/200 ]\tLoss: 0.002508\n",
      "Timestamp 2019-11-27 18:49:34.597618 Train Epoch: 18 [180/200 ]\tLoss: 0.002346\n",
      "Timestamp 2019-11-27 18:49:36.900330 Train Epoch: 18 [190/200 ]\tLoss: 0.002560\n",
      "Timestamp 2019-11-27 18:49:39.200148 Train Epoch: 18 [200/200 ]\tLoss: 0.002802\n",
      "====> Timestamp 2019-11-27 18:49:39.243226 Epoch: 18 Average loss: 0.00250661\n",
      "epoch: 18====> Test set loss: 0.15188401\n",
      "Timestamp 2019-11-27 18:49:52.717558 Train Epoch: 19 [10/200 ]\tLoss: 0.001972\n",
      "Timestamp 2019-11-27 18:49:55.029861 Train Epoch: 19 [20/200 ]\tLoss: 0.002178\n",
      "Timestamp 2019-11-27 18:49:57.338984 Train Epoch: 19 [30/200 ]\tLoss: 0.002413\n",
      "Timestamp 2019-11-27 18:49:59.637584 Train Epoch: 19 [40/200 ]\tLoss: 0.002777\n",
      "Timestamp 2019-11-27 18:50:01.938839 Train Epoch: 19 [50/200 ]\tLoss: 0.002343\n",
      "Timestamp 2019-11-27 18:50:04.244301 Train Epoch: 19 [60/200 ]\tLoss: 0.002608\n",
      "Timestamp 2019-11-27 18:50:06.545257 Train Epoch: 19 [70/200 ]\tLoss: 0.002608\n",
      "Timestamp 2019-11-27 18:50:08.846568 Train Epoch: 19 [80/200 ]\tLoss: 0.002454\n",
      "Timestamp 2019-11-27 18:50:11.160367 Train Epoch: 19 [90/200 ]\tLoss: 0.002297\n",
      "Timestamp 2019-11-27 18:50:13.459315 Train Epoch: 19 [100/200 ]\tLoss: 0.002668\n",
      "Timestamp 2019-11-27 18:50:15.759318 Train Epoch: 19 [110/200 ]\tLoss: 0.002103\n",
      "Timestamp 2019-11-27 18:50:18.057596 Train Epoch: 19 [120/200 ]\tLoss: 0.001981\n",
      "Timestamp 2019-11-27 18:50:20.364454 Train Epoch: 19 [130/200 ]\tLoss: 0.002771\n",
      "Timestamp 2019-11-27 18:50:22.684512 Train Epoch: 19 [140/200 ]\tLoss: 0.002187\n",
      "Timestamp 2019-11-27 18:50:24.992795 Train Epoch: 19 [150/200 ]\tLoss: 0.002725\n",
      "Timestamp 2019-11-27 18:50:27.294280 Train Epoch: 19 [160/200 ]\tLoss: 0.002870\n",
      "Timestamp 2019-11-27 18:50:29.597349 Train Epoch: 19 [170/200 ]\tLoss: 0.002460\n",
      "Timestamp 2019-11-27 18:50:31.899582 Train Epoch: 19 [180/200 ]\tLoss: 0.002287\n",
      "Timestamp 2019-11-27 18:50:34.201317 Train Epoch: 19 [190/200 ]\tLoss: 0.002528\n",
      "Timestamp 2019-11-27 18:50:36.501176 Train Epoch: 19 [200/200 ]\tLoss: 0.002725\n",
      "====> Timestamp 2019-11-27 18:50:36.544595 Epoch: 19 Average loss: 0.00246115\n",
      "epoch: 19====> Test set loss: 0.15187298\n",
      "Timestamp 2019-11-27 18:50:50.035800 Train Epoch: 20 [10/200 ]\tLoss: 0.001921\n",
      "Timestamp 2019-11-27 18:50:52.365720 Train Epoch: 20 [20/200 ]\tLoss: 0.002146\n",
      "Timestamp 2019-11-27 18:50:54.672589 Train Epoch: 20 [30/200 ]\tLoss: 0.002370\n",
      "Timestamp 2019-11-27 18:50:56.987216 Train Epoch: 20 [40/200 ]\tLoss: 0.002725\n",
      "Timestamp 2019-11-27 18:50:59.298831 Train Epoch: 20 [50/200 ]\tLoss: 0.002306\n",
      "Timestamp 2019-11-27 18:51:01.611766 Train Epoch: 20 [60/200 ]\tLoss: 0.002564\n",
      "Timestamp 2019-11-27 18:51:03.926231 Train Epoch: 20 [70/200 ]\tLoss: 0.002556\n",
      "Timestamp 2019-11-27 18:51:06.239401 Train Epoch: 20 [80/200 ]\tLoss: 0.002434\n",
      "Timestamp 2019-11-27 18:51:08.553109 Train Epoch: 20 [90/200 ]\tLoss: 0.002269\n",
      "Timestamp 2019-11-27 18:51:10.863190 Train Epoch: 20 [100/200 ]\tLoss: 0.002596\n",
      "Timestamp 2019-11-27 18:51:13.181010 Train Epoch: 20 [110/200 ]\tLoss: 0.002078\n",
      "Timestamp 2019-11-27 18:51:15.481470 Train Epoch: 20 [120/200 ]\tLoss: 0.001932\n",
      "Timestamp 2019-11-27 18:51:17.788753 Train Epoch: 20 [130/200 ]\tLoss: 0.002720\n",
      "Timestamp 2019-11-27 18:51:20.097418 Train Epoch: 20 [140/200 ]\tLoss: 0.002141\n",
      "Timestamp 2019-11-27 18:51:22.423497 Train Epoch: 20 [150/200 ]\tLoss: 0.002702\n",
      "Timestamp 2019-11-27 18:51:24.736928 Train Epoch: 20 [160/200 ]\tLoss: 0.002813\n",
      "Timestamp 2019-11-27 18:51:27.049007 Train Epoch: 20 [170/200 ]\tLoss: 0.002426\n",
      "Timestamp 2019-11-27 18:51:29.367032 Train Epoch: 20 [180/200 ]\tLoss: 0.002246\n",
      "Timestamp 2019-11-27 18:51:31.678001 Train Epoch: 20 [190/200 ]\tLoss: 0.002469\n",
      "Timestamp 2019-11-27 18:51:33.990688 Train Epoch: 20 [200/200 ]\tLoss: 0.002694\n",
      "====> Timestamp 2019-11-27 18:51:34.038122 Epoch: 20 Average loss: 0.00241980\n",
      "epoch: 20====> Test set loss: 0.15112363\n",
      "Timestamp 2019-11-27 18:51:47.426993 Train Epoch: 21 [10/200 ]\tLoss: 0.001865\n",
      "Timestamp 2019-11-27 18:51:49.738136 Train Epoch: 21 [20/200 ]\tLoss: 0.002115\n",
      "Timestamp 2019-11-27 18:51:52.069326 Train Epoch: 21 [30/200 ]\tLoss: 0.002332\n",
      "Timestamp 2019-11-27 18:51:54.385512 Train Epoch: 21 [40/200 ]\tLoss: 0.002722\n",
      "Timestamp 2019-11-27 18:51:56.696898 Train Epoch: 21 [50/200 ]\tLoss: 0.002242\n",
      "Timestamp 2019-11-27 18:51:59.008332 Train Epoch: 21 [60/200 ]\tLoss: 0.002520\n",
      "Timestamp 2019-11-27 18:52:01.323710 Train Epoch: 21 [70/200 ]\tLoss: 0.002537\n",
      "Timestamp 2019-11-27 18:52:03.631881 Train Epoch: 21 [80/200 ]\tLoss: 0.002383\n",
      "Timestamp 2019-11-27 18:52:05.937211 Train Epoch: 21 [90/200 ]\tLoss: 0.002250\n",
      "Timestamp 2019-11-27 18:52:08.238077 Train Epoch: 21 [100/200 ]\tLoss: 0.002566\n",
      "Timestamp 2019-11-27 18:52:10.545253 Train Epoch: 21 [110/200 ]\tLoss: 0.002046\n",
      "Timestamp 2019-11-27 18:52:12.848022 Train Epoch: 21 [120/200 ]\tLoss: 0.001909\n",
      "Timestamp 2019-11-27 18:52:15.147846 Train Epoch: 21 [130/200 ]\tLoss: 0.002661\n",
      "Timestamp 2019-11-27 18:52:17.448507 Train Epoch: 21 [140/200 ]\tLoss: 0.002084\n",
      "Timestamp 2019-11-27 18:52:19.754976 Train Epoch: 21 [150/200 ]\tLoss: 0.002635\n",
      "Timestamp 2019-11-27 18:52:22.076195 Train Epoch: 21 [160/200 ]\tLoss: 0.002781\n",
      "Timestamp 2019-11-27 18:52:24.393934 Train Epoch: 21 [170/200 ]\tLoss: 0.002376\n",
      "Timestamp 2019-11-27 18:52:26.691499 Train Epoch: 21 [180/200 ]\tLoss: 0.002202\n",
      "Timestamp 2019-11-27 18:52:28.999998 Train Epoch: 21 [190/200 ]\tLoss: 0.002447\n",
      "Timestamp 2019-11-27 18:52:31.301825 Train Epoch: 21 [200/200 ]\tLoss: 0.002618\n",
      "====> Timestamp 2019-11-27 18:52:31.345286 Epoch: 21 Average loss: 0.00237966\n",
      "epoch: 21====> Test set loss: 0.15040390\n",
      "Timestamp 2019-11-27 18:52:44.842275 Train Epoch: 22 [10/200 ]\tLoss: 0.001833\n",
      "Timestamp 2019-11-27 18:52:47.148314 Train Epoch: 22 [20/200 ]\tLoss: 0.002097\n",
      "Timestamp 2019-11-27 18:52:49.456690 Train Epoch: 22 [30/200 ]\tLoss: 0.002288\n",
      "Timestamp 2019-11-27 18:52:51.771400 Train Epoch: 22 [40/200 ]\tLoss: 0.002657\n",
      "Timestamp 2019-11-27 18:52:54.090148 Train Epoch: 22 [50/200 ]\tLoss: 0.002233\n",
      "Timestamp 2019-11-27 18:52:56.403456 Train Epoch: 22 [60/200 ]\tLoss: 0.002494\n",
      "Timestamp 2019-11-27 18:52:58.715941 Train Epoch: 22 [70/200 ]\tLoss: 0.002449\n",
      "Timestamp 2019-11-27 18:53:01.031431 Train Epoch: 22 [80/200 ]\tLoss: 0.002310\n",
      "Timestamp 2019-11-27 18:53:03.345106 Train Epoch: 22 [90/200 ]\tLoss: 0.002229\n",
      "Timestamp 2019-11-27 18:53:05.654800 Train Epoch: 22 [100/200 ]\tLoss: 0.002497\n",
      "Timestamp 2019-11-27 18:53:07.964349 Train Epoch: 22 [110/200 ]\tLoss: 0.001993\n",
      "Timestamp 2019-11-27 18:53:10.271401 Train Epoch: 22 [120/200 ]\tLoss: 0.001885\n",
      "Timestamp 2019-11-27 18:53:12.590129 Train Epoch: 22 [130/200 ]\tLoss: 0.002614\n",
      "Timestamp 2019-11-27 18:53:14.903765 Train Epoch: 22 [140/200 ]\tLoss: 0.002067\n",
      "Timestamp 2019-11-27 18:53:17.217698 Train Epoch: 22 [150/200 ]\tLoss: 0.002579\n",
      "Timestamp 2019-11-27 18:53:19.525538 Train Epoch: 22 [160/200 ]\tLoss: 0.002745\n",
      "Timestamp 2019-11-27 18:53:21.843643 Train Epoch: 22 [170/200 ]\tLoss: 0.002338\n",
      "Timestamp 2019-11-27 18:53:24.159410 Train Epoch: 22 [180/200 ]\tLoss: 0.002164\n",
      "Timestamp 2019-11-27 18:53:26.463645 Train Epoch: 22 [190/200 ]\tLoss: 0.002393\n",
      "Timestamp 2019-11-27 18:53:28.763887 Train Epoch: 22 [200/200 ]\tLoss: 0.002606\n",
      "====> Timestamp 2019-11-27 18:53:28.807195 Epoch: 22 Average loss: 0.00234134\n",
      "epoch: 22====> Test set loss: 0.15003198\n",
      "Timestamp 2019-11-27 18:53:42.254895 Train Epoch: 23 [10/200 ]\tLoss: 0.001803\n",
      "Timestamp 2019-11-27 18:53:44.556499 Train Epoch: 23 [20/200 ]\tLoss: 0.002039\n",
      "Timestamp 2019-11-27 18:53:46.857730 Train Epoch: 23 [30/200 ]\tLoss: 0.002270\n",
      "Timestamp 2019-11-27 18:53:49.152457 Train Epoch: 23 [40/200 ]\tLoss: 0.002637\n",
      "Timestamp 2019-11-27 18:53:51.456742 Train Epoch: 23 [50/200 ]\tLoss: 0.002182\n",
      "Timestamp 2019-11-27 18:53:53.778767 Train Epoch: 23 [60/200 ]\tLoss: 0.002456\n",
      "Timestamp 2019-11-27 18:53:56.084482 Train Epoch: 23 [70/200 ]\tLoss: 0.002433\n",
      "Timestamp 2019-11-27 18:53:58.384109 Train Epoch: 23 [80/200 ]\tLoss: 0.002305\n",
      "Timestamp 2019-11-27 18:54:00.699411 Train Epoch: 23 [90/200 ]\tLoss: 0.002204\n",
      "Timestamp 2019-11-27 18:54:03.004294 Train Epoch: 23 [100/200 ]\tLoss: 0.002441\n",
      "Timestamp 2019-11-27 18:54:05.305300 Train Epoch: 23 [110/200 ]\tLoss: 0.001965\n",
      "Timestamp 2019-11-27 18:54:07.606519 Train Epoch: 23 [120/200 ]\tLoss: 0.001866\n",
      "Timestamp 2019-11-27 18:54:09.910351 Train Epoch: 23 [130/200 ]\tLoss: 0.002587\n",
      "Timestamp 2019-11-27 18:54:12.214591 Train Epoch: 23 [140/200 ]\tLoss: 0.002019\n",
      "Timestamp 2019-11-27 18:54:14.513884 Train Epoch: 23 [150/200 ]\tLoss: 0.002548\n",
      "Timestamp 2019-11-27 18:54:16.817297 Train Epoch: 23 [160/200 ]\tLoss: 0.002704\n",
      "Timestamp 2019-11-27 18:54:19.115234 Train Epoch: 23 [170/200 ]\tLoss: 0.002305\n",
      "Timestamp 2019-11-27 18:54:21.417539 Train Epoch: 23 [180/200 ]\tLoss: 0.002129\n",
      "Timestamp 2019-11-27 18:54:23.725222 Train Epoch: 23 [190/200 ]\tLoss: 0.002386\n",
      "Timestamp 2019-11-27 18:54:26.026236 Train Epoch: 23 [200/200 ]\tLoss: 0.002554\n",
      "====> Timestamp 2019-11-27 18:54:26.071668 Epoch: 23 Average loss: 0.00230523\n",
      "epoch: 23====> Test set loss: 0.14878285\n",
      "Timestamp 2019-11-27 18:54:39.500353 Train Epoch: 24 [10/200 ]\tLoss: 0.001767\n",
      "Timestamp 2019-11-27 18:54:41.812206 Train Epoch: 24 [20/200 ]\tLoss: 0.002038\n",
      "Timestamp 2019-11-27 18:54:44.125036 Train Epoch: 24 [30/200 ]\tLoss: 0.002240\n",
      "Timestamp 2019-11-27 18:54:46.438399 Train Epoch: 24 [40/200 ]\tLoss: 0.002612\n",
      "Timestamp 2019-11-27 18:54:48.743491 Train Epoch: 24 [50/200 ]\tLoss: 0.002134\n",
      "Timestamp 2019-11-27 18:54:51.049985 Train Epoch: 24 [60/200 ]\tLoss: 0.002421\n",
      "Timestamp 2019-11-27 18:54:53.369515 Train Epoch: 24 [70/200 ]\tLoss: 0.002383\n",
      "Timestamp 2019-11-27 18:54:55.678754 Train Epoch: 24 [80/200 ]\tLoss: 0.002226\n",
      "Timestamp 2019-11-27 18:54:57.978825 Train Epoch: 24 [90/200 ]\tLoss: 0.002203\n",
      "Timestamp 2019-11-27 18:55:00.302771 Train Epoch: 24 [100/200 ]\tLoss: 0.002433\n",
      "Timestamp 2019-11-27 18:55:02.607787 Train Epoch: 24 [110/200 ]\tLoss: 0.001910\n",
      "Timestamp 2019-11-27 18:55:04.907801 Train Epoch: 24 [120/200 ]\tLoss: 0.001811\n",
      "Timestamp 2019-11-27 18:55:07.209147 Train Epoch: 24 [130/200 ]\tLoss: 0.002540\n",
      "Timestamp 2019-11-27 18:55:09.505051 Train Epoch: 24 [140/200 ]\tLoss: 0.001985\n",
      "Timestamp 2019-11-27 18:55:11.801844 Train Epoch: 24 [150/200 ]\tLoss: 0.002507\n",
      "Timestamp 2019-11-27 18:55:14.103567 Train Epoch: 24 [160/200 ]\tLoss: 0.002663\n",
      "Timestamp 2019-11-27 18:55:16.404029 Train Epoch: 24 [170/200 ]\tLoss: 0.002292\n",
      "Timestamp 2019-11-27 18:55:18.709994 Train Epoch: 24 [180/200 ]\tLoss: 0.002109\n",
      "Timestamp 2019-11-27 18:55:21.013874 Train Epoch: 24 [190/200 ]\tLoss: 0.002352\n",
      "Timestamp 2019-11-27 18:55:23.335254 Train Epoch: 24 [200/200 ]\tLoss: 0.002506\n",
      "====> Timestamp 2019-11-27 18:55:23.378322 Epoch: 24 Average loss: 0.00226907\n",
      "epoch: 24====> Test set loss: 0.14826786\n",
      "Timestamp 2019-11-27 18:55:36.750480 Train Epoch: 25 [10/200 ]\tLoss: 0.001750\n",
      "Timestamp 2019-11-27 18:55:39.059919 Train Epoch: 25 [20/200 ]\tLoss: 0.001998\n",
      "Timestamp 2019-11-27 18:55:41.367926 Train Epoch: 25 [30/200 ]\tLoss: 0.002228\n",
      "Timestamp 2019-11-27 18:55:43.678672 Train Epoch: 25 [40/200 ]\tLoss: 0.002541\n",
      "Timestamp 2019-11-27 18:55:45.982880 Train Epoch: 25 [50/200 ]\tLoss: 0.002089\n",
      "Timestamp 2019-11-27 18:55:48.296986 Train Epoch: 25 [60/200 ]\tLoss: 0.002381\n",
      "Timestamp 2019-11-27 18:55:50.607307 Train Epoch: 25 [70/200 ]\tLoss: 0.002328\n",
      "Timestamp 2019-11-27 18:55:52.939218 Train Epoch: 25 [80/200 ]\tLoss: 0.002177\n",
      "Timestamp 2019-11-27 18:55:55.255424 Train Epoch: 25 [90/200 ]\tLoss: 0.002161\n",
      "Timestamp 2019-11-27 18:55:57.567615 Train Epoch: 25 [100/200 ]\tLoss: 0.002396\n",
      "Timestamp 2019-11-27 18:55:59.885300 Train Epoch: 25 [110/200 ]\tLoss: 0.001882\n",
      "Timestamp 2019-11-27 18:56:02.202827 Train Epoch: 25 [120/200 ]\tLoss: 0.001795\n",
      "Timestamp 2019-11-27 18:56:04.515393 Train Epoch: 25 [130/200 ]\tLoss: 0.002484\n",
      "Timestamp 2019-11-27 18:56:06.824976 Train Epoch: 25 [140/200 ]\tLoss: 0.001974\n",
      "Timestamp 2019-11-27 18:56:09.138267 Train Epoch: 25 [150/200 ]\tLoss: 0.002457\n",
      "Timestamp 2019-11-27 18:56:11.451318 Train Epoch: 25 [160/200 ]\tLoss: 0.002624\n",
      "Timestamp 2019-11-27 18:56:13.766513 Train Epoch: 25 [170/200 ]\tLoss: 0.002233\n",
      "Timestamp 2019-11-27 18:56:16.072863 Train Epoch: 25 [180/200 ]\tLoss: 0.002070\n",
      "Timestamp 2019-11-27 18:56:18.378938 Train Epoch: 25 [190/200 ]\tLoss: 0.002323\n",
      "Timestamp 2019-11-27 18:56:20.693546 Train Epoch: 25 [200/200 ]\tLoss: 0.002479\n",
      "====> Timestamp 2019-11-27 18:56:20.737625 Epoch: 25 Average loss: 0.00223247\n",
      "epoch: 25====> Test set loss: 0.14788495\n",
      "Timestamp 2019-11-27 18:56:34.191734 Train Epoch: 26 [10/200 ]\tLoss: 0.001750\n",
      "Timestamp 2019-11-27 18:56:36.499907 Train Epoch: 26 [20/200 ]\tLoss: 0.001974\n",
      "Timestamp 2019-11-27 18:56:38.806485 Train Epoch: 26 [30/200 ]\tLoss: 0.002174\n",
      "Timestamp 2019-11-27 18:56:41.116211 Train Epoch: 26 [40/200 ]\tLoss: 0.002541\n",
      "Timestamp 2019-11-27 18:56:43.425067 Train Epoch: 26 [50/200 ]\tLoss: 0.002065\n",
      "Timestamp 2019-11-27 18:56:45.733185 Train Epoch: 26 [60/200 ]\tLoss: 0.002341\n",
      "Timestamp 2019-11-27 18:56:48.045661 Train Epoch: 26 [70/200 ]\tLoss: 0.002299\n",
      "Timestamp 2019-11-27 18:56:50.357359 Train Epoch: 26 [80/200 ]\tLoss: 0.002146\n",
      "Timestamp 2019-11-27 18:56:52.685227 Train Epoch: 26 [90/200 ]\tLoss: 0.002146\n",
      "Timestamp 2019-11-27 18:56:54.993795 Train Epoch: 26 [100/200 ]\tLoss: 0.002357\n",
      "Timestamp 2019-11-27 18:56:57.301736 Train Epoch: 26 [110/200 ]\tLoss: 0.001863\n",
      "Timestamp 2019-11-27 18:56:59.608254 Train Epoch: 26 [120/200 ]\tLoss: 0.001793\n",
      "Timestamp 2019-11-27 18:57:01.919607 Train Epoch: 26 [130/200 ]\tLoss: 0.002439\n",
      "Timestamp 2019-11-27 18:57:04.221217 Train Epoch: 26 [140/200 ]\tLoss: 0.001942\n",
      "Timestamp 2019-11-27 18:57:06.528880 Train Epoch: 26 [150/200 ]\tLoss: 0.002421\n",
      "Timestamp 2019-11-27 18:57:08.836039 Train Epoch: 26 [160/200 ]\tLoss: 0.002601\n",
      "Timestamp 2019-11-27 18:57:11.148530 Train Epoch: 26 [170/200 ]\tLoss: 0.002197\n",
      "Timestamp 2019-11-27 18:57:13.460768 Train Epoch: 26 [180/200 ]\tLoss: 0.002023\n",
      "Timestamp 2019-11-27 18:57:15.769457 Train Epoch: 26 [190/200 ]\tLoss: 0.002262\n",
      "Timestamp 2019-11-27 18:57:18.081887 Train Epoch: 26 [200/200 ]\tLoss: 0.002418\n",
      "====> Timestamp 2019-11-27 18:57:18.125969 Epoch: 26 Average loss: 0.00220043\n",
      "epoch: 26====> Test set loss: 0.14744987\n",
      "Timestamp 2019-11-27 18:57:31.494943 Train Epoch: 27 [10/200 ]\tLoss: 0.001734\n",
      "Timestamp 2019-11-27 18:57:33.808745 Train Epoch: 27 [20/200 ]\tLoss: 0.001956\n",
      "Timestamp 2019-11-27 18:57:36.117229 Train Epoch: 27 [30/200 ]\tLoss: 0.002123\n",
      "Timestamp 2019-11-27 18:57:38.424609 Train Epoch: 27 [40/200 ]\tLoss: 0.002490\n",
      "Timestamp 2019-11-27 18:57:40.724571 Train Epoch: 27 [50/200 ]\tLoss: 0.002045\n",
      "Timestamp 2019-11-27 18:57:43.031778 Train Epoch: 27 [60/200 ]\tLoss: 0.002301\n",
      "Timestamp 2019-11-27 18:57:45.333387 Train Epoch: 27 [70/200 ]\tLoss: 0.002268\n",
      "Timestamp 2019-11-27 18:57:47.638655 Train Epoch: 27 [80/200 ]\tLoss: 0.002115\n",
      "Timestamp 2019-11-27 18:57:49.939186 Train Epoch: 27 [90/200 ]\tLoss: 0.002108\n",
      "Timestamp 2019-11-27 18:57:52.269861 Train Epoch: 27 [100/200 ]\tLoss: 0.002300\n",
      "Timestamp 2019-11-27 18:57:54.567928 Train Epoch: 27 [110/200 ]\tLoss: 0.001792\n",
      "Timestamp 2019-11-27 18:57:56.870066 Train Epoch: 27 [120/200 ]\tLoss: 0.001754\n",
      "Timestamp 2019-11-27 18:57:59.174539 Train Epoch: 27 [130/200 ]\tLoss: 0.002393\n",
      "Timestamp 2019-11-27 18:58:01.477864 Train Epoch: 27 [140/200 ]\tLoss: 0.001906\n",
      "Timestamp 2019-11-27 18:58:03.782124 Train Epoch: 27 [150/200 ]\tLoss: 0.002391\n",
      "Timestamp 2019-11-27 18:58:06.081272 Train Epoch: 27 [160/200 ]\tLoss: 0.002570\n",
      "Timestamp 2019-11-27 18:58:08.378756 Train Epoch: 27 [170/200 ]\tLoss: 0.002181\n",
      "Timestamp 2019-11-27 18:58:10.681934 Train Epoch: 27 [180/200 ]\tLoss: 0.001969\n",
      "Timestamp 2019-11-27 18:58:12.980889 Train Epoch: 27 [190/200 ]\tLoss: 0.002264\n",
      "Timestamp 2019-11-27 18:58:15.283058 Train Epoch: 27 [200/200 ]\tLoss: 0.002389\n",
      "====> Timestamp 2019-11-27 18:58:15.324553 Epoch: 27 Average loss: 0.00216720\n",
      "epoch: 27====> Test set loss: 0.14726023\n",
      "Timestamp 2019-11-27 18:58:28.809811 Train Epoch: 28 [10/200 ]\tLoss: 0.001682\n",
      "Timestamp 2019-11-27 18:58:31.126009 Train Epoch: 28 [20/200 ]\tLoss: 0.001918\n",
      "Timestamp 2019-11-27 18:58:33.432348 Train Epoch: 28 [30/200 ]\tLoss: 0.002117\n",
      "Timestamp 2019-11-27 18:58:35.741814 Train Epoch: 28 [40/200 ]\tLoss: 0.002469\n",
      "Timestamp 2019-11-27 18:58:38.056378 Train Epoch: 28 [50/200 ]\tLoss: 0.001970\n",
      "Timestamp 2019-11-27 18:58:40.371991 Train Epoch: 28 [60/200 ]\tLoss: 0.002264\n",
      "Timestamp 2019-11-27 18:58:42.680704 Train Epoch: 28 [70/200 ]\tLoss: 0.002251\n",
      "Timestamp 2019-11-27 18:58:44.989048 Train Epoch: 28 [80/200 ]\tLoss: 0.002091\n",
      "Timestamp 2019-11-27 18:58:47.294608 Train Epoch: 28 [90/200 ]\tLoss: 0.002111\n",
      "Timestamp 2019-11-27 18:58:49.595440 Train Epoch: 28 [100/200 ]\tLoss: 0.002260\n",
      "Timestamp 2019-11-27 18:58:51.923698 Train Epoch: 28 [110/200 ]\tLoss: 0.001783\n",
      "Timestamp 2019-11-27 18:58:54.225939 Train Epoch: 28 [120/200 ]\tLoss: 0.001743\n",
      "Timestamp 2019-11-27 18:58:56.521249 Train Epoch: 28 [130/200 ]\tLoss: 0.002349\n",
      "Timestamp 2019-11-27 18:58:58.821887 Train Epoch: 28 [140/200 ]\tLoss: 0.001871\n",
      "Timestamp 2019-11-27 18:59:01.118696 Train Epoch: 28 [150/200 ]\tLoss: 0.002380\n",
      "Timestamp 2019-11-27 18:59:03.418406 Train Epoch: 28 [160/200 ]\tLoss: 0.002533\n",
      "Timestamp 2019-11-27 18:59:05.713030 Train Epoch: 28 [170/200 ]\tLoss: 0.002128\n",
      "Timestamp 2019-11-27 18:59:08.017178 Train Epoch: 28 [180/200 ]\tLoss: 0.001959\n",
      "Timestamp 2019-11-27 18:59:10.315544 Train Epoch: 28 [190/200 ]\tLoss: 0.002224\n",
      "Timestamp 2019-11-27 18:59:12.623181 Train Epoch: 28 [200/200 ]\tLoss: 0.002352\n",
      "====> Timestamp 2019-11-27 18:59:12.666767 Epoch: 28 Average loss: 0.00213635\n",
      "epoch: 28====> Test set loss: 0.14716240\n",
      "Timestamp 2019-11-27 18:59:26.098124 Train Epoch: 29 [10/200 ]\tLoss: 0.001675\n",
      "Timestamp 2019-11-27 18:59:28.404188 Train Epoch: 29 [20/200 ]\tLoss: 0.001851\n",
      "Timestamp 2019-11-27 18:59:30.717560 Train Epoch: 29 [30/200 ]\tLoss: 0.002092\n",
      "Timestamp 2019-11-27 18:59:33.029614 Train Epoch: 29 [40/200 ]\tLoss: 0.002429\n",
      "Timestamp 2019-11-27 18:59:35.343942 Train Epoch: 29 [50/200 ]\tLoss: 0.001973\n",
      "Timestamp 2019-11-27 18:59:37.654865 Train Epoch: 29 [60/200 ]\tLoss: 0.002226\n",
      "Timestamp 2019-11-27 18:59:39.965414 Train Epoch: 29 [70/200 ]\tLoss: 0.002189\n",
      "Timestamp 2019-11-27 18:59:42.279331 Train Epoch: 29 [80/200 ]\tLoss: 0.002047\n",
      "Timestamp 2019-11-27 18:59:44.589860 Train Epoch: 29 [90/200 ]\tLoss: 0.002067\n",
      "Timestamp 2019-11-27 18:59:46.898292 Train Epoch: 29 [100/200 ]\tLoss: 0.002240\n",
      "Timestamp 2019-11-27 18:59:49.206101 Train Epoch: 29 [110/200 ]\tLoss: 0.001752\n",
      "Timestamp 2019-11-27 18:59:51.515129 Train Epoch: 29 [120/200 ]\tLoss: 0.001719\n",
      "Timestamp 2019-11-27 18:59:53.838760 Train Epoch: 29 [130/200 ]\tLoss: 0.002332\n",
      "Timestamp 2019-11-27 18:59:56.142432 Train Epoch: 29 [140/200 ]\tLoss: 0.001837\n",
      "Timestamp 2019-11-27 18:59:58.450520 Train Epoch: 29 [150/200 ]\tLoss: 0.002339\n",
      "Timestamp 2019-11-27 19:00:00.758179 Train Epoch: 29 [160/200 ]\tLoss: 0.002500\n",
      "Timestamp 2019-11-27 19:00:03.058327 Train Epoch: 29 [170/200 ]\tLoss: 0.002097\n",
      "Timestamp 2019-11-27 19:00:05.365562 Train Epoch: 29 [180/200 ]\tLoss: 0.001928\n",
      "Timestamp 2019-11-27 19:00:07.667263 Train Epoch: 29 [190/200 ]\tLoss: 0.002198\n",
      "Timestamp 2019-11-27 19:00:09.979391 Train Epoch: 29 [200/200 ]\tLoss: 0.002326\n",
      "====> Timestamp 2019-11-27 19:00:10.022483 Epoch: 29 Average loss: 0.00210212\n",
      "epoch: 29====> Test set loss: 0.14636030\n",
      "Timestamp 2019-11-27 19:00:23.539230 Train Epoch: 30 [10/200 ]\tLoss: 0.001676\n",
      "Timestamp 2019-11-27 19:00:25.849452 Train Epoch: 30 [20/200 ]\tLoss: 0.001855\n",
      "Timestamp 2019-11-27 19:00:28.157964 Train Epoch: 30 [30/200 ]\tLoss: 0.002045\n",
      "Timestamp 2019-11-27 19:00:30.473387 Train Epoch: 30 [40/200 ]\tLoss: 0.002424\n",
      "Timestamp 2019-11-27 19:00:32.781007 Train Epoch: 30 [50/200 ]\tLoss: 0.001916\n",
      "Timestamp 2019-11-27 19:00:35.088640 Train Epoch: 30 [60/200 ]\tLoss: 0.002178\n",
      "Timestamp 2019-11-27 19:00:37.394881 Train Epoch: 30 [70/200 ]\tLoss: 0.002180\n",
      "Timestamp 2019-11-27 19:00:39.713284 Train Epoch: 30 [80/200 ]\tLoss: 0.002019\n",
      "Timestamp 2019-11-27 19:00:42.026996 Train Epoch: 30 [90/200 ]\tLoss: 0.002052\n",
      "Timestamp 2019-11-27 19:00:44.342642 Train Epoch: 30 [100/200 ]\tLoss: 0.002203\n",
      "Timestamp 2019-11-27 19:00:46.653857 Train Epoch: 30 [110/200 ]\tLoss: 0.001708\n",
      "Timestamp 2019-11-27 19:00:48.964903 Train Epoch: 30 [120/200 ]\tLoss: 0.001676\n",
      "Timestamp 2019-11-27 19:00:51.274030 Train Epoch: 30 [130/200 ]\tLoss: 0.002305\n",
      "Timestamp 2019-11-27 19:00:53.604475 Train Epoch: 30 [140/200 ]\tLoss: 0.001799\n",
      "Timestamp 2019-11-27 19:00:55.907616 Train Epoch: 30 [150/200 ]\tLoss: 0.002276\n",
      "Timestamp 2019-11-27 19:00:58.217874 Train Epoch: 30 [160/200 ]\tLoss: 0.002508\n",
      "Timestamp 2019-11-27 19:01:00.530351 Train Epoch: 30 [170/200 ]\tLoss: 0.002110\n",
      "Timestamp 2019-11-27 19:01:02.837442 Train Epoch: 30 [180/200 ]\tLoss: 0.001891\n",
      "Timestamp 2019-11-27 19:01:05.145474 Train Epoch: 30 [190/200 ]\tLoss: 0.002172\n",
      "Timestamp 2019-11-27 19:01:07.459711 Train Epoch: 30 [200/200 ]\tLoss: 0.002299\n",
      "====> Timestamp 2019-11-27 19:01:07.504138 Epoch: 30 Average loss: 0.00207207\n",
      "epoch: 30====> Test set loss: 0.14529123\n",
      "Timestamp 2019-11-27 19:01:20.887498 Train Epoch: 31 [10/200 ]\tLoss: 0.001624\n",
      "Timestamp 2019-11-27 19:01:23.214664 Train Epoch: 31 [20/200 ]\tLoss: 0.001818\n",
      "Timestamp 2019-11-27 19:01:25.523427 Train Epoch: 31 [30/200 ]\tLoss: 0.002014\n",
      "Timestamp 2019-11-27 19:01:27.834325 Train Epoch: 31 [40/200 ]\tLoss: 0.002377\n",
      "Timestamp 2019-11-27 19:01:30.147438 Train Epoch: 31 [50/200 ]\tLoss: 0.001896\n",
      "Timestamp 2019-11-27 19:01:32.460831 Train Epoch: 31 [60/200 ]\tLoss: 0.002152\n",
      "Timestamp 2019-11-27 19:01:34.776590 Train Epoch: 31 [70/200 ]\tLoss: 0.002154\n",
      "Timestamp 2019-11-27 19:01:37.081145 Train Epoch: 31 [80/200 ]\tLoss: 0.001991\n",
      "Timestamp 2019-11-27 19:01:39.391823 Train Epoch: 31 [90/200 ]\tLoss: 0.002004\n",
      "Timestamp 2019-11-27 19:01:41.709241 Train Epoch: 31 [100/200 ]\tLoss: 0.002169\n",
      "Timestamp 2019-11-27 19:01:44.017403 Train Epoch: 31 [110/200 ]\tLoss: 0.001704\n",
      "Timestamp 2019-11-27 19:01:46.324248 Train Epoch: 31 [120/200 ]\tLoss: 0.001642\n",
      "Timestamp 2019-11-27 19:01:48.638621 Train Epoch: 31 [130/200 ]\tLoss: 0.002246\n",
      "Timestamp 2019-11-27 19:01:50.948604 Train Epoch: 31 [140/200 ]\tLoss: 0.001777\n",
      "Timestamp 2019-11-27 19:01:53.271400 Train Epoch: 31 [150/200 ]\tLoss: 0.002278\n",
      "Timestamp 2019-11-27 19:01:55.588691 Train Epoch: 31 [160/200 ]\tLoss: 0.002438\n",
      "Timestamp 2019-11-27 19:01:57.903827 Train Epoch: 31 [170/200 ]\tLoss: 0.002054\n",
      "Timestamp 2019-11-27 19:02:00.217819 Train Epoch: 31 [180/200 ]\tLoss: 0.001857\n",
      "Timestamp 2019-11-27 19:02:02.536649 Train Epoch: 31 [190/200 ]\tLoss: 0.002143\n",
      "Timestamp 2019-11-27 19:02:04.841147 Train Epoch: 31 [200/200 ]\tLoss: 0.002279\n",
      "====> Timestamp 2019-11-27 19:02:04.883121 Epoch: 31 Average loss: 0.00204256\n",
      "epoch: 31====> Test set loss: 0.14511871\n",
      "Timestamp 2019-11-27 19:02:18.290472 Train Epoch: 32 [10/200 ]\tLoss: 0.001617\n",
      "Timestamp 2019-11-27 19:02:20.604556 Train Epoch: 32 [20/200 ]\tLoss: 0.001796\n",
      "Timestamp 2019-11-27 19:02:22.934645 Train Epoch: 32 [30/200 ]\tLoss: 0.001995\n",
      "Timestamp 2019-11-27 19:02:25.242027 Train Epoch: 32 [40/200 ]\tLoss: 0.002358\n",
      "Timestamp 2019-11-27 19:02:27.544875 Train Epoch: 32 [50/200 ]\tLoss: 0.001867\n",
      "Timestamp 2019-11-27 19:02:29.849334 Train Epoch: 32 [60/200 ]\tLoss: 0.002121\n",
      "Timestamp 2019-11-27 19:02:32.159296 Train Epoch: 32 [70/200 ]\tLoss: 0.002100\n",
      "Timestamp 2019-11-27 19:02:34.468839 Train Epoch: 32 [80/200 ]\tLoss: 0.001934\n",
      "Timestamp 2019-11-27 19:02:36.774618 Train Epoch: 32 [90/200 ]\tLoss: 0.001982\n",
      "Timestamp 2019-11-27 19:02:39.082008 Train Epoch: 32 [100/200 ]\tLoss: 0.002138\n",
      "Timestamp 2019-11-27 19:02:41.389593 Train Epoch: 32 [110/200 ]\tLoss: 0.001661\n",
      "Timestamp 2019-11-27 19:02:43.699821 Train Epoch: 32 [120/200 ]\tLoss: 0.001624\n",
      "Timestamp 2019-11-27 19:02:46.011994 Train Epoch: 32 [130/200 ]\tLoss: 0.002214\n",
      "Timestamp 2019-11-27 19:02:48.327976 Train Epoch: 32 [140/200 ]\tLoss: 0.001763\n",
      "Timestamp 2019-11-27 19:02:50.644283 Train Epoch: 32 [150/200 ]\tLoss: 0.002235\n",
      "Timestamp 2019-11-27 19:02:52.970910 Train Epoch: 32 [160/200 ]\tLoss: 0.002427\n",
      "Timestamp 2019-11-27 19:02:55.276485 Train Epoch: 32 [170/200 ]\tLoss: 0.002028\n",
      "Timestamp 2019-11-27 19:02:57.585489 Train Epoch: 32 [180/200 ]\tLoss: 0.001834\n",
      "Timestamp 2019-11-27 19:02:59.890445 Train Epoch: 32 [190/200 ]\tLoss: 0.002126\n",
      "Timestamp 2019-11-27 19:03:02.201519 Train Epoch: 32 [200/200 ]\tLoss: 0.002241\n",
      "====> Timestamp 2019-11-27 19:03:02.245689 Epoch: 32 Average loss: 0.00201193\n",
      "epoch: 32====> Test set loss: 0.14369267\n",
      "Timestamp 2019-11-27 19:03:15.760501 Train Epoch: 33 [10/200 ]\tLoss: 0.001599\n",
      "Timestamp 2019-11-27 19:03:18.076692 Train Epoch: 33 [20/200 ]\tLoss: 0.001765\n",
      "Timestamp 2019-11-27 19:03:20.384457 Train Epoch: 33 [30/200 ]\tLoss: 0.001988\n",
      "Timestamp 2019-11-27 19:03:22.721400 Train Epoch: 33 [40/200 ]\tLoss: 0.002325\n",
      "Timestamp 2019-11-27 19:03:25.031142 Train Epoch: 33 [50/200 ]\tLoss: 0.001815\n",
      "Timestamp 2019-11-27 19:03:27.345323 Train Epoch: 33 [60/200 ]\tLoss: 0.002087\n",
      "Timestamp 2019-11-27 19:03:29.652904 Train Epoch: 33 [70/200 ]\tLoss: 0.002097\n",
      "Timestamp 2019-11-27 19:03:31.963570 Train Epoch: 33 [80/200 ]\tLoss: 0.001873\n",
      "Timestamp 2019-11-27 19:03:34.266560 Train Epoch: 33 [90/200 ]\tLoss: 0.001980\n",
      "Timestamp 2019-11-27 19:03:36.579581 Train Epoch: 33 [100/200 ]\tLoss: 0.002104\n",
      "Timestamp 2019-11-27 19:03:38.888556 Train Epoch: 33 [110/200 ]\tLoss: 0.001616\n",
      "Timestamp 2019-11-27 19:03:41.197728 Train Epoch: 33 [120/200 ]\tLoss: 0.001592\n",
      "Timestamp 2019-11-27 19:03:43.503233 Train Epoch: 33 [130/200 ]\tLoss: 0.002203\n",
      "Timestamp 2019-11-27 19:03:45.813564 Train Epoch: 33 [140/200 ]\tLoss: 0.001744\n",
      "Timestamp 2019-11-27 19:03:48.125228 Train Epoch: 33 [150/200 ]\tLoss: 0.002189\n",
      "Timestamp 2019-11-27 19:03:50.429979 Train Epoch: 33 [160/200 ]\tLoss: 0.002387\n",
      "Timestamp 2019-11-27 19:03:52.751634 Train Epoch: 33 [170/200 ]\tLoss: 0.002012\n",
      "Timestamp 2019-11-27 19:03:55.060915 Train Epoch: 33 [180/200 ]\tLoss: 0.001808\n",
      "Timestamp 2019-11-27 19:03:57.373769 Train Epoch: 33 [190/200 ]\tLoss: 0.002107\n",
      "Timestamp 2019-11-27 19:03:59.689077 Train Epoch: 33 [200/200 ]\tLoss: 0.002222\n",
      "====> Timestamp 2019-11-27 19:03:59.732680 Epoch: 33 Average loss: 0.00198425\n",
      "epoch: 33====> Test set loss: 0.14375339\n",
      "Timestamp 2019-11-27 19:04:13.110726 Train Epoch: 34 [10/200 ]\tLoss: 0.001583\n",
      "Timestamp 2019-11-27 19:04:15.419534 Train Epoch: 34 [20/200 ]\tLoss: 0.001724\n",
      "Timestamp 2019-11-27 19:04:17.719699 Train Epoch: 34 [30/200 ]\tLoss: 0.001931\n",
      "Timestamp 2019-11-27 19:04:20.019872 Train Epoch: 34 [40/200 ]\tLoss: 0.002281\n",
      "Timestamp 2019-11-27 19:04:22.342973 Train Epoch: 34 [50/200 ]\tLoss: 0.001796\n",
      "Timestamp 2019-11-27 19:04:24.641213 Train Epoch: 34 [60/200 ]\tLoss: 0.002062\n",
      "Timestamp 2019-11-27 19:04:26.947241 Train Epoch: 34 [70/200 ]\tLoss: 0.002077\n",
      "Timestamp 2019-11-27 19:04:29.251278 Train Epoch: 34 [80/200 ]\tLoss: 0.001890\n",
      "Timestamp 2019-11-27 19:04:31.556254 Train Epoch: 34 [90/200 ]\tLoss: 0.001919\n",
      "Timestamp 2019-11-27 19:04:33.861946 Train Epoch: 34 [100/200 ]\tLoss: 0.002059\n",
      "Timestamp 2019-11-27 19:04:36.163803 Train Epoch: 34 [110/200 ]\tLoss: 0.001587\n",
      "Timestamp 2019-11-27 19:04:38.462147 Train Epoch: 34 [120/200 ]\tLoss: 0.001567\n",
      "Timestamp 2019-11-27 19:04:40.759256 Train Epoch: 34 [130/200 ]\tLoss: 0.002132\n",
      "Timestamp 2019-11-27 19:04:43.057466 Train Epoch: 34 [140/200 ]\tLoss: 0.001713\n",
      "Timestamp 2019-11-27 19:04:45.360346 Train Epoch: 34 [150/200 ]\tLoss: 0.002167\n",
      "Timestamp 2019-11-27 19:04:47.667923 Train Epoch: 34 [160/200 ]\tLoss: 0.002364\n",
      "Timestamp 2019-11-27 19:04:49.975821 Train Epoch: 34 [170/200 ]\tLoss: 0.001975\n",
      "Timestamp 2019-11-27 19:04:52.309724 Train Epoch: 34 [180/200 ]\tLoss: 0.001777\n",
      "Timestamp 2019-11-27 19:04:54.614880 Train Epoch: 34 [190/200 ]\tLoss: 0.002085\n",
      "Timestamp 2019-11-27 19:04:56.923532 Train Epoch: 34 [200/200 ]\tLoss: 0.002189\n",
      "====> Timestamp 2019-11-27 19:04:56.973760 Epoch: 34 Average loss: 0.00195502\n",
      "epoch: 34====> Test set loss: 0.14341770\n",
      "Timestamp 2019-11-27 19:05:10.364828 Train Epoch: 35 [10/200 ]\tLoss: 0.001564\n",
      "Timestamp 2019-11-27 19:05:12.675142 Train Epoch: 35 [20/200 ]\tLoss: 0.001719\n",
      "Timestamp 2019-11-27 19:05:14.988381 Train Epoch: 35 [30/200 ]\tLoss: 0.001891\n",
      "Timestamp 2019-11-27 19:05:17.300313 Train Epoch: 35 [40/200 ]\tLoss: 0.002291\n",
      "Timestamp 2019-11-27 19:05:19.611216 Train Epoch: 35 [50/200 ]\tLoss: 0.001803\n",
      "Timestamp 2019-11-27 19:05:21.939213 Train Epoch: 35 [60/200 ]\tLoss: 0.002022\n",
      "Timestamp 2019-11-27 19:05:24.241591 Train Epoch: 35 [70/200 ]\tLoss: 0.002065\n",
      "Timestamp 2019-11-27 19:05:26.541283 Train Epoch: 35 [80/200 ]\tLoss: 0.001857\n",
      "Timestamp 2019-11-27 19:05:28.842550 Train Epoch: 35 [90/200 ]\tLoss: 0.001921\n",
      "Timestamp 2019-11-27 19:05:31.139151 Train Epoch: 35 [100/200 ]\tLoss: 0.002056\n",
      "Timestamp 2019-11-27 19:05:33.445334 Train Epoch: 35 [110/200 ]\tLoss: 0.001564\n",
      "Timestamp 2019-11-27 19:05:35.746188 Train Epoch: 35 [120/200 ]\tLoss: 0.001555\n",
      "Timestamp 2019-11-27 19:05:38.043121 Train Epoch: 35 [130/200 ]\tLoss: 0.002098\n",
      "Timestamp 2019-11-27 19:05:40.338724 Train Epoch: 35 [140/200 ]\tLoss: 0.001694\n",
      "Timestamp 2019-11-27 19:05:42.641930 Train Epoch: 35 [150/200 ]\tLoss: 0.002144\n",
      "Timestamp 2019-11-27 19:05:44.944531 Train Epoch: 35 [160/200 ]\tLoss: 0.002358\n",
      "Timestamp 2019-11-27 19:05:47.251294 Train Epoch: 35 [170/200 ]\tLoss: 0.001954\n",
      "Timestamp 2019-11-27 19:05:49.547663 Train Epoch: 35 [180/200 ]\tLoss: 0.001751\n",
      "Timestamp 2019-11-27 19:05:51.864805 Train Epoch: 35 [190/200 ]\tLoss: 0.002073\n",
      "Timestamp 2019-11-27 19:05:54.184754 Train Epoch: 35 [200/200 ]\tLoss: 0.002166\n",
      "====> Timestamp 2019-11-27 19:05:54.226191 Epoch: 35 Average loss: 0.00192880\n",
      "epoch: 35====> Test set loss: 0.14248417\n",
      "Timestamp 2019-11-27 19:06:07.605948 Train Epoch: 36 [10/200 ]\tLoss: 0.001530\n",
      "Timestamp 2019-11-27 19:06:09.912688 Train Epoch: 36 [20/200 ]\tLoss: 0.001711\n",
      "Timestamp 2019-11-27 19:06:12.228101 Train Epoch: 36 [30/200 ]\tLoss: 0.001903\n",
      "Timestamp 2019-11-27 19:06:14.539602 Train Epoch: 36 [40/200 ]\tLoss: 0.002202\n",
      "Timestamp 2019-11-27 19:06:16.845978 Train Epoch: 36 [50/200 ]\tLoss: 0.001792\n",
      "Timestamp 2019-11-27 19:06:19.159225 Train Epoch: 36 [60/200 ]\tLoss: 0.001970\n",
      "Timestamp 2019-11-27 19:06:21.474127 Train Epoch: 36 [70/200 ]\tLoss: 0.002018\n",
      "Timestamp 2019-11-27 19:06:23.808224 Train Epoch: 36 [80/200 ]\tLoss: 0.001812\n",
      "Timestamp 2019-11-27 19:06:26.117628 Train Epoch: 36 [90/200 ]\tLoss: 0.001906\n",
      "Timestamp 2019-11-27 19:06:28.430389 Train Epoch: 36 [100/200 ]\tLoss: 0.002020\n",
      "Timestamp 2019-11-27 19:06:30.740681 Train Epoch: 36 [110/200 ]\tLoss: 0.001530\n",
      "Timestamp 2019-11-27 19:06:33.045749 Train Epoch: 36 [120/200 ]\tLoss: 0.001543\n",
      "Timestamp 2019-11-27 19:06:35.347542 Train Epoch: 36 [130/200 ]\tLoss: 0.002049\n",
      "Timestamp 2019-11-27 19:06:37.658007 Train Epoch: 36 [140/200 ]\tLoss: 0.001691\n",
      "Timestamp 2019-11-27 19:06:39.961234 Train Epoch: 36 [150/200 ]\tLoss: 0.002074\n",
      "Timestamp 2019-11-27 19:06:42.266820 Train Epoch: 36 [160/200 ]\tLoss: 0.002304\n",
      "Timestamp 2019-11-27 19:06:44.578521 Train Epoch: 36 [170/200 ]\tLoss: 0.001954\n",
      "Timestamp 2019-11-27 19:06:46.886298 Train Epoch: 36 [180/200 ]\tLoss: 0.001745\n",
      "Timestamp 2019-11-27 19:06:49.195679 Train Epoch: 36 [190/200 ]\tLoss: 0.002032\n",
      "Timestamp 2019-11-27 19:06:51.509861 Train Epoch: 36 [200/200 ]\tLoss: 0.002130\n",
      "====> Timestamp 2019-11-27 19:06:51.553817 Epoch: 36 Average loss: 0.00190423\n",
      "epoch: 36====> Test set loss: 0.14200449\n",
      "Timestamp 2019-11-27 19:07:05.013058 Train Epoch: 37 [10/200 ]\tLoss: 0.001505\n",
      "Timestamp 2019-11-27 19:07:07.325773 Train Epoch: 37 [20/200 ]\tLoss: 0.001657\n",
      "Timestamp 2019-11-27 19:07:09.642525 Train Epoch: 37 [30/200 ]\tLoss: 0.001857\n",
      "Timestamp 2019-11-27 19:07:11.955126 Train Epoch: 37 [40/200 ]\tLoss: 0.002168\n",
      "Timestamp 2019-11-27 19:07:14.262511 Train Epoch: 37 [50/200 ]\tLoss: 0.001726\n",
      "Timestamp 2019-11-27 19:07:16.573484 Train Epoch: 37 [60/200 ]\tLoss: 0.001990\n",
      "Timestamp 2019-11-27 19:07:18.884004 Train Epoch: 37 [70/200 ]\tLoss: 0.002012\n",
      "Timestamp 2019-11-27 19:07:21.193610 Train Epoch: 37 [80/200 ]\tLoss: 0.001769\n",
      "Timestamp 2019-11-27 19:07:23.511936 Train Epoch: 37 [90/200 ]\tLoss: 0.001865\n",
      "Timestamp 2019-11-27 19:07:25.808750 Train Epoch: 37 [100/200 ]\tLoss: 0.002007\n",
      "Timestamp 2019-11-27 19:07:28.102934 Train Epoch: 37 [110/200 ]\tLoss: 0.001530\n",
      "Timestamp 2019-11-27 19:07:30.395845 Train Epoch: 37 [120/200 ]\tLoss: 0.001487\n",
      "Timestamp 2019-11-27 19:07:32.697025 Train Epoch: 37 [130/200 ]\tLoss: 0.002051\n",
      "Timestamp 2019-11-27 19:07:34.992448 Train Epoch: 37 [140/200 ]\tLoss: 0.001658\n",
      "Timestamp 2019-11-27 19:07:37.288107 Train Epoch: 37 [150/200 ]\tLoss: 0.002081\n",
      "Timestamp 2019-11-27 19:07:39.588039 Train Epoch: 37 [160/200 ]\tLoss: 0.002273\n",
      "Timestamp 2019-11-27 19:07:41.888514 Train Epoch: 37 [170/200 ]\tLoss: 0.001913\n",
      "Timestamp 2019-11-27 19:07:44.184736 Train Epoch: 37 [180/200 ]\tLoss: 0.001741\n",
      "Timestamp 2019-11-27 19:07:46.482874 Train Epoch: 37 [190/200 ]\tLoss: 0.002006\n",
      "Timestamp 2019-11-27 19:07:48.790364 Train Epoch: 37 [200/200 ]\tLoss: 0.002092\n",
      "====> Timestamp 2019-11-27 19:07:48.836270 Epoch: 37 Average loss: 0.00187827\n",
      "epoch: 37====> Test set loss: 0.14228630\n",
      "Timestamp 2019-11-27 19:08:02.339790 Train Epoch: 38 [10/200 ]\tLoss: 0.001510\n",
      "Timestamp 2019-11-27 19:08:04.651779 Train Epoch: 38 [20/200 ]\tLoss: 0.001671\n",
      "Timestamp 2019-11-27 19:08:06.964021 Train Epoch: 38 [30/200 ]\tLoss: 0.001826\n",
      "Timestamp 2019-11-27 19:08:09.272314 Train Epoch: 38 [40/200 ]\tLoss: 0.002191\n",
      "Timestamp 2019-11-27 19:08:11.587087 Train Epoch: 38 [50/200 ]\tLoss: 0.001722\n",
      "Timestamp 2019-11-27 19:08:13.892227 Train Epoch: 38 [60/200 ]\tLoss: 0.001945\n",
      "Timestamp 2019-11-27 19:08:16.198823 Train Epoch: 38 [70/200 ]\tLoss: 0.001981\n",
      "Timestamp 2019-11-27 19:08:18.512858 Train Epoch: 38 [80/200 ]\tLoss: 0.001757\n",
      "Timestamp 2019-11-27 19:08:20.829018 Train Epoch: 38 [90/200 ]\tLoss: 0.001835\n",
      "Timestamp 2019-11-27 19:08:23.147562 Train Epoch: 38 [100/200 ]\tLoss: 0.001965\n",
      "Timestamp 2019-11-27 19:08:25.453711 Train Epoch: 38 [110/200 ]\tLoss: 0.001500\n",
      "Timestamp 2019-11-27 19:08:27.766254 Train Epoch: 38 [120/200 ]\tLoss: 0.001454\n",
      "Timestamp 2019-11-27 19:08:30.071879 Train Epoch: 38 [130/200 ]\tLoss: 0.001990\n",
      "Timestamp 2019-11-27 19:08:32.386572 Train Epoch: 38 [140/200 ]\tLoss: 0.001625\n",
      "Timestamp 2019-11-27 19:08:34.693337 Train Epoch: 38 [150/200 ]\tLoss: 0.002058\n",
      "Timestamp 2019-11-27 19:08:37.001494 Train Epoch: 38 [160/200 ]\tLoss: 0.002261\n",
      "Timestamp 2019-11-27 19:08:39.310076 Train Epoch: 38 [170/200 ]\tLoss: 0.001873\n",
      "Timestamp 2019-11-27 19:08:41.623807 Train Epoch: 38 [180/200 ]\tLoss: 0.001674\n",
      "Timestamp 2019-11-27 19:08:43.923309 Train Epoch: 38 [190/200 ]\tLoss: 0.002005\n",
      "Timestamp 2019-11-27 19:08:46.222998 Train Epoch: 38 [200/200 ]\tLoss: 0.002077\n",
      "====> Timestamp 2019-11-27 19:08:46.266311 Epoch: 38 Average loss: 0.00185406\n",
      "epoch: 38====> Test set loss: 0.14136864\n",
      "Timestamp 2019-11-27 19:09:00.061152 Train Epoch: 39 [10/200 ]\tLoss: 0.001480\n",
      "Timestamp 2019-11-27 19:09:02.460986 Train Epoch: 39 [20/200 ]\tLoss: 0.001651\n",
      "Timestamp 2019-11-27 19:09:04.867813 Train Epoch: 39 [30/200 ]\tLoss: 0.001829\n",
      "Timestamp 2019-11-27 19:09:07.281535 Train Epoch: 39 [40/200 ]\tLoss: 0.002155\n",
      "Timestamp 2019-11-27 19:09:09.790209 Train Epoch: 39 [50/200 ]\tLoss: 0.001684\n",
      "Timestamp 2019-11-27 19:09:12.273203 Train Epoch: 39 [60/200 ]\tLoss: 0.001912\n",
      "Timestamp 2019-11-27 19:09:14.743297 Train Epoch: 39 [70/200 ]\tLoss: 0.001936\n",
      "Timestamp 2019-11-27 19:09:17.250744 Train Epoch: 39 [80/200 ]\tLoss: 0.001742\n",
      "Timestamp 2019-11-27 19:09:19.686969 Train Epoch: 39 [90/200 ]\tLoss: 0.001825\n",
      "Timestamp 2019-11-27 19:09:22.126327 Train Epoch: 39 [100/200 ]\tLoss: 0.001908\n",
      "Timestamp 2019-11-27 19:09:24.548644 Train Epoch: 39 [110/200 ]\tLoss: 0.001448\n",
      "Timestamp 2019-11-27 19:09:26.949789 Train Epoch: 39 [120/200 ]\tLoss: 0.001441\n",
      "Timestamp 2019-11-27 19:09:29.349307 Train Epoch: 39 [130/200 ]\tLoss: 0.001979\n",
      "Timestamp 2019-11-27 19:09:31.889020 Train Epoch: 39 [140/200 ]\tLoss: 0.001592\n",
      "Timestamp 2019-11-27 19:09:34.329466 Train Epoch: 39 [150/200 ]\tLoss: 0.002015\n",
      "Timestamp 2019-11-27 19:09:36.751522 Train Epoch: 39 [160/200 ]\tLoss: 0.002244\n",
      "Timestamp 2019-11-27 19:09:39.151247 Train Epoch: 39 [170/200 ]\tLoss: 0.001872\n",
      "Timestamp 2019-11-27 19:09:41.522655 Train Epoch: 39 [180/200 ]\tLoss: 0.001674\n",
      "Timestamp 2019-11-27 19:09:43.890880 Train Epoch: 39 [190/200 ]\tLoss: 0.001944\n",
      "Timestamp 2019-11-27 19:09:46.263726 Train Epoch: 39 [200/200 ]\tLoss: 0.002076\n",
      "====> Timestamp 2019-11-27 19:09:46.307506 Epoch: 39 Average loss: 0.00183186\n",
      "epoch: 39====> Test set loss: 0.14157322\n",
      "Timestamp 2019-11-27 19:10:00.471598 Train Epoch: 40 [10/200 ]\tLoss: 0.001421\n",
      "Timestamp 2019-11-27 19:10:02.870275 Train Epoch: 40 [20/200 ]\tLoss: 0.001654\n",
      "Timestamp 2019-11-27 19:10:05.247882 Train Epoch: 40 [30/200 ]\tLoss: 0.001762\n",
      "Timestamp 2019-11-27 19:10:07.625734 Train Epoch: 40 [40/200 ]\tLoss: 0.002150\n",
      "Timestamp 2019-11-27 19:10:10.018363 Train Epoch: 40 [50/200 ]\tLoss: 0.001651\n",
      "Timestamp 2019-11-27 19:10:12.419332 Train Epoch: 40 [60/200 ]\tLoss: 0.001850\n",
      "Timestamp 2019-11-27 19:10:14.884735 Train Epoch: 40 [70/200 ]\tLoss: 0.001919\n",
      "Timestamp 2019-11-27 19:10:17.420396 Train Epoch: 40 [80/200 ]\tLoss: 0.001691\n",
      "Timestamp 2019-11-27 19:10:19.885097 Train Epoch: 40 [90/200 ]\tLoss: 0.001816\n",
      "Timestamp 2019-11-27 19:10:22.382725 Train Epoch: 40 [100/200 ]\tLoss: 0.001924\n",
      "Timestamp 2019-11-27 19:10:24.834539 Train Epoch: 40 [110/200 ]\tLoss: 0.001461\n",
      "Timestamp 2019-11-27 19:10:27.342412 Train Epoch: 40 [120/200 ]\tLoss: 0.001445\n",
      "Timestamp 2019-11-27 19:10:29.854019 Train Epoch: 40 [130/200 ]\tLoss: 0.001944\n",
      "Timestamp 2019-11-27 19:10:32.343003 Train Epoch: 40 [140/200 ]\tLoss: 0.001590\n",
      "Timestamp 2019-11-27 19:10:34.797557 Train Epoch: 40 [150/200 ]\tLoss: 0.001996\n",
      "Timestamp 2019-11-27 19:10:37.265001 Train Epoch: 40 [160/200 ]\tLoss: 0.002216\n",
      "Timestamp 2019-11-27 19:10:39.774261 Train Epoch: 40 [170/200 ]\tLoss: 0.001833\n",
      "Timestamp 2019-11-27 19:10:42.184590 Train Epoch: 40 [180/200 ]\tLoss: 0.001625\n",
      "Timestamp 2019-11-27 19:10:44.612715 Train Epoch: 40 [190/200 ]\tLoss: 0.001962\n",
      "Timestamp 2019-11-27 19:10:47.109325 Train Epoch: 40 [200/200 ]\tLoss: 0.002045\n",
      "====> Timestamp 2019-11-27 19:10:47.153385 Epoch: 40 Average loss: 0.00180636\n",
      "epoch: 40====> Test set loss: 0.14100345\n",
      "Timestamp 2019-11-27 19:11:01.478271 Train Epoch: 41 [10/200 ]\tLoss: 0.001403\n",
      "Timestamp 2019-11-27 19:11:03.905338 Train Epoch: 41 [20/200 ]\tLoss: 0.001608\n",
      "Timestamp 2019-11-27 19:11:06.317932 Train Epoch: 41 [30/200 ]\tLoss: 0.001792\n",
      "Timestamp 2019-11-27 19:11:08.720812 Train Epoch: 41 [40/200 ]\tLoss: 0.002090\n",
      "Timestamp 2019-11-27 19:11:11.143324 Train Epoch: 41 [50/200 ]\tLoss: 0.001596\n",
      "Timestamp 2019-11-27 19:11:13.634928 Train Epoch: 41 [60/200 ]\tLoss: 0.001892\n",
      "Timestamp 2019-11-27 19:11:16.020342 Train Epoch: 41 [70/200 ]\tLoss: 0.001885\n",
      "Timestamp 2019-11-27 19:11:18.434718 Train Epoch: 41 [80/200 ]\tLoss: 0.001703\n",
      "Timestamp 2019-11-27 19:11:20.960667 Train Epoch: 41 [90/200 ]\tLoss: 0.001786\n",
      "Timestamp 2019-11-27 19:11:23.427781 Train Epoch: 41 [100/200 ]\tLoss: 0.001884\n",
      "Timestamp 2019-11-27 19:11:25.897275 Train Epoch: 41 [110/200 ]\tLoss: 0.001436\n",
      "Timestamp 2019-11-27 19:11:28.355989 Train Epoch: 41 [120/200 ]\tLoss: 0.001372\n",
      "Timestamp 2019-11-27 19:11:30.742742 Train Epoch: 41 [130/200 ]\tLoss: 0.001893\n",
      "Timestamp 2019-11-27 19:11:33.157742 Train Epoch: 41 [140/200 ]\tLoss: 0.001577\n",
      "Timestamp 2019-11-27 19:11:35.615826 Train Epoch: 41 [150/200 ]\tLoss: 0.001967\n",
      "Timestamp 2019-11-27 19:11:38.067791 Train Epoch: 41 [160/200 ]\tLoss: 0.002216\n",
      "Timestamp 2019-11-27 19:11:40.438741 Train Epoch: 41 [170/200 ]\tLoss: 0.001827\n",
      "Timestamp 2019-11-27 19:11:42.889452 Train Epoch: 41 [180/200 ]\tLoss: 0.001595\n",
      "Timestamp 2019-11-27 19:11:45.260035 Train Epoch: 41 [190/200 ]\tLoss: 0.001950\n",
      "Timestamp 2019-11-27 19:11:47.702897 Train Epoch: 41 [200/200 ]\tLoss: 0.002028\n",
      "====> Timestamp 2019-11-27 19:11:47.746436 Epoch: 41 Average loss: 0.00178528\n",
      "epoch: 41====> Test set loss: 0.14109362\n",
      "Timestamp 2019-11-27 19:12:02.030506 Train Epoch: 42 [10/200 ]\tLoss: 0.001375\n",
      "Timestamp 2019-11-27 19:12:04.444233 Train Epoch: 42 [20/200 ]\tLoss: 0.001550\n",
      "Timestamp 2019-11-27 19:12:06.944863 Train Epoch: 42 [30/200 ]\tLoss: 0.001761\n",
      "Timestamp 2019-11-27 19:12:09.348912 Train Epoch: 42 [40/200 ]\tLoss: 0.002084\n",
      "Timestamp 2019-11-27 19:12:11.814826 Train Epoch: 42 [50/200 ]\tLoss: 0.001632\n",
      "Timestamp 2019-11-27 19:12:14.322236 Train Epoch: 42 [60/200 ]\tLoss: 0.001863\n",
      "Timestamp 2019-11-27 19:12:16.828707 Train Epoch: 42 [70/200 ]\tLoss: 0.001879\n",
      "Timestamp 2019-11-27 19:12:19.272787 Train Epoch: 42 [80/200 ]\tLoss: 0.001676\n",
      "Timestamp 2019-11-27 19:12:21.772325 Train Epoch: 42 [90/200 ]\tLoss: 0.001775\n",
      "Timestamp 2019-11-27 19:12:24.283502 Train Epoch: 42 [100/200 ]\tLoss: 0.001870\n",
      "Timestamp 2019-11-27 19:12:26.669589 Train Epoch: 42 [110/200 ]\tLoss: 0.001421\n",
      "Timestamp 2019-11-27 19:12:29.113971 Train Epoch: 42 [120/200 ]\tLoss: 0.001391\n",
      "Timestamp 2019-11-27 19:12:31.574405 Train Epoch: 42 [130/200 ]\tLoss: 0.001857\n",
      "Timestamp 2019-11-27 19:12:34.013873 Train Epoch: 42 [140/200 ]\tLoss: 0.001575\n",
      "Timestamp 2019-11-27 19:12:36.462279 Train Epoch: 42 [150/200 ]\tLoss: 0.001918\n",
      "Timestamp 2019-11-27 19:12:38.890894 Train Epoch: 42 [160/200 ]\tLoss: 0.002143\n",
      "Timestamp 2019-11-27 19:12:41.340940 Train Epoch: 42 [170/200 ]\tLoss: 0.001812\n",
      "Timestamp 2019-11-27 19:12:43.804276 Train Epoch: 42 [180/200 ]\tLoss: 0.001577\n",
      "Timestamp 2019-11-27 19:12:46.225258 Train Epoch: 42 [190/200 ]\tLoss: 0.001930\n",
      "Timestamp 2019-11-27 19:12:48.660397 Train Epoch: 42 [200/200 ]\tLoss: 0.001977\n",
      "====> Timestamp 2019-11-27 19:12:48.704398 Epoch: 42 Average loss: 0.00176520\n",
      "epoch: 42====> Test set loss: 0.14027132\n",
      "Timestamp 2019-11-27 19:13:02.716038 Train Epoch: 43 [10/200 ]\tLoss: 0.001382\n",
      "Timestamp 2019-11-27 19:13:05.213362 Train Epoch: 43 [20/200 ]\tLoss: 0.001556\n",
      "Timestamp 2019-11-27 19:13:07.745313 Train Epoch: 43 [30/200 ]\tLoss: 0.001721\n",
      "Timestamp 2019-11-27 19:13:10.177251 Train Epoch: 43 [40/200 ]\tLoss: 0.002083\n",
      "Timestamp 2019-11-27 19:13:12.566829 Train Epoch: 43 [50/200 ]\tLoss: 0.001591\n",
      "Timestamp 2019-11-27 19:13:14.948577 Train Epoch: 43 [60/200 ]\tLoss: 0.001850\n",
      "Timestamp 2019-11-27 19:13:17.487051 Train Epoch: 43 [70/200 ]\tLoss: 0.001833\n",
      "Timestamp 2019-11-27 19:13:20.020766 Train Epoch: 43 [80/200 ]\tLoss: 0.001633\n",
      "Timestamp 2019-11-27 19:13:22.499007 Train Epoch: 43 [90/200 ]\tLoss: 0.001709\n",
      "Timestamp 2019-11-27 19:13:24.972370 Train Epoch: 43 [100/200 ]\tLoss: 0.001862\n",
      "Timestamp 2019-11-27 19:13:27.439147 Train Epoch: 43 [110/200 ]\tLoss: 0.001385\n",
      "Timestamp 2019-11-27 19:13:29.996399 Train Epoch: 43 [120/200 ]\tLoss: 0.001360\n",
      "Timestamp 2019-11-27 19:13:32.412527 Train Epoch: 43 [130/200 ]\tLoss: 0.001837\n",
      "Timestamp 2019-11-27 19:13:34.783079 Train Epoch: 43 [140/200 ]\tLoss: 0.001556\n",
      "Timestamp 2019-11-27 19:13:37.192836 Train Epoch: 43 [150/200 ]\tLoss: 0.001929\n",
      "Timestamp 2019-11-27 19:13:39.606942 Train Epoch: 43 [160/200 ]\tLoss: 0.002144\n",
      "Timestamp 2019-11-27 19:13:42.063130 Train Epoch: 43 [170/200 ]\tLoss: 0.001790\n",
      "Timestamp 2019-11-27 19:13:44.476365 Train Epoch: 43 [180/200 ]\tLoss: 0.001571\n",
      "Timestamp 2019-11-27 19:13:46.932763 Train Epoch: 43 [190/200 ]\tLoss: 0.001912\n",
      "Timestamp 2019-11-27 19:13:49.403724 Train Epoch: 43 [200/200 ]\tLoss: 0.001968\n",
      "====> Timestamp 2019-11-27 19:13:49.446470 Epoch: 43 Average loss: 0.00173985\n",
      "epoch: 43====> Test set loss: 0.14049560\n",
      "Timestamp 2019-11-27 19:14:03.272621 Train Epoch: 44 [10/200 ]\tLoss: 0.001387\n",
      "Timestamp 2019-11-27 19:14:05.672935 Train Epoch: 44 [20/200 ]\tLoss: 0.001568\n",
      "Timestamp 2019-11-27 19:14:08.077608 Train Epoch: 44 [30/200 ]\tLoss: 0.001678\n",
      "Timestamp 2019-11-27 19:14:10.465199 Train Epoch: 44 [40/200 ]\tLoss: 0.002059\n",
      "Timestamp 2019-11-27 19:14:12.877631 Train Epoch: 44 [50/200 ]\tLoss: 0.001593\n",
      "Timestamp 2019-11-27 19:14:15.274492 Train Epoch: 44 [60/200 ]\tLoss: 0.001845\n",
      "Timestamp 2019-11-27 19:14:17.680826 Train Epoch: 44 [70/200 ]\tLoss: 0.001827\n",
      "Timestamp 2019-11-27 19:14:20.080174 Train Epoch: 44 [80/200 ]\tLoss: 0.001594\n",
      "Timestamp 2019-11-27 19:14:22.490292 Train Epoch: 44 [90/200 ]\tLoss: 0.001701\n",
      "Timestamp 2019-11-27 19:14:24.890102 Train Epoch: 44 [100/200 ]\tLoss: 0.001843\n",
      "Timestamp 2019-11-27 19:14:27.304434 Train Epoch: 44 [110/200 ]\tLoss: 0.001352\n",
      "Timestamp 2019-11-27 19:14:29.748708 Train Epoch: 44 [120/200 ]\tLoss: 0.001346\n",
      "Timestamp 2019-11-27 19:14:32.223996 Train Epoch: 44 [130/200 ]\tLoss: 0.001821\n",
      "Timestamp 2019-11-27 19:14:34.601776 Train Epoch: 44 [140/200 ]\tLoss: 0.001517\n",
      "Timestamp 2019-11-27 19:14:36.976555 Train Epoch: 44 [150/200 ]\tLoss: 0.001887\n",
      "Timestamp 2019-11-27 19:14:39.373199 Train Epoch: 44 [160/200 ]\tLoss: 0.002148\n",
      "Timestamp 2019-11-27 19:14:41.751187 Train Epoch: 44 [170/200 ]\tLoss: 0.001785\n",
      "Timestamp 2019-11-27 19:14:44.146842 Train Epoch: 44 [180/200 ]\tLoss: 0.001556\n",
      "Timestamp 2019-11-27 19:14:46.542387 Train Epoch: 44 [190/200 ]\tLoss: 0.001888\n",
      "Timestamp 2019-11-27 19:14:48.959549 Train Epoch: 44 [200/200 ]\tLoss: 0.001910\n",
      "====> Timestamp 2019-11-27 19:14:49.002803 Epoch: 44 Average loss: 0.00172117\n",
      "epoch: 44====> Test set loss: 0.14078983\n",
      "Timestamp 2019-11-27 19:15:03.063830 Train Epoch: 45 [10/200 ]\tLoss: 0.001350\n",
      "Timestamp 2019-11-27 19:15:05.464515 Train Epoch: 45 [20/200 ]\tLoss: 0.001569\n",
      "Timestamp 2019-11-27 19:15:08.010303 Train Epoch: 45 [30/200 ]\tLoss: 0.001680\n",
      "Timestamp 2019-11-27 19:15:10.410815 Train Epoch: 45 [40/200 ]\tLoss: 0.002033\n",
      "Timestamp 2019-11-27 19:15:12.788483 Train Epoch: 45 [50/200 ]\tLoss: 0.001599\n",
      "Timestamp 2019-11-27 19:15:15.215364 Train Epoch: 45 [60/200 ]\tLoss: 0.001746\n",
      "Timestamp 2019-11-27 19:15:17.611878 Train Epoch: 45 [70/200 ]\tLoss: 0.001811\n",
      "Timestamp 2019-11-27 19:15:20.050669 Train Epoch: 45 [80/200 ]\tLoss: 0.001615\n",
      "Timestamp 2019-11-27 19:15:22.458163 Train Epoch: 45 [90/200 ]\tLoss: 0.001723\n",
      "Timestamp 2019-11-27 19:15:24.865192 Train Epoch: 45 [100/200 ]\tLoss: 0.001801\n",
      "Timestamp 2019-11-27 19:15:27.332981 Train Epoch: 45 [110/200 ]\tLoss: 0.001364\n",
      "Timestamp 2019-11-27 19:15:29.826039 Train Epoch: 45 [120/200 ]\tLoss: 0.001334\n",
      "Timestamp 2019-11-27 19:15:32.314638 Train Epoch: 45 [130/200 ]\tLoss: 0.001821\n",
      "Timestamp 2019-11-27 19:15:34.762032 Train Epoch: 45 [140/200 ]\tLoss: 0.001498\n",
      "Timestamp 2019-11-27 19:15:37.165449 Train Epoch: 45 [150/200 ]\tLoss: 0.001839\n",
      "Timestamp 2019-11-27 19:15:39.624432 Train Epoch: 45 [160/200 ]\tLoss: 0.002096\n",
      "Timestamp 2019-11-27 19:15:42.143847 Train Epoch: 45 [170/200 ]\tLoss: 0.001728\n",
      "Timestamp 2019-11-27 19:15:44.579078 Train Epoch: 45 [180/200 ]\tLoss: 0.001551\n",
      "Timestamp 2019-11-27 19:15:46.970166 Train Epoch: 45 [190/200 ]\tLoss: 0.001877\n",
      "Timestamp 2019-11-27 19:15:49.396164 Train Epoch: 45 [200/200 ]\tLoss: 0.001915\n",
      "====> Timestamp 2019-11-27 19:15:49.440803 Epoch: 45 Average loss: 0.00170585\n",
      "epoch: 45====> Test set loss: 0.14043623\n",
      "Timestamp 2019-11-27 19:16:03.395189 Train Epoch: 46 [10/200 ]\tLoss: 0.001367\n",
      "Timestamp 2019-11-27 19:16:05.808987 Train Epoch: 46 [20/200 ]\tLoss: 0.001552\n",
      "Timestamp 2019-11-27 19:16:08.196976 Train Epoch: 46 [30/200 ]\tLoss: 0.001658\n",
      "Timestamp 2019-11-27 19:16:10.643217 Train Epoch: 46 [40/200 ]\tLoss: 0.001973\n",
      "Timestamp 2019-11-27 19:16:13.162161 Train Epoch: 46 [50/200 ]\tLoss: 0.001575\n",
      "Timestamp 2019-11-27 19:16:15.564601 Train Epoch: 46 [60/200 ]\tLoss: 0.001787\n",
      "Timestamp 2019-11-27 19:16:17.957566 Train Epoch: 46 [70/200 ]\tLoss: 0.001751\n",
      "Timestamp 2019-11-27 19:16:20.321059 Train Epoch: 46 [80/200 ]\tLoss: 0.001565\n",
      "Timestamp 2019-11-27 19:16:22.691329 Train Epoch: 46 [90/200 ]\tLoss: 0.001689\n",
      "Timestamp 2019-11-27 19:16:25.065254 Train Epoch: 46 [100/200 ]\tLoss: 0.001782\n",
      "Timestamp 2019-11-27 19:16:27.435683 Train Epoch: 46 [110/200 ]\tLoss: 0.001335\n",
      "Timestamp 2019-11-27 19:16:29.803252 Train Epoch: 46 [120/200 ]\tLoss: 0.001323\n",
      "Timestamp 2019-11-27 19:16:32.177696 Train Epoch: 46 [130/200 ]\tLoss: 0.001801\n",
      "Timestamp 2019-11-27 19:16:34.550752 Train Epoch: 46 [140/200 ]\tLoss: 0.001485\n",
      "Timestamp 2019-11-27 19:16:36.918628 Train Epoch: 46 [150/200 ]\tLoss: 0.001862\n",
      "Timestamp 2019-11-27 19:16:39.293156 Train Epoch: 46 [160/200 ]\tLoss: 0.002083\n",
      "Timestamp 2019-11-27 19:16:41.667987 Train Epoch: 46 [170/200 ]\tLoss: 0.001728\n",
      "Timestamp 2019-11-27 19:16:44.035586 Train Epoch: 46 [180/200 ]\tLoss: 0.001504\n",
      "Timestamp 2019-11-27 19:16:46.403407 Train Epoch: 46 [190/200 ]\tLoss: 0.001834\n",
      "Timestamp 2019-11-27 19:16:48.794297 Train Epoch: 46 [200/200 ]\tLoss: 0.001933\n",
      "====> Timestamp 2019-11-27 19:16:48.839086 Epoch: 46 Average loss: 0.00168713\n",
      "epoch: 46====> Test set loss: 0.14068812\n",
      "Timestamp 2019-11-27 19:17:02.611671 Train Epoch: 47 [10/200 ]\tLoss: 0.001320\n",
      "Timestamp 2019-11-27 19:17:04.989944 Train Epoch: 47 [20/200 ]\tLoss: 0.001538\n",
      "Timestamp 2019-11-27 19:17:07.356927 Train Epoch: 47 [30/200 ]\tLoss: 0.001664\n",
      "Timestamp 2019-11-27 19:17:09.738915 Train Epoch: 47 [40/200 ]\tLoss: 0.001983\n",
      "Timestamp 2019-11-27 19:17:12.108424 Train Epoch: 47 [50/200 ]\tLoss: 0.001528\n",
      "Timestamp 2019-11-27 19:17:14.486716 Train Epoch: 47 [60/200 ]\tLoss: 0.001761\n",
      "Timestamp 2019-11-27 19:17:16.854735 Train Epoch: 47 [70/200 ]\tLoss: 0.001758\n",
      "Timestamp 2019-11-27 19:17:19.247439 Train Epoch: 47 [80/200 ]\tLoss: 0.001561\n",
      "Timestamp 2019-11-27 19:17:21.629954 Train Epoch: 47 [90/200 ]\tLoss: 0.001691\n",
      "Timestamp 2019-11-27 19:17:23.996603 Train Epoch: 47 [100/200 ]\tLoss: 0.001780\n",
      "Timestamp 2019-11-27 19:17:26.361569 Train Epoch: 47 [110/200 ]\tLoss: 0.001355\n",
      "Timestamp 2019-11-27 19:17:28.746044 Train Epoch: 47 [120/200 ]\tLoss: 0.001310\n",
      "Timestamp 2019-11-27 19:17:31.155191 Train Epoch: 47 [130/200 ]\tLoss: 0.001757\n",
      "Timestamp 2019-11-27 19:17:33.527394 Train Epoch: 47 [140/200 ]\tLoss: 0.001531\n",
      "Timestamp 2019-11-27 19:17:35.904126 Train Epoch: 47 [150/200 ]\tLoss: 0.001795\n",
      "Timestamp 2019-11-27 19:17:38.265705 Train Epoch: 47 [160/200 ]\tLoss: 0.002079\n",
      "Timestamp 2019-11-27 19:17:40.632373 Train Epoch: 47 [170/200 ]\tLoss: 0.001700\n",
      "Timestamp 2019-11-27 19:17:42.998113 Train Epoch: 47 [180/200 ]\tLoss: 0.001479\n",
      "Timestamp 2019-11-27 19:17:45.377729 Train Epoch: 47 [190/200 ]\tLoss: 0.001841\n",
      "Timestamp 2019-11-27 19:17:47.758629 Train Epoch: 47 [200/200 ]\tLoss: 0.001880\n",
      "====> Timestamp 2019-11-27 19:17:47.803384 Epoch: 47 Average loss: 0.00166835\n",
      "epoch: 47====> Test set loss: 0.14041193\n",
      "Timestamp 2019-11-27 19:18:01.590990 Train Epoch: 48 [10/200 ]\tLoss: 0.001349\n",
      "Timestamp 2019-11-27 19:18:03.954450 Train Epoch: 48 [20/200 ]\tLoss: 0.001516\n",
      "Timestamp 2019-11-27 19:18:06.318815 Train Epoch: 48 [30/200 ]\tLoss: 0.001594\n",
      "Timestamp 2019-11-27 19:18:08.681624 Train Epoch: 48 [40/200 ]\tLoss: 0.001972\n",
      "Timestamp 2019-11-27 19:18:11.061650 Train Epoch: 48 [50/200 ]\tLoss: 0.001521\n",
      "Timestamp 2019-11-27 19:18:13.422258 Train Epoch: 48 [60/200 ]\tLoss: 0.001749\n",
      "Timestamp 2019-11-27 19:18:15.784512 Train Epoch: 48 [70/200 ]\tLoss: 0.001743\n",
      "Timestamp 2019-11-27 19:18:18.149837 Train Epoch: 48 [80/200 ]\tLoss: 0.001522\n",
      "Timestamp 2019-11-27 19:18:20.515520 Train Epoch: 48 [90/200 ]\tLoss: 0.001563\n",
      "Timestamp 2019-11-27 19:18:22.890428 Train Epoch: 48 [100/200 ]\tLoss: 0.001789\n",
      "Timestamp 2019-11-27 19:18:25.251218 Train Epoch: 48 [110/200 ]\tLoss: 0.001301\n",
      "Timestamp 2019-11-27 19:18:27.612282 Train Epoch: 48 [120/200 ]\tLoss: 0.001261\n",
      "Timestamp 2019-11-27 19:18:29.973789 Train Epoch: 48 [130/200 ]\tLoss: 0.001759\n",
      "Timestamp 2019-11-27 19:18:32.343483 Train Epoch: 48 [140/200 ]\tLoss: 0.001525\n",
      "Timestamp 2019-11-27 19:18:34.707043 Train Epoch: 48 [150/200 ]\tLoss: 0.001838\n",
      "Timestamp 2019-11-27 19:18:37.063698 Train Epoch: 48 [160/200 ]\tLoss: 0.002022\n",
      "Timestamp 2019-11-27 19:18:39.425875 Train Epoch: 48 [170/200 ]\tLoss: 0.001702\n",
      "Timestamp 2019-11-27 19:18:41.783866 Train Epoch: 48 [180/200 ]\tLoss: 0.001442\n",
      "Timestamp 2019-11-27 19:18:44.142042 Train Epoch: 48 [190/200 ]\tLoss: 0.001833\n",
      "Timestamp 2019-11-27 19:18:46.507466 Train Epoch: 48 [200/200 ]\tLoss: 0.001875\n",
      "====> Timestamp 2019-11-27 19:18:46.550143 Epoch: 48 Average loss: 0.00164927\n",
      "epoch: 48====> Test set loss: 0.14007586\n",
      "Timestamp 2019-11-27 19:19:00.348900 Train Epoch: 49 [10/200 ]\tLoss: 0.001295\n",
      "Timestamp 2019-11-27 19:19:02.727206 Train Epoch: 49 [20/200 ]\tLoss: 0.001463\n",
      "Timestamp 2019-11-27 19:19:05.094256 Train Epoch: 49 [30/200 ]\tLoss: 0.001629\n",
      "Timestamp 2019-11-27 19:19:07.480038 Train Epoch: 49 [40/200 ]\tLoss: 0.001924\n",
      "Timestamp 2019-11-27 19:19:09.904628 Train Epoch: 49 [50/200 ]\tLoss: 0.001494\n",
      "Timestamp 2019-11-27 19:19:12.409712 Train Epoch: 49 [60/200 ]\tLoss: 0.001713\n",
      "Timestamp 2019-11-27 19:19:14.786993 Train Epoch: 49 [70/200 ]\tLoss: 0.001739\n",
      "Timestamp 2019-11-27 19:19:17.195939 Train Epoch: 49 [80/200 ]\tLoss: 0.001517\n",
      "Timestamp 2019-11-27 19:19:19.677593 Train Epoch: 49 [90/200 ]\tLoss: 0.001610\n",
      "Timestamp 2019-11-27 19:19:22.197420 Train Epoch: 49 [100/200 ]\tLoss: 0.001736\n",
      "Timestamp 2019-11-27 19:19:24.731453 Train Epoch: 49 [110/200 ]\tLoss: 0.001281\n",
      "Timestamp 2019-11-27 19:19:27.254958 Train Epoch: 49 [120/200 ]\tLoss: 0.001281\n",
      "Timestamp 2019-11-27 19:19:29.793135 Train Epoch: 49 [130/200 ]\tLoss: 0.001713\n",
      "Timestamp 2019-11-27 19:19:32.241749 Train Epoch: 49 [140/200 ]\tLoss: 0.001485\n",
      "Timestamp 2019-11-27 19:19:34.615211 Train Epoch: 49 [150/200 ]\tLoss: 0.001805\n",
      "Timestamp 2019-11-27 19:19:36.986008 Train Epoch: 49 [160/200 ]\tLoss: 0.002026\n",
      "Timestamp 2019-11-27 19:19:39.391176 Train Epoch: 49 [170/200 ]\tLoss: 0.001692\n",
      "Timestamp 2019-11-27 19:19:41.764295 Train Epoch: 49 [180/200 ]\tLoss: 0.001441\n",
      "Timestamp 2019-11-27 19:19:44.129207 Train Epoch: 49 [190/200 ]\tLoss: 0.001804\n",
      "Timestamp 2019-11-27 19:19:46.493101 Train Epoch: 49 [200/200 ]\tLoss: 0.001825\n",
      "====> Timestamp 2019-11-27 19:19:46.537611 Epoch: 49 Average loss: 0.00163467\n",
      "epoch: 49====> Test set loss: 0.13946624\n",
      "Timestamp 2019-11-27 19:20:00.642383 Train Epoch: 50 [10/200 ]\tLoss: 0.001274\n",
      "Timestamp 2019-11-27 19:20:03.043029 Train Epoch: 50 [20/200 ]\tLoss: 0.001466\n",
      "Timestamp 2019-11-27 19:20:05.477904 Train Epoch: 50 [30/200 ]\tLoss: 0.001562\n",
      "Timestamp 2019-11-27 19:20:08.018690 Train Epoch: 50 [40/200 ]\tLoss: 0.001908\n",
      "Timestamp 2019-11-27 19:20:10.464059 Train Epoch: 50 [50/200 ]\tLoss: 0.001477\n",
      "Timestamp 2019-11-27 19:20:12.868223 Train Epoch: 50 [60/200 ]\tLoss: 0.001752\n",
      "Timestamp 2019-11-27 19:20:15.288678 Train Epoch: 50 [70/200 ]\tLoss: 0.001729\n",
      "Timestamp 2019-11-27 19:20:17.741253 Train Epoch: 50 [80/200 ]\tLoss: 0.001505\n",
      "Timestamp 2019-11-27 19:20:20.189908 Train Epoch: 50 [90/200 ]\tLoss: 0.001614\n",
      "Timestamp 2019-11-27 19:20:22.746615 Train Epoch: 50 [100/200 ]\tLoss: 0.001695\n",
      "Timestamp 2019-11-27 19:20:25.232614 Train Epoch: 50 [110/200 ]\tLoss: 0.001290\n",
      "Timestamp 2019-11-27 19:20:27.746316 Train Epoch: 50 [120/200 ]\tLoss: 0.001236\n",
      "Timestamp 2019-11-27 19:20:30.225723 Train Epoch: 50 [130/200 ]\tLoss: 0.001669\n",
      "Timestamp 2019-11-27 19:20:32.609656 Train Epoch: 50 [140/200 ]\tLoss: 0.001488\n",
      "Timestamp 2019-11-27 19:20:35.033283 Train Epoch: 50 [150/200 ]\tLoss: 0.001739\n",
      "Timestamp 2019-11-27 19:20:37.403011 Train Epoch: 50 [160/200 ]\tLoss: 0.001984\n",
      "Timestamp 2019-11-27 19:20:39.776535 Train Epoch: 50 [170/200 ]\tLoss: 0.001652\n",
      "Timestamp 2019-11-27 19:20:42.158497 Train Epoch: 50 [180/200 ]\tLoss: 0.001416\n",
      "Timestamp 2019-11-27 19:20:44.527822 Train Epoch: 50 [190/200 ]\tLoss: 0.001812\n",
      "Timestamp 2019-11-27 19:20:46.901540 Train Epoch: 50 [200/200 ]\tLoss: 0.001787\n",
      "====> Timestamp 2019-11-27 19:20:46.945663 Epoch: 50 Average loss: 0.00161312\n",
      "epoch: 50====> Test set loss: 0.14015156\n",
      "Timestamp 2019-11-27 19:21:00.791278 Train Epoch: 51 [10/200 ]\tLoss: 0.001219\n",
      "Timestamp 2019-11-27 19:21:03.237877 Train Epoch: 51 [20/200 ]\tLoss: 0.001447\n",
      "Timestamp 2019-11-27 19:21:05.679111 Train Epoch: 51 [30/200 ]\tLoss: 0.001565\n",
      "Timestamp 2019-11-27 19:21:08.104535 Train Epoch: 51 [40/200 ]\tLoss: 0.001922\n",
      "Timestamp 2019-11-27 19:21:10.574381 Train Epoch: 51 [50/200 ]\tLoss: 0.001485\n",
      "Timestamp 2019-11-27 19:21:13.114524 Train Epoch: 51 [60/200 ]\tLoss: 0.001669\n",
      "Timestamp 2019-11-27 19:21:15.557625 Train Epoch: 51 [70/200 ]\tLoss: 0.001719\n",
      "Timestamp 2019-11-27 19:21:18.060238 Train Epoch: 51 [80/200 ]\tLoss: 0.001493\n",
      "Timestamp 2019-11-27 19:21:20.540722 Train Epoch: 51 [90/200 ]\tLoss: 0.001571\n",
      "Timestamp 2019-11-27 19:21:22.984020 Train Epoch: 51 [100/200 ]\tLoss: 0.001706\n",
      "Timestamp 2019-11-27 19:21:25.388059 Train Epoch: 51 [110/200 ]\tLoss: 0.001276\n",
      "Timestamp 2019-11-27 19:21:27.775292 Train Epoch: 51 [120/200 ]\tLoss: 0.001240\n",
      "Timestamp 2019-11-27 19:21:30.263156 Train Epoch: 51 [130/200 ]\tLoss: 0.001682\n",
      "Timestamp 2019-11-27 19:21:32.740439 Train Epoch: 51 [140/200 ]\tLoss: 0.001480\n",
      "Timestamp 2019-11-27 19:21:35.178473 Train Epoch: 51 [150/200 ]\tLoss: 0.001725\n",
      "Timestamp 2019-11-27 19:21:37.673684 Train Epoch: 51 [160/200 ]\tLoss: 0.001997\n",
      "Timestamp 2019-11-27 19:21:40.076170 Train Epoch: 51 [170/200 ]\tLoss: 0.001666\n",
      "Timestamp 2019-11-27 19:21:42.459211 Train Epoch: 51 [180/200 ]\tLoss: 0.001405\n",
      "Timestamp 2019-11-27 19:21:44.839204 Train Epoch: 51 [190/200 ]\tLoss: 0.001783\n",
      "Timestamp 2019-11-27 19:21:47.231331 Train Epoch: 51 [200/200 ]\tLoss: 0.001780\n",
      "====> Timestamp 2019-11-27 19:21:47.275177 Epoch: 51 Average loss: 0.00159895\n",
      "epoch: 51====> Test set loss: 0.13921206\n",
      "Timestamp 2019-11-27 19:22:01.124346 Train Epoch: 52 [10/200 ]\tLoss: 0.001238\n",
      "Timestamp 2019-11-27 19:22:03.499975 Train Epoch: 52 [20/200 ]\tLoss: 0.001438\n",
      "Timestamp 2019-11-27 19:22:05.893262 Train Epoch: 52 [30/200 ]\tLoss: 0.001543\n",
      "Timestamp 2019-11-27 19:22:08.324306 Train Epoch: 52 [40/200 ]\tLoss: 0.001872\n",
      "Timestamp 2019-11-27 19:22:10.722478 Train Epoch: 52 [50/200 ]\tLoss: 0.001457\n",
      "Timestamp 2019-11-27 19:22:13.181652 Train Epoch: 52 [60/200 ]\tLoss: 0.001692\n",
      "Timestamp 2019-11-27 19:22:15.599958 Train Epoch: 52 [70/200 ]\tLoss: 0.001639\n",
      "Timestamp 2019-11-27 19:22:18.047735 Train Epoch: 52 [80/200 ]\tLoss: 0.001491\n",
      "Timestamp 2019-11-27 19:22:20.430623 Train Epoch: 52 [90/200 ]\tLoss: 0.001526\n",
      "Timestamp 2019-11-27 19:22:22.812965 Train Epoch: 52 [100/200 ]\tLoss: 0.001684\n",
      "Timestamp 2019-11-27 19:22:25.324937 Train Epoch: 52 [110/200 ]\tLoss: 0.001285\n",
      "Timestamp 2019-11-27 19:22:27.823316 Train Epoch: 52 [120/200 ]\tLoss: 0.001225\n",
      "Timestamp 2019-11-27 19:22:30.267092 Train Epoch: 52 [130/200 ]\tLoss: 0.001672\n",
      "Timestamp 2019-11-27 19:22:32.774082 Train Epoch: 52 [140/200 ]\tLoss: 0.001460\n",
      "Timestamp 2019-11-27 19:22:35.200767 Train Epoch: 52 [150/200 ]\tLoss: 0.001747\n",
      "Timestamp 2019-11-27 19:22:37.642106 Train Epoch: 52 [160/200 ]\tLoss: 0.001969\n",
      "Timestamp 2019-11-27 19:22:40.096074 Train Epoch: 52 [170/200 ]\tLoss: 0.001634\n",
      "Timestamp 2019-11-27 19:22:42.496509 Train Epoch: 52 [180/200 ]\tLoss: 0.001364\n",
      "Timestamp 2019-11-27 19:22:44.869419 Train Epoch: 52 [190/200 ]\tLoss: 0.001756\n",
      "Timestamp 2019-11-27 19:22:47.237158 Train Epoch: 52 [200/200 ]\tLoss: 0.001759\n",
      "====> Timestamp 2019-11-27 19:22:47.280091 Epoch: 52 Average loss: 0.00158249\n",
      "epoch: 52====> Test set loss: 0.13891551\n",
      "Timestamp 2019-11-27 19:23:01.282759 Train Epoch: 53 [10/200 ]\tLoss: 0.001204\n",
      "Timestamp 2019-11-27 19:23:03.659437 Train Epoch: 53 [20/200 ]\tLoss: 0.001436\n",
      "Timestamp 2019-11-27 19:23:06.041931 Train Epoch: 53 [30/200 ]\tLoss: 0.001532\n",
      "Timestamp 2019-11-27 19:23:08.476332 Train Epoch: 53 [40/200 ]\tLoss: 0.001835\n",
      "Timestamp 2019-11-27 19:23:10.931842 Train Epoch: 53 [50/200 ]\tLoss: 0.001433\n",
      "Timestamp 2019-11-27 19:23:13.324401 Train Epoch: 53 [60/200 ]\tLoss: 0.001682\n",
      "Timestamp 2019-11-27 19:23:15.692302 Train Epoch: 53 [70/200 ]\tLoss: 0.001630\n",
      "Timestamp 2019-11-27 19:23:18.106816 Train Epoch: 53 [80/200 ]\tLoss: 0.001453\n",
      "Timestamp 2019-11-27 19:23:20.463493 Train Epoch: 53 [90/200 ]\tLoss: 0.001527\n",
      "Timestamp 2019-11-27 19:23:22.835461 Train Epoch: 53 [100/200 ]\tLoss: 0.001679\n",
      "Timestamp 2019-11-27 19:23:25.196330 Train Epoch: 53 [110/200 ]\tLoss: 0.001250\n",
      "Timestamp 2019-11-27 19:23:27.602536 Train Epoch: 53 [120/200 ]\tLoss: 0.001217\n",
      "Timestamp 2019-11-27 19:23:29.981818 Train Epoch: 53 [130/200 ]\tLoss: 0.001646\n",
      "Timestamp 2019-11-27 19:23:32.371937 Train Epoch: 53 [140/200 ]\tLoss: 0.001479\n",
      "Timestamp 2019-11-27 19:23:34.755261 Train Epoch: 53 [150/200 ]\tLoss: 0.001719\n",
      "Timestamp 2019-11-27 19:23:37.124507 Train Epoch: 53 [160/200 ]\tLoss: 0.001961\n",
      "Timestamp 2019-11-27 19:23:39.487718 Train Epoch: 53 [170/200 ]\tLoss: 0.001623\n",
      "Timestamp 2019-11-27 19:23:41.854900 Train Epoch: 53 [180/200 ]\tLoss: 0.001358\n",
      "Timestamp 2019-11-27 19:23:44.227574 Train Epoch: 53 [190/200 ]\tLoss: 0.001740\n",
      "Timestamp 2019-11-27 19:23:46.610771 Train Epoch: 53 [200/200 ]\tLoss: 0.001737\n",
      "====> Timestamp 2019-11-27 19:23:46.650923 Epoch: 53 Average loss: 0.00156674\n",
      "epoch: 53====> Test set loss: 0.13954278\n",
      "Timestamp 2019-11-27 19:24:00.458075 Train Epoch: 54 [10/200 ]\tLoss: 0.001213\n",
      "Timestamp 2019-11-27 19:24:02.882686 Train Epoch: 54 [20/200 ]\tLoss: 0.001375\n",
      "Timestamp 2019-11-27 19:24:05.261692 Train Epoch: 54 [30/200 ]\tLoss: 0.001469\n",
      "Timestamp 2019-11-27 19:24:07.627855 Train Epoch: 54 [40/200 ]\tLoss: 0.001864\n",
      "Timestamp 2019-11-27 19:24:10.009093 Train Epoch: 54 [50/200 ]\tLoss: 0.001442\n",
      "Timestamp 2019-11-27 19:24:12.395415 Train Epoch: 54 [60/200 ]\tLoss: 0.001648\n",
      "Timestamp 2019-11-27 19:24:14.778359 Train Epoch: 54 [70/200 ]\tLoss: 0.001647\n",
      "Timestamp 2019-11-27 19:24:17.149507 Train Epoch: 54 [80/200 ]\tLoss: 0.001474\n",
      "Timestamp 2019-11-27 19:24:19.548812 Train Epoch: 54 [90/200 ]\tLoss: 0.001543\n",
      "Timestamp 2019-11-27 19:24:21.929264 Train Epoch: 54 [100/200 ]\tLoss: 0.001661\n",
      "Timestamp 2019-11-27 19:24:24.301577 Train Epoch: 54 [110/200 ]\tLoss: 0.001205\n",
      "Timestamp 2019-11-27 19:24:26.709048 Train Epoch: 54 [120/200 ]\tLoss: 0.001194\n",
      "Timestamp 2019-11-27 19:24:29.116530 Train Epoch: 54 [130/200 ]\tLoss: 0.001621\n",
      "Timestamp 2019-11-27 19:24:31.600559 Train Epoch: 54 [140/200 ]\tLoss: 0.001437\n",
      "Timestamp 2019-11-27 19:24:34.053852 Train Epoch: 54 [150/200 ]\tLoss: 0.001711\n",
      "Timestamp 2019-11-27 19:24:36.535002 Train Epoch: 54 [160/200 ]\tLoss: 0.001949\n",
      "Timestamp 2019-11-27 19:24:39.018017 Train Epoch: 54 [170/200 ]\tLoss: 0.001613\n",
      "Timestamp 2019-11-27 19:24:41.473232 Train Epoch: 54 [180/200 ]\tLoss: 0.001352\n",
      "Timestamp 2019-11-27 19:24:43.899802 Train Epoch: 54 [190/200 ]\tLoss: 0.001749\n",
      "Timestamp 2019-11-27 19:24:46.323333 Train Epoch: 54 [200/200 ]\tLoss: 0.001717\n",
      "====> Timestamp 2019-11-27 19:24:46.369174 Epoch: 54 Average loss: 0.00155256\n",
      "epoch: 54====> Test set loss: 0.14015211\n",
      "Timestamp 2019-11-27 19:25:00.632185 Train Epoch: 55 [10/200 ]\tLoss: 0.001194\n",
      "Timestamp 2019-11-27 19:25:03.001559 Train Epoch: 55 [20/200 ]\tLoss: 0.001395\n",
      "Timestamp 2019-11-27 19:25:05.460125 Train Epoch: 55 [30/200 ]\tLoss: 0.001445\n",
      "Timestamp 2019-11-27 19:25:07.827077 Train Epoch: 55 [40/200 ]\tLoss: 0.001837\n",
      "Timestamp 2019-11-27 19:25:10.242683 Train Epoch: 55 [50/200 ]\tLoss: 0.001412\n",
      "Timestamp 2019-11-27 19:25:12.693034 Train Epoch: 55 [60/200 ]\tLoss: 0.001627\n",
      "Timestamp 2019-11-27 19:25:15.119944 Train Epoch: 55 [70/200 ]\tLoss: 0.001616\n",
      "Timestamp 2019-11-27 19:25:17.531235 Train Epoch: 55 [80/200 ]\tLoss: 0.001419\n",
      "Timestamp 2019-11-27 19:25:19.964358 Train Epoch: 55 [90/200 ]\tLoss: 0.001485\n",
      "Timestamp 2019-11-27 19:25:22.370853 Train Epoch: 55 [100/200 ]\tLoss: 0.001595\n",
      "Timestamp 2019-11-27 19:25:24.904111 Train Epoch: 55 [110/200 ]\tLoss: 0.001231\n",
      "Timestamp 2019-11-27 19:25:27.466667 Train Epoch: 55 [120/200 ]\tLoss: 0.001192\n",
      "Timestamp 2019-11-27 19:25:29.952061 Train Epoch: 55 [130/200 ]\tLoss: 0.001639\n",
      "Timestamp 2019-11-27 19:25:32.371129 Train Epoch: 55 [140/200 ]\tLoss: 0.001440\n",
      "Timestamp 2019-11-27 19:25:34.746083 Train Epoch: 55 [150/200 ]\tLoss: 0.001696\n",
      "Timestamp 2019-11-27 19:25:37.294630 Train Epoch: 55 [160/200 ]\tLoss: 0.001892\n",
      "Timestamp 2019-11-27 19:25:39.739716 Train Epoch: 55 [170/200 ]\tLoss: 0.001600\n",
      "Timestamp 2019-11-27 19:25:42.154022 Train Epoch: 55 [180/200 ]\tLoss: 0.001375\n",
      "Timestamp 2019-11-27 19:25:44.547234 Train Epoch: 55 [190/200 ]\tLoss: 0.001717\n",
      "Timestamp 2019-11-27 19:25:46.937851 Train Epoch: 55 [200/200 ]\tLoss: 0.001732\n",
      "====> Timestamp 2019-11-27 19:25:46.984675 Epoch: 55 Average loss: 0.00153661\n",
      "epoch: 55====> Test set loss: 0.13924223\n",
      "Timestamp 2019-11-27 19:26:01.232047 Train Epoch: 56 [10/200 ]\tLoss: 0.001181\n",
      "Timestamp 2019-11-27 19:26:03.678271 Train Epoch: 56 [20/200 ]\tLoss: 0.001433\n",
      "Timestamp 2019-11-27 19:26:06.063263 Train Epoch: 56 [30/200 ]\tLoss: 0.001438\n",
      "Timestamp 2019-11-27 19:26:08.463816 Train Epoch: 56 [40/200 ]\tLoss: 0.001831\n",
      "Timestamp 2019-11-27 19:26:10.978021 Train Epoch: 56 [50/200 ]\tLoss: 0.001378\n",
      "Timestamp 2019-11-27 19:26:13.357452 Train Epoch: 56 [60/200 ]\tLoss: 0.001607\n",
      "Timestamp 2019-11-27 19:26:15.896632 Train Epoch: 56 [70/200 ]\tLoss: 0.001617\n",
      "Timestamp 2019-11-27 19:26:18.421196 Train Epoch: 56 [80/200 ]\tLoss: 0.001416\n",
      "Timestamp 2019-11-27 19:26:20.944723 Train Epoch: 56 [90/200 ]\tLoss: 0.001455\n",
      "Timestamp 2019-11-27 19:26:23.415026 Train Epoch: 56 [100/200 ]\tLoss: 0.001637\n",
      "Timestamp 2019-11-27 19:26:25.891573 Train Epoch: 56 [110/200 ]\tLoss: 0.001220\n",
      "Timestamp 2019-11-27 19:26:28.444059 Train Epoch: 56 [120/200 ]\tLoss: 0.001160\n",
      "Timestamp 2019-11-27 19:26:30.959106 Train Epoch: 56 [130/200 ]\tLoss: 0.001574\n",
      "Timestamp 2019-11-27 19:26:33.376758 Train Epoch: 56 [140/200 ]\tLoss: 0.001422\n",
      "Timestamp 2019-11-27 19:26:35.801930 Train Epoch: 56 [150/200 ]\tLoss: 0.001667\n",
      "Timestamp 2019-11-27 19:26:38.306425 Train Epoch: 56 [160/200 ]\tLoss: 0.001890\n",
      "Timestamp 2019-11-27 19:26:40.734986 Train Epoch: 56 [170/200 ]\tLoss: 0.001566\n",
      "Timestamp 2019-11-27 19:26:43.106512 Train Epoch: 56 [180/200 ]\tLoss: 0.001318\n",
      "Timestamp 2019-11-27 19:26:45.487742 Train Epoch: 56 [190/200 ]\tLoss: 0.001710\n",
      "Timestamp 2019-11-27 19:26:47.953991 Train Epoch: 56 [200/200 ]\tLoss: 0.001691\n",
      "====> Timestamp 2019-11-27 19:26:48.000248 Epoch: 56 Average loss: 0.00152090\n",
      "epoch: 56====> Test set loss: 0.14008893\n",
      "Timestamp 2019-11-27 19:27:02.321620 Train Epoch: 57 [10/200 ]\tLoss: 0.001161\n",
      "Timestamp 2019-11-27 19:27:04.719946 Train Epoch: 57 [20/200 ]\tLoss: 0.001408\n",
      "Timestamp 2019-11-27 19:27:07.119910 Train Epoch: 57 [30/200 ]\tLoss: 0.001459\n",
      "Timestamp 2019-11-27 19:27:09.513692 Train Epoch: 57 [40/200 ]\tLoss: 0.001791\n",
      "Timestamp 2019-11-27 19:27:11.904062 Train Epoch: 57 [50/200 ]\tLoss: 0.001374\n",
      "Timestamp 2019-11-27 19:27:14.307825 Train Epoch: 57 [60/200 ]\tLoss: 0.001609\n",
      "Timestamp 2019-11-27 19:27:16.695172 Train Epoch: 57 [70/200 ]\tLoss: 0.001550\n",
      "Timestamp 2019-11-27 19:27:19.135394 Train Epoch: 57 [80/200 ]\tLoss: 0.001404\n",
      "Timestamp 2019-11-27 19:27:21.525700 Train Epoch: 57 [90/200 ]\tLoss: 0.001445\n",
      "Timestamp 2019-11-27 19:27:23.915633 Train Epoch: 57 [100/200 ]\tLoss: 0.001588\n",
      "Timestamp 2019-11-27 19:27:26.300139 Train Epoch: 57 [110/200 ]\tLoss: 0.001223\n",
      "Timestamp 2019-11-27 19:27:28.702187 Train Epoch: 57 [120/200 ]\tLoss: 0.001152\n",
      "Timestamp 2019-11-27 19:27:31.095812 Train Epoch: 57 [130/200 ]\tLoss: 0.001578\n",
      "Timestamp 2019-11-27 19:27:33.501730 Train Epoch: 57 [140/200 ]\tLoss: 0.001404\n",
      "Timestamp 2019-11-27 19:27:35.886406 Train Epoch: 57 [150/200 ]\tLoss: 0.001662\n",
      "Timestamp 2019-11-27 19:27:38.267060 Train Epoch: 57 [160/200 ]\tLoss: 0.001881\n",
      "Timestamp 2019-11-27 19:27:40.652206 Train Epoch: 57 [170/200 ]\tLoss: 0.001593\n",
      "Timestamp 2019-11-27 19:27:43.030781 Train Epoch: 57 [180/200 ]\tLoss: 0.001314\n",
      "Timestamp 2019-11-27 19:27:45.402808 Train Epoch: 57 [190/200 ]\tLoss: 0.001678\n",
      "Timestamp 2019-11-27 19:27:47.788220 Train Epoch: 57 [200/200 ]\tLoss: 0.001650\n",
      "====> Timestamp 2019-11-27 19:27:47.836763 Epoch: 57 Average loss: 0.00150547\n",
      "epoch: 57====> Test set loss: 0.13955243\n",
      "Timestamp 2019-11-27 19:28:01.845747 Train Epoch: 58 [10/200 ]\tLoss: 0.001154\n",
      "Timestamp 2019-11-27 19:28:04.231030 Train Epoch: 58 [20/200 ]\tLoss: 0.001343\n",
      "Timestamp 2019-11-27 19:28:06.616284 Train Epoch: 58 [30/200 ]\tLoss: 0.001443\n",
      "Timestamp 2019-11-27 19:28:09.003349 Train Epoch: 58 [40/200 ]\tLoss: 0.001765\n",
      "Timestamp 2019-11-27 19:28:11.389185 Train Epoch: 58 [50/200 ]\tLoss: 0.001373\n",
      "Timestamp 2019-11-27 19:28:13.773599 Train Epoch: 58 [60/200 ]\tLoss: 0.001581\n",
      "Timestamp 2019-11-27 19:28:16.162908 Train Epoch: 58 [70/200 ]\tLoss: 0.001565\n",
      "Timestamp 2019-11-27 19:28:18.594265 Train Epoch: 58 [80/200 ]\tLoss: 0.001360\n",
      "Timestamp 2019-11-27 19:28:20.970983 Train Epoch: 58 [90/200 ]\tLoss: 0.001435\n",
      "Timestamp 2019-11-27 19:28:23.343291 Train Epoch: 58 [100/200 ]\tLoss: 0.001553\n",
      "Timestamp 2019-11-27 19:28:25.715164 Train Epoch: 58 [110/200 ]\tLoss: 0.001214\n",
      "Timestamp 2019-11-27 19:28:28.105505 Train Epoch: 58 [120/200 ]\tLoss: 0.001130\n",
      "Timestamp 2019-11-27 19:28:30.484689 Train Epoch: 58 [130/200 ]\tLoss: 0.001547\n",
      "Timestamp 2019-11-27 19:28:32.865530 Train Epoch: 58 [140/200 ]\tLoss: 0.001418\n",
      "Timestamp 2019-11-27 19:28:35.245126 Train Epoch: 58 [150/200 ]\tLoss: 0.001671\n",
      "Timestamp 2019-11-27 19:28:37.620422 Train Epoch: 58 [160/200 ]\tLoss: 0.001895\n",
      "Timestamp 2019-11-27 19:28:40.006222 Train Epoch: 58 [170/200 ]\tLoss: 0.001541\n",
      "Timestamp 2019-11-27 19:28:42.388025 Train Epoch: 58 [180/200 ]\tLoss: 0.001287\n",
      "Timestamp 2019-11-27 19:28:44.766850 Train Epoch: 58 [190/200 ]\tLoss: 0.001701\n",
      "Timestamp 2019-11-27 19:28:47.216785 Train Epoch: 58 [200/200 ]\tLoss: 0.001664\n",
      "====> Timestamp 2019-11-27 19:28:47.259896 Epoch: 58 Average loss: 0.00149169\n",
      "epoch: 58====> Test set loss: 0.13899158\n",
      "Timestamp 2019-11-27 19:29:01.205386 Train Epoch: 59 [10/200 ]\tLoss: 0.001158\n",
      "Timestamp 2019-11-27 19:29:03.599566 Train Epoch: 59 [20/200 ]\tLoss: 0.001340\n",
      "Timestamp 2019-11-27 19:29:06.001099 Train Epoch: 59 [30/200 ]\tLoss: 0.001393\n",
      "Timestamp 2019-11-27 19:29:08.420035 Train Epoch: 59 [40/200 ]\tLoss: 0.001757\n",
      "Timestamp 2019-11-27 19:29:10.829516 Train Epoch: 59 [50/200 ]\tLoss: 0.001336\n",
      "Timestamp 2019-11-27 19:29:13.241972 Train Epoch: 59 [60/200 ]\tLoss: 0.001600\n",
      "Timestamp 2019-11-27 19:29:15.657660 Train Epoch: 59 [70/200 ]\tLoss: 0.001534\n",
      "Timestamp 2019-11-27 19:29:18.100008 Train Epoch: 59 [80/200 ]\tLoss: 0.001373\n",
      "Timestamp 2019-11-27 19:29:20.531778 Train Epoch: 59 [90/200 ]\tLoss: 0.001394\n",
      "Timestamp 2019-11-27 19:29:22.923389 Train Epoch: 59 [100/200 ]\tLoss: 0.001604\n",
      "Timestamp 2019-11-27 19:29:25.329913 Train Epoch: 59 [110/200 ]\tLoss: 0.001185\n",
      "Timestamp 2019-11-27 19:29:27.726183 Train Epoch: 59 [120/200 ]\tLoss: 0.001117\n",
      "Timestamp 2019-11-27 19:29:30.119172 Train Epoch: 59 [130/200 ]\tLoss: 0.001535\n",
      "Timestamp 2019-11-27 19:29:32.511417 Train Epoch: 59 [140/200 ]\tLoss: 0.001386\n",
      "Timestamp 2019-11-27 19:29:34.902201 Train Epoch: 59 [150/200 ]\tLoss: 0.001589\n",
      "Timestamp 2019-11-27 19:29:37.297419 Train Epoch: 59 [160/200 ]\tLoss: 0.001858\n",
      "Timestamp 2019-11-27 19:29:39.707125 Train Epoch: 59 [170/200 ]\tLoss: 0.001541\n",
      "Timestamp 2019-11-27 19:29:42.119801 Train Epoch: 59 [180/200 ]\tLoss: 0.001254\n",
      "Timestamp 2019-11-27 19:29:44.522309 Train Epoch: 59 [190/200 ]\tLoss: 0.001667\n",
      "Timestamp 2019-11-27 19:29:46.914084 Train Epoch: 59 [200/200 ]\tLoss: 0.001626\n",
      "====> Timestamp 2019-11-27 19:29:46.954298 Epoch: 59 Average loss: 0.00147574\n",
      "epoch: 59====> Test set loss: 0.13890836\n",
      "Timestamp 2019-11-27 19:30:00.755680 Train Epoch: 60 [10/200 ]\tLoss: 0.001123\n",
      "Timestamp 2019-11-27 19:30:03.157444 Train Epoch: 60 [20/200 ]\tLoss: 0.001373\n",
      "Timestamp 2019-11-27 19:30:05.565703 Train Epoch: 60 [30/200 ]\tLoss: 0.001400\n",
      "Timestamp 2019-11-27 19:30:07.956953 Train Epoch: 60 [40/200 ]\tLoss: 0.001762\n",
      "Timestamp 2019-11-27 19:30:10.369032 Train Epoch: 60 [50/200 ]\tLoss: 0.001341\n",
      "Timestamp 2019-11-27 19:30:12.771573 Train Epoch: 60 [60/200 ]\tLoss: 0.001559\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epoch_count = 1\n",
    "for e in epochs:\n",
    "    batches = chunks(e, batch_size, dim=0)\n",
    "    eloss = train(model, optimizer, loss_function, batches, epoch_count, epoch_size, device, log_interval=10)\n",
    "    test(model, loss_function, test_data, epoch_count, device, max_data=50)\n",
    "    epoch_count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# epoch_count = 2\n",
    "# eloss = train(model, optimizer, loss_function, batches, epoch_count, len(data), device, log_interval=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.save_model(\"./trained_models/conv1dcol\", \"conv1dcol_nll-loss_epoch-{}\".format(epoch_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried different Nx50 sizes for batches but the only one that works is 50, it seems will be the maximum number of samples in each batch for the training in my GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue is that training does not seem to work correctly.\n",
    "\n",
    "All training losses (kl_div, mse_loss) seem to learn well only the first 100 batches and then nothing, it oscilates. After several different initializations with kl_div it worked better (the first loss was about initialized to -1 ... ) so initialization seems to take an important role here.\n",
    "\n",
    "I need to write a test function now to be able to measure with the test datasets and see the real accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
