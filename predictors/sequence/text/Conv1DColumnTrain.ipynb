{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Tests for Part Of Speech tagging\n",
    "\n",
    "This notebook is dedicated to start working with the PoS dataset already pre-processed and the column networks that I'm creating.\n",
    "\n",
    "The network will be constructed from small parts, each will be trained on top of the previous one, adding a new column and decoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n",
      "Loading faiss.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from langmodels.models import *\n",
    "import langmodels.utf8codec as utf8codec\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the embeddings first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the codebook and all the dictionaries mapping the data\n",
    "# utf8codes, txt2code, code2txt, txt2num, num2txt = utf8codec._load_codebook()\n",
    "utf8codes = np.load(\"./utf8-codes/utf8_codebook_overfit_matrix_2seg_dim64.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utf8codes = utf8codes.reshape(1987,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Conv1DPoS(utf8codes)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2161960"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the original network 11266152 parameters, I have cut the number of features and dimensions to make it smaller\n",
    "\n",
    "for nlayers = 5 of dim 5 is 6912424 and 6846888 trainable\n",
    "\n",
    "for the following Conv1DPartOfSpeech the number of parameters is: 2161960 where 2096424 are trainable\n",
    "\n",
    "    nchannels_in=[64, 128, 256, 512, 256],\n",
    "    nchannels_out=[128, 256, 512, 256, 96],\n",
    "    kernels=[3, 3, 3, 3, 3],\n",
    "    nlayers=[6, 6, 4, 4, 3],\n",
    "    groups=[1, 4, 8, 4, 1],\n",
    "    \n",
    "And LinearUposDeprelDecoder params are:\n",
    "\n",
    "    lin_in_dim=96, \n",
    "    lin_hidd_dim=768,\n",
    "    upos_dim=18, \n",
    "    deprel_dim=278,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2096424"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets are the one that are heavy, so I'll just load them and check what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = \"/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.4/traindev_np_batches_779000x3x1024_uint16.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.load(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779000, 3, 1024)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint16')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta_train_txt = data_train[:,0,:]\n",
    "dta_train_upos = data_train[:,1,:]\n",
    "dta_train_deprel = data_train[:,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(dta_train_txt[:50].astype(\"int64\")).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[113, 117, 111,  ...,   0,   0,   0],\n",
       "        [ 77, 111, 110,  ...,   0,   0,   0],\n",
       "        [ 65, 117, 223,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [ 68,  97, 103,  ...,   0,   0,   0],\n",
       "        [ 67, 111, 109,  ...,   0,   0,   0],\n",
       "        [113, 117, 105,  ...,   0,   0,   0]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "txtcode, positions, latent, dec = net(x)\n",
    "last_latent = latent[-1]\n",
    "upos, deprel = dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 64, 1024]),\n",
       " torch.Size([1, 1024]),\n",
       " torch.Size([50, 96, 1024]),\n",
       " torch.Size([50, 1024, 18]),\n",
       " torch.Size([50, 1024, 278]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtcode.shape, positions.shape, last_latent.shape, upos.shape, deprel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.cat([upos,deprel], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1024, 296])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
