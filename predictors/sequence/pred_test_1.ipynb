{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence prediction analysis - Test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sequence prediction analysis tests are done to analyze several different elements of different algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Networks to Evaluate\n",
    "\n",
    " - Fully Connected Networks\n",
    " - LSTM Networks\n",
    " - TCN (Temporal Convolutional Networks)\n",
    " - MANNs (different ones, to determine)\n",
    " - Networks Augmented with Attention Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Elements:\n",
    "\n",
    "The following elements must appear in the report of each experiment:\n",
    "\n",
    "* Algorithm ID (name), reference to the architecture details\n",
    "* Date\n",
    "* Time\n",
    "* Number of Parameters in the network\n",
    "* Training Time (including the hardware where it was trained)\n",
    "* Performance (accuracy/something else .. yet to define) at different future points\n",
    "* Loss (log loss, RMS, etc) at different future points\n",
    "* Performance decay on the future time, starting from the last training point\n",
    "* Optimizer used (Adam, Gradient Descent, Momentum, ... etc)\n",
    "* Input queue size\n",
    "* Output Queue size\n",
    "* Feedback Error metric (SME, absolute, log, log-loss, ...) \n",
    "* Using/Not using space-time coding (details later, this is something I want to elaborate more and research)\n",
    "* Comments\n",
    "* Some others that I have yet to think about"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "\n",
    "* The input to the network is standardized for all the models to be tested\n",
    "\n",
    "#### Architecture\n",
    "\n",
    "More details in the Architecture Section\n",
    "\n",
    "* The general architecture is stable, this is, an input queue, an output queue and an error signal that is fed back to the predictor network\n",
    "* The input is temporally saved in a limited dimension input queue, this queue can or not be used by the network\n",
    "* The output of the prediction is also kept in an output queue, as before this queue can or not be used by the network\n",
    "* The error is *always* computed, and is fed back into the network (based on ideas from control systems) in the next time step\n",
    "\n",
    "#### Resources\n",
    "\n",
    "* The network must be small enough to be trained in my computer with an Intel i7 7700K and a NVidia GTX 1080\n",
    "\n",
    "#### Training Data\n",
    "\n",
    "* All networks will use the same data, pre-processed in the same manner, no specific pre-processing or adaptation should be done\n",
    "* The input dimension to study is 1D vectors, this means vectors of size (1xN) such as N is a Natural Number\n",
    "* Training data can be an audio sequence, a list of prices of an exchange, text, MIDI signal, a bitwise signal (example CommaAI-env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "The Architecture is separated in 2 main parts:\n",
    "\n",
    "1. General Architecture\n",
    "2. Specific Method Architecture\n",
    "\n",
    "### General Architecture\n",
    "\n",
    "The General Architecture can be seen in the following image:\n",
    "\n",
    "#TODO !!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "The architecture consists of an input queue and an output queue. \n",
    "\n",
    "The input one provides the data to the predictor network (PN).\n",
    "\n",
    "The output one stores the predicted data from the predictor network (PN).\n",
    "\n",
    "An error signal is computed and fed back into the Predictor Network (PN).\n",
    "\n",
    "### Specific Method Architecture\n",
    "\n",
    "The point #2 depends on the particularities of the network (LSTM, Fully Connected, Convolutional, etc) so this will be specified in each section separately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output queue specificities\n",
    "\n",
    "The input and output queues can be composed of several queues, these can be the following ones:\n",
    "\n",
    "1. The actual input data (Mandatory)\n",
    "2. Time Coding of the input (Optional to be evaluated)\n",
    "3. Space Coding of the input (Out of scope from the current study)\n",
    "\n",
    "\n",
    "### The actual input data\n",
    "\n",
    "This data is the data from the input signal that I'm trying to predict. \n",
    "\n",
    "This data can be:\n",
    "\n",
    " * A scalar input such as: sound signal, prices from the stock market, temperatures, linear position, ...\n",
    " * A Vector input such as text symbols, midi signals, ...\n",
    " \n",
    "### Time Coding of the input\n",
    " \n",
    "This is a code that signifies the TIME at which the input arrives.\n",
    " \n",
    "T his idea comes from the notion that our brain contain not only the symbols arriving in due time, but also there are sensors in our body that allows us to know how much we have moved, how much time has passed, ....\n",
    "\n",
    "The argument is that for many operations we need this data to actually \n",
    "\n",
    "Just to be short without to much reference for the moment (I might write more details on this later):\n",
    "\n",
    "* in the brain there are neurons that can be stable, unstable, bi-stables and oscilating, \n",
    "* that there are some others that are sensitive to location and orientation ( V1 ),\n",
    "* or spacially related (latest work by deepmind in grid neurons),\n",
    "* the work on Attention Is All You Need uses positional encoding for words in a sinusoidal maner for this.\n",
    "\n",
    "\n",
    "### Space Coding for the input\n",
    "\n",
    "The idea is the same as the Time coding, but for spatial dimensions. This study does not target any evaluation in this domain but is worth to mention it for future work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/DeepLearning/venv3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting number of parameters\n",
    "# https://discuss.pytorch.org/t/how-do-i-check-the-number-of-parameters-of-a-model/4325/7\n",
    "# https://stackoverflow.com/questions/49201236/check-the-total-number-of-parameters-in-a-pytorch-model\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
