{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, utils\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import skimage \n",
    "import math\n",
    "# import io\n",
    "# import requests\n",
    "# from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch tests to understand some ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test update patches of tensor (replace some values only instead of operation in entire tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "[torch.FloatTensor of size (10,10)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[3:5, 3:5] = torch.zeros(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0  1\n",
       " 0  0  1\n",
       "[torch.FloatTensor of size (2,3)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[3:5, 3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpatch = t[5:7, 5:7]\n",
    "tpatch = torch.rand(2,2)\n",
    "tpatch2 = torch.rand(10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.5234  0.6426\n",
       " 0.3535  0.0635\n",
       "[torch.FloatTensor of size (2,2)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     1\n",
       "    1     1\n",
       "    1     1\n",
       "    1     1\n",
       "    1     1\n",
       "    1     1\n",
       "    1     1\n",
       "    1     1\n",
       "    1     1\n",
       "    1     1\n",
       "[torch.FloatTensor of size (10,2)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 5:7] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (10) must match the existing size (2) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dcab0f718683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtpatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (10) must match the existing size (2) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "t[:, 5:7]  = tpatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[:, 5:7]  = tpatch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.0000  1.0000  1.0000  1.0000  1.0000  0.8014  0.8230  1.0000  1.0000  1.0000\n",
       " 1.0000  1.0000  1.0000  1.0000  1.0000  0.0922  0.5681  1.0000  1.0000  1.0000\n",
       " 1.0000  1.0000  1.0000  1.0000  1.0000  0.7856  0.3420  1.0000  1.0000  1.0000\n",
       " 1.0000  1.0000  1.0000  0.0000  0.0000  0.5735  0.3144  1.0000  1.0000  1.0000\n",
       " 1.0000  1.0000  1.0000  0.0000  0.0000  0.2125  0.3810  1.0000  1.0000  1.0000\n",
       " 1.0000  1.0000  1.0000  1.0000  1.0000  0.6290  0.6791  1.0000  1.0000  1.0000\n",
       " 1.0000  1.0000  1.0000  1.0000  1.0000  0.5470  0.7892  1.0000  1.0000  1.0000\n",
       " 1.0000  1.0000  1.0000  1.0000  1.0000  0.2704  0.7376  1.0000  1.0000  1.0000\n",
       " 1.0000  1.0000  1.0000  1.0000  1.0000  0.6119  0.5020  1.0000  1.0000  1.0000\n",
       " 1.0000  1.0000  1.0000  1.0000  1.0000  0.7909  0.4424  1.0000  1.0000  1.0000\n",
       "[torch.FloatTensor of size (10,10)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(tpatch2, t[:, 5:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test transforms applied to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DownsamplerLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, width, height):\n",
    "        super().__init__()\n",
    "        self.resizer = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        # transforms.ToPILImage(),  #is this correct? will this be slow??\n",
    "                        transforms.Resize(width, height),\n",
    "                        transforms.ToTensor()\n",
    "                        ])\n",
    "    def forward(self, x):\n",
    "        return self.resizer(x)\n",
    "        #return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DownsamplerLayer(5,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = transforms.Resize(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-68fa25079c6e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-68fa25079c6e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tr(t.data.)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tr(t.data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl(t.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_URL = 'https://s3.amazonaws.com/outcome-blog/wp-content/uploads/2017/02/25192225/cat.jpg'\n",
    "response = requests.get(IMG_URL)\n",
    "img_pil = Image.open(io.BytesIO(response.content))#.convert(\"RGB\")\n",
    "\n",
    "#test one:\n",
    "preprocess = transforms.Compose([\n",
    "    #transforms.Resize(50),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "\n",
    "\n",
    "\n",
    "img_tensor = preprocess(img_pil)\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor[-0.5:0, -0.5:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pil(img_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test AdaptiveAvgPool2D as downsampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.AdaptiveAvgPool2d((5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 10, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = nn.AdaptiveAvgPool2d((50,75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled = ds(img_tensor)\n",
    "to_pil(downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test upsampling tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = nn.AdaptiveMaxPool2d((100,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled = us(downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pil(upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests with bilinear interpolation\n",
    "\n",
    "Documentation and examples from [here](https://gist.github.com/peteflorence/a1da2c759ca1ac2b74af9a83f69ce20e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional\n",
    "dtype = torch.cuda.FloatTensor\n",
    "dtype_long = torch.cuda.LongTensor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilinear_interpolate_torch_gridsample(image, samples_x, samples_y):\n",
    "                                                # input image is: W x H x C\n",
    "    image = image.permute(2,0,1)                # change to:      C x W x H\n",
    "    image = image.unsqueeze(0)                  # change to:  1 x C x W x H\n",
    "    samples_x = samples_x.unsqueeze(2)\n",
    "    samples_x = samples_x.unsqueeze(3)\n",
    "    samples_y = samples_y.unsqueeze(2)\n",
    "    samples_y = samples_y.unsqueeze(3)\n",
    "    samples = torch.cat([samples_x, samples_y],3)\n",
    "    samples[:,:,:,0] = (samples[:,:,:,0]/(W-1)) # normalize to between  0 and 1\n",
    "    samples[:,:,:,1] = (samples[:,:,:,1]/(H-1)) # normalize to between  0 and 1\n",
    "    samples = samples*2-1                       # normalize to between -1 and 1\n",
    "    return torch.nn.functional.grid_sample(image, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctness test\n",
    "W, H, C = 5, 5, 1\n",
    "test_image = torch.ones(W,H,C).type(dtype)\n",
    "test_image[3,3,:] = 4\n",
    "test_image[3,4,:] = 3\n",
    "\n",
    "test_samples_x = torch.FloatTensor([[3.2]]).type(dtype)\n",
    "test_samples_y = torch.FloatTensor([[3.4]]).type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = bilinear_interpolate_torch_gridsample(test_image, test_samples_x, test_samples_y)\n",
    "\n",
    "# Benchmark\n",
    "# start = time.time()\n",
    "# bilinear_interpolate_torch_gridsample(image, samples_x, samples_y)\n",
    "# print (\"torch gridsample took \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Variable(torch.FloatTensor([1.0/3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Variable(torch.rand(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.2249  0.2423  0.1418\n",
       " 0.2403  0.0933  0.0808\n",
       " 0.0480  0.0302  0.0269\n",
       "[torch.FloatTensor of size (3,3)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t * v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.6748  0.7268  0.4255\n",
       " 0.7208  0.2798  0.2424\n",
       " 0.1441  0.0905  0.0807\n",
       "[torch.FloatTensor of size (3,3)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
