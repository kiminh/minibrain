{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliography:\n",
    "\n",
    "* [Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction](http://people.idsia.ch/~ciresan/data/icann2011.pdf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, utils\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import skimage \n",
    "import math\n",
    "# import io\n",
    "# import requests\n",
    "# from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from helper_modules import *\n",
    "from multi_res_cae import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport helpers, helper_modules, multi_res_cae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "helper_modules helpers multi_res_cae\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frcae = MultiFullCAE((640,480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mrcae = MultiResCAE([640,480])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "# num_epochs = 5\n",
    "# batch_size = 100\n",
    "# learning_rate = 0.001\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 309 ms, total: 1.46 s\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#%time model = MultiFullCAE(in_img_shape=(32,32), full_image_resize=(24,24)).cuda()\n",
    "model = MultiResCAE(in_img_shape=[32,32], channels=3, conv_layer_feat=[16, 16, 32],\n",
    "                 res_px=[[24, 24], [16, 16], [12, 12]], crop_sizes=[[32, 32], [24,24], [12, 12]],\n",
    "                 # conv_sizes = [(3,5,7), (3,5,7,11), (3,5,7,11)]  # this is too much I think\n",
    "                 conv_sizes=[[3, 5], [3, 5], [3, 5, 7]]\n",
    "        ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 559 µs, sys: 264 µs, total: 823 µs\n",
      "Wall time: 826 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 3, 32, 32)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "CPU times: user 716 ms, sys: 172 ms, total: 888 ms\n",
      "Wall time: 886 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#transformation = monochrome_preprocess(32,32)\n",
    "transformation = fullimage_preprocess(32,32)\n",
    "#train_loader, test_loader = get_loaders(batch_size, transformation, dataset=datasets.CocoDetection)\n",
    "train_loader, test_loader = get_loaders(batch_size, transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "prev_crop torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 24, 24])\n",
      "prev_crop torch.Size([128, 3, 24, 24])\n",
      "torch.Size([128, 3, 12, 12])\n",
      "encoding crop size =  torch.Size([128, 3, 32, 32])\n",
      "encoding crop size =  torch.Size([128, 3, 24, 24])\n",
      "encoding crop size =  torch.Size([128, 3, 12, 12])\n",
      "ranges =  \n",
      "  0   0  32  32\n",
      "  3   4  27  28\n",
      "  3   6  15  18\n",
      "[torch.IntTensor of size (3,4)]\n",
      "\n",
      "merging  0 \n",
      "  3\n",
      "  4\n",
      " 27\n",
      " 28\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 24, 24])\n",
      "merging  1 \n",
      "  3\n",
      "  6\n",
      " 15\n",
      " 18\n",
      "[torch.IntTensor of size (4,)]\n",
      " torch.Size([128, 3, 12, 12]) torch.Size([128, 3, 24, 24]) torch.Size([128, 3, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (img, labels) in enumerate(train_loader):\n",
    "        img = Variable(img).cuda()\n",
    "        # ===================forward=====================\n",
    "#         print(\"encoding batch of  images\")\n",
    "        output = model(img)\n",
    "#         print(\"computing loss\")\n",
    "        loss = criterion(output, img)\n",
    "        # ===================backward====================\n",
    "#         print(\"Backward \")\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.data[0]))\n",
    "    if epoch % 10 == 0:\n",
    "        pic = to_img(output.cpu().data)\n",
    "        in_pic = to_img(img.cpu().data)\n",
    "        save_image(pic, './mrcae_results/in-64x64_32x32_3-5-7-11-out_image_{}.png'.format(epoch))\n",
    "        save_image(in_pic, './mrcae_results/in-64x64_32x32_3-5-7-11-in_image_{}.png'.format(epoch))\n",
    "    if loss.data[0] < 0.21: #arbitrary number because I saw that it works well enough\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(\"fmrcae_in-64x64_32x32_3-5-7-11.pth\", model)\n",
    "#torch.save(\"mrcae_in-32x32_.pth\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Results \n",
    "\n",
    "Experiments with the following configurations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch understanding tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
